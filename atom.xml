<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>凡是过去 皆为序曲</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-12-29T05:03:11.929Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>kevin</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>sk_buff和协议头</title>
    <link href="http://yoursite.com/2017/12/26/sk-buff%E5%92%8C%E5%8D%8F%E8%AE%AE%E5%A4%B4/"/>
    <id>http://yoursite.com/2017/12/26/sk-buff和协议头/</id>
    <published>2017-12-26T00:23:44.000Z</published>
    <updated>2017-12-29T05:03:11.929Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;在Linux TCP/IP协议栈中，sk_buff是代表网络报文的网络缓冲区。sk_buff有三个构成部分：sk_buff、线性数据缓冲区、分页数据（struct_skb_shared_info）。当请求sk_buff时，需要传递线性数据区域的长度。sk_buff中有一些页分别指向传输层、网络层和链路层头。<br>&emsp;&emsp;这篇博客主要讨论sk_buff结构中的各个域，以及处理sk_buff结构的头、尾、结束、数据以及长度域的函数，将对sk_buff结构的data_len域和处理该域的函数做出说明。还将阐述skb_shared_info结构以及该结构的用途，然后描述了各种与sk_buff复制和排队操作相关的各种函数。<br>&emsp;&emsp;sk_buff包含线性和非线性两部分的数据。线性数据由sk_buff的数据域表示。一般来说，能够在单页中容纳的IP报文才分配一页的线性数据。如果整个IP报文的长度超过了一页的容量，处理该报文就有两个选择。一种是分配一个长度可容纳整个IP报文的先行数据区，另一种是使用分页数据区来容纳报文的剩余部分（线性数据=1页，IP剩余部分则存储在sk_buff的分页数据区中）。<br><a id="more"></a></p>
<h4 id="结构sk-buff"><a href="#结构sk-buff" class="headerlink" title="结构sk_buff"></a>结构sk_buff</h4><p>&emsp;&emsp;在Linux中，sk_buff结构代表了一个报文，它由三个部分组成。<br>&emsp;&emsp;（1）sk_buff结构，也称为sk_buff头；<br>&emsp;&emsp;（2）包含数据的线性数据块；<br>&emsp;&emsp;（3）由struct skb_shared_info表示的非线性数据部分；<br>&emsp;&emsp;sk_buff结构包含指向特定协议头数据结构的指针域，因此，有些域包含了每一层的控制信息，以便构建协议头，同时还可以用来根据特定事件判断下一步的处理动作。有些域包含IP校验和，以及下一个协议信息。任何时候当要从某接口接收或者发送新报文时，都要为该数据块分配一个sk_buff结构，并将数据复制到sk_buff中，然后才进一步处理报文。根据需要，可以克隆（只复制sk_buff结构，但是共享数据块）或完全复制sk_buff（完全复制sk_buff结构，同时也复制了一份数据块）。<br>&emsp;&emsp;下面是sk_buff结构定义的代码块实现：<br>include/linux/skbuff.h<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div></pre></td><td class="code"><pre><div class="line">struct sk_buff &#123;</div><div class="line">    /*next和prev这两个域链接相关的sk_buff结构，当报文分段时，原始报文的每个分段</div><div class="line">     *通过next域链接在一起。</div><div class="line">     */</div><div class="line">    struct sk_buff *next; //指向下一个分段   </div><div class="line">    struct sk_buff *prev; //指向前一个分段</div><div class="line"></div><div class="line">    //list指针指向该sk_buff当前放置的队列或者列表</div><div class="line">    struct sk_buff_head *list;</div><div class="line">    struct sock *sk; //指向报文（sk_buff）所属套接字的指针</div><div class="line">    struct timeval stamp; //该域记录接收或者传输报文时刻的时间戳</div><div class="line"></div><div class="line">    /* 这是指向设备（struct net_device）的指针，报文通过此设备接收或者发送。</div><div class="line">     * net_device记录网络接口（数据链路层）信息以及该设备的相关操作。</div><div class="line">     */</div><div class="line">    struct net_device *dev;</div><div class="line"></div><div class="line">    /* 这是一个不同传输层头的指针联合，该域指向传输层头在报文中开始的位置 */</div><div class="line">    union &#123;</div><div class="line">        struct tcphdr  *th;</div><div class="line">        struct udphdr  *uh;</div><div class="line">        struct icmphdr *icmph;</div><div class="line">        struct igmphdr *igmph;</div><div class="line">        struct iphdr   *ipiph;</div><div class="line">        struct spxhdr  *spxh;</div><div class="line">        unsigned char  *raw;</div><div class="line">    &#125;h;</div><div class="line"></div><div class="line">    /* 这是一个不同网络层头的指针联合，该域指向网络层头在报文中开始的位置 */</div><div class="line">    union &#123;</div><div class="line">        struct iphdr    *iph;</div><div class="line">        struct ipv6hdr  *ipv6h;</div><div class="line">        struct arphdr   *arph;</div><div class="line">        struct ipxhdr   *ipxh;</div><div class="line">        unsigned char   *raw;</div><div class="line">    &#125;nh;</div><div class="line"></div><div class="line">    /* 这是一个不同MAC层头的指针联合，该域指向MAC层头在报文中开始的位置 */</div><div class="line">    union &#123;</div><div class="line">        struct ethhdr *ethernet;</div><div class="line">        unsigned char *raw;</div><div class="line">    &#125;max;</div><div class="line"></div><div class="line">    /* dst 指向dst_entry结构，该结构记录了到达给定目的地的路由信息，也记录了一</div><div class="line">     *些给定连接相关的网络特征信息，如PMTU、RTT等。</div><div class="line">     */</div><div class="line">    struct dst_entry *dst;</div><div class="line">    /* 该域保存协议相关的控制信息，每个协议层可能独立的使用这些信息。*/</div><div class="line">    char             cb[48];</div><div class="line"></div><div class="line">    unsigned int len; //该域记录sk_buff中数据的总长度</div><div class="line">    unsigned int data_len; //只有当sk_buff中有非线性数据时才使用该域</div><div class="line">    unsigned int csum; //这是某时刻协议的校验和</div><div class="line">    unsigned int char __unused, </div><div class="line">                 cloned, //该域保存当前sk_buff是原始数据还是克隆数据的信息</div><div class="line">                 /* 该域包含报文类型信息。类型通常为多播、广播、回路、主机、其</div><div class="line">                  * 他主机、传出等。</div><div class="line">                  */</div><div class="line">                 pkt_type,</div><div class="line">                 ip_summed; //该域表示驱动是否计算IP校验和</div><div class="line">    __u32 priority; //该域保存报文的排队优先级信息，这基于IP头中的TOS域</div><div class="line">    atomic_t users; //该域保存引用了sk_buff的数量</div><div class="line"></div><div class="line">     /* 该域保存了下一个协议层信息，在处理报文时由当前协议层设置 */</div><div class="line">    unsigned short protocol;</div><div class="line">    unsigned short security; //该域保存报文的安全级别</div><div class="line"></div><div class="line">     /* 该域保存为该缓冲区所分配的总内存。它包括sk_buff结构的大小+分配给该</div><div class="line">      * sk_buff的数据块的大小。</div><div class="line">      */</div><div class="line">    unsigned int truesize;</div><div class="line"></div><div class="line">    /* 该域指向线性数据区的开始（为sk_buff分配的线性数据区的首字节） */</div><div class="line">    unsigned char *head; </div><div class="line">    /* 该域指向驻留在线性数据区的数据的起始位置。驻留在线性数据区中的数据可能并</div><div class="line">     * 不总是从线性数据区的起始head开始。</div><div class="line">     */</div><div class="line">    unsigned char *data;</div><div class="line">    unsigned char *tail; //该域指向驻留在线性数据区的最后一个字节的数据</div><div class="line"></div><div class="line">    /* 该域指向线性数据区的结尾，与tail不同。驻留在线性数据区中的数据结尾并不是</div><div class="line">     * 总是在线性数据区的结尾。利用该域可以确保我们没有使用超出可用存储的缓冲区</div><div class="line">     */</div><div class="line">    unsigned char *end;</div><div class="line">    ......</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;head、data、end、tail这4个域维护了线性数据区，当为新的sk_buff分配缓冲区时，需要提供线性数据区的大小。同时还要初始化sk_buff的这4个域，以指向线性数据区中合适的位置。下图是当skb_alloc()刚返回时的sk_buff结构：<br><img src="../../../../pictures/TCP/20171226114708.png" alt=""></p>
<h4 id="结构skb-shared-info"><a href="#结构skb-shared-info" class="headerlink" title="结构skb_shared_info"></a>结构skb_shared_info</h4><p>&emsp;&emsp;处于线性数据区结尾的结构，包含sk_buff的分段信息和非线性数据信息。<br>include/linux/skbuff.h<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">struct skb_shared_info &#123;</div><div class="line">    atomic_t        dataref; //该域保存skb_shared_info对象的引用次数</div><div class="line"></div><div class="line">     /* 该域保存sk_buff分页段的数目，它表示frags[]</div><div class="line">      * 数组的元素数量，该数组包含sk_buff的分页数据。</div><div class="line">      */</div><div class="line">    unsigned int nr_frags;</div><div class="line"></div><div class="line">    /* 该域是一个指向原始报文（frag_list所属的sk_buff）sk_buffs分段列表的指针。</div><div class="line">     * 如果原始报文需要分段，所有表示这些分配的sk_buffs将链接到该链表中。</div><div class="line">     */ </div><div class="line">    struct sk_buff  *frag_list;</div><div class="line">    /* 该域是分段的数组，这些分段包含sk_buff的分页数据。分页数据由</div><div class="line">    *  skb_frag_struct表示，分页数据（由frags[]表示）的数据长度是每个页段中所含字节数（frags[i]-&gt;size）的总和，并存储在sk_buff的data_len域。</div><div class="line">    */</div><div class="line">    skb_frag_t      frags[MAX_SKB_FRAGS]; </div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<h4 id="sk-buff和DMA-skb-frag-struct"><a href="#sk-buff和DMA-skb-frag-struct" class="headerlink" title="sk_buff和DMA-skb_frag_struct"></a>sk_buff和DMA-skb_frag_struct</h4><p>&emsp;&emsp;该结构是一个描述符，描述了包含sk_buff分页数据的每个分页段。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">struct skb_frag_struct &#123;</div><div class="line">    /* 该域是一个指向页结构的指针，页结构包含了分页数据。每个分页段都包含了一页</div><div class="line">     * 所容纳的最大数据。</div><div class="line">     */</div><div class="line">    struct page *page; </div><div class="line">    __u16 page_offset; //该域是页偏移量指针，指向本页数据的起始位置</div><div class="line">    __u16 size; //该域是page域所指页中数据的总长度</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<h4 id="sk-buff例程操作"><a href="#sk-buff例程操作" class="headerlink" title="sk_buff例程操作"></a>sk_buff例程操作</h4><p>（1） alloc_skb()<br>&emsp;&emsp;该函数分配一个新的sk_buff，该函数的参数为数据区的长度和内存分配的模式。数据区是分配给sk_buff的内存块，报文在这个数据区中构造。当alloc_skb()放回时，head、data、tail和end指针的位置在前面的图中已经给出了。可以看出，内存分配完成后，tail空间等于为sk_buff所请求的数据块的长度，head空间和数据长度则为0。<br>（2） skb_reserve()<br>&emsp;&emsp;该函数会改变sk_buff的head和tail空间，它主要用来为协议头预留空间。当需要为协议头保留空间时，就调用该函数，并向其传递头空间的长度。如下图所示。<br><img src="../../../../pictures/TCP/20171227101518.png" alt=""><br>（3） skb_put()<br>&emsp;&emsp;该例程用来处理sk_buff的线性数据区。该函数为分段数据在线性数据区的结尾预留空间。在大部分情况下，用户数据将在此处理，或者说TCP/UDP载荷在此处复制，它为报文载荷创建空间，如下图所示。<br><img src="../../../../pictures/TCP/20171227102803.png" alt=""><br>下面是skb_put()的源码<br>include/linux/skbuff.h<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">static inline unsigned char *skb_put(struct sk_buff *skb, unsigned int len)</div><div class="line">&#123;</div><div class="line">    unsigned char *tmp = skb-&gt;tail; //记录sk_buff的原始tail域</div><div class="line">    SKB_LINEAR_ASSERT(skb);</div><div class="line">    /* tail域加上请求的长度值，修改后的tail域扩展了sk_buff的总长度。</div><div class="line">     * 同样skb-&gt;len也要加上请求的长度值。</div><div class="line">     */</div><div class="line">    skb-&gt;tail += len; </div><div class="line">    skb-&gt;len += len;</div><div class="line">    /* 做完善性检查，以确保tail没有超过线性数据区的结束（skb-&gt;end）*/</div><div class="line">    if (skb-&gt;tail&gt;skb-&gt;end) &#123;</div><div class="line">        skb_over_panic(skb, len, current_text_addr());</div><div class="line">    &#125;</div><div class="line">    return tmp;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>（4） skb_push()<br>&emsp;&emsp;该函数处理sk_buff的data域，仅操作线性数据区。它将data域向head推进一个值，该值是以参数传递给该函数的字节数。数据长度增加多少，头空间就减少多少。skb_push()函数的源码如下所示。<br>include/linux/skbuff.h<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">static inline unsigned char *skb_push()</div><div class="line">&#123;</div><div class="line">    skb-&gt;data -= len; //data根据请求的长度减少</div><div class="line">    /* data域向head的推导导致整个sk_buff长度的扩展，sk_buff的长度将增加请求的长</div><div class="line">     * 度。</div><div class="line">     */</div><div class="line">    skb-&gt;len += len;</div><div class="line">    /* 进行完善性检查*/</div><div class="line">    if (skb-&gt;data&lt;skb-&gt;head) &#123;</div><div class="line">        skb_under_panic(skb, len, current_text_addr());</div><div class="line">    &#125;</div><div class="line">    /* 检查通过，将一个数据指针引用放回给调用者。 */</div><div class="line">    return skb-&gt;data;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><img src="../../../../pictures/TCP/20171229115947.png" alt=""><br>&emsp;&emsp;下图给出了调用skb_push()来处理data域的情形。$l_0$是sk_buff的原始长度，其中虚线表示data域指针。$l_r$是调用skb_push()所请求的长度。skb_push()处理完sk_buff后，线性数据区的总长度变为$l<em>r+l</em> 0$，黑线表示数据指针。<br>（5）skb_pull()<br>&emsp;&emsp;这个函数根据字节移动数据指针，字节数则以参数的形式传递给该函数，然后返回新的数据指针。它通过修改sk_buff的data域来处理sk_buff的线性数据区。该函数将skb-&gt;len减小请求的字节数大小，从而增加了sk_buff线性数据区头空间的大小。下面是源代码。<br>include/linux/skbuff.h<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">static inline unsigned char *skb_pull(struct sk_buff *skb, unsigned int len)</div><div class="line">&#123;</div><div class="line">    if (len &gt; skb-&gt;len)</div><div class="line">        return NULL;</div><div class="line">    return __skb_pull(skb, len);</div><div class="line">&#125;</div><div class="line"></div><div class="line">static inline char *__skb_pull(struct sk_buff *skb, unsigned int len)</div><div class="line">&#123;</div><div class="line">    skb-&gt;len -= len;</div><div class="line">    if (skb-&gt;len &lt; skb-&gt;data_len)</div><div class="line">        out_of_line_bug();</div><div class="line">    return skb-&gt;data += len;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;在Linux TCP/IP协议栈中，sk_buff是代表网络报文的网络缓冲区。sk_buff有三个构成部分：sk_buff、线性数据缓冲区、分页数据（struct_skb_shared_info）。当请求sk_buff时，需要传递线性数据区域的长度。sk_buff中有一些页分别指向传输层、网络层和链路层头。&lt;br&gt;&amp;emsp;&amp;emsp;这篇博客主要讨论sk_buff结构中的各个域，以及处理sk_buff结构的头、尾、结束、数据以及长度域的函数，将对sk_buff结构的data_len域和处理该域的函数做出说明。还将阐述skb_shared_info结构以及该结构的用途，然后描述了各种与sk_buff复制和排队操作相关的各种函数。&lt;br&gt;&amp;emsp;&amp;emsp;sk_buff包含线性和非线性两部分的数据。线性数据由sk_buff的数据域表示。一般来说，能够在单页中容纳的IP报文才分配一页的线性数据。如果整个IP报文的长度超过了一页的容量，处理该报文就有两个选择。一种是分配一个长度可容纳整个IP报文的先行数据区，另一种是使用分页数据区来容纳报文的剩余部分（线性数据=1页，IP剩余部分则存储在sk_buff的分页数据区中）。&lt;br&gt;
    
    </summary>
    
      <category term="TCP/IP架构、设计及应用" scheme="http://yoursite.com/categories/TCP-IP%E6%9E%B6%E6%9E%84%E3%80%81%E8%AE%BE%E8%AE%A1%E5%8F%8A%E5%BA%94%E7%94%A8/"/>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>TCP拥塞控制之CUBIC</title>
    <link href="http://yoursite.com/2017/12/21/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E4%B9%8BCUBIC/"/>
    <id>http://yoursite.com/2017/12/21/TCP拥塞控制之CUBIC/</id>
    <published>2017-12-21T12:00:34.000Z</published>
    <updated>2017-12-25T02:33:02.233Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;CUBIC是当前Linux系统上默认的拥塞控制算法。它的拥塞控制窗口增长函数是一个三次函数，这样设计的目的是为了在当前的快速和长距离网络环境中有更好的扩展性。CUBIC的拥塞窗口增长独立于RTT，因此能更好的保证流与流之间的公平性。<br><a id="more"></a></p>
<h3 id="问题是什么"><a href="#问题是什么" class="headerlink" title="问题是什么"></a>问题是什么</h3><p>&emspp;&emsp;当今的因特网朝着速度更快，距离更长的趋势发展，致使针对传统网络设计的TCP算法性能受到了挑战。上面的网络特性用一个专业名词描述叫做高BDP（bandwidth and delay product），它代表了带宽被完全利用时网络中能容纳的数据包总量。<br>&emsp;&emsp;传统的TCP算法，例如TCP-Reno，TCP-NewReno，TCP-SACK等之所以在新环境下不能充分利用网络带宽，主要是因为在进入拥塞避免阶段后，它们的拥塞窗口每经过一个RTT才加1，拥塞窗口的增长速度太慢，当碰上高带宽环境时，可能需要经历很多个RTT，拥塞窗口才能接近于一个BDP。如果数据流很短，可能拥塞窗口还没增长到一个BDP，数据流就已经结束了，这种情况的带宽利用率就会非常低。</p>
<h3 id="已存在的方法"><a href="#已存在的方法" class="headerlink" title="已存在的方法"></a>已存在的方法</h3><p>&emsp;&emsp;为了解决上面提到的TCP低利用率问题，有很新的TCP变体被提出来，例如FAST，HSTCP，STCP，HTCP，SQRT，West-wood和BIC-TCP。这些算法都号称能在很短的时间内提高网络传输速率。在Linux内核2.6.8版本里，BIC-TCP被选为默认算法，其他算法也实施在Linux内核里作为可选项。BIC-TCP相比其他算法的优点是其稳定性。下面就花点篇幅介绍下BIC-TCP算法。</p>
<h4 id="BIC-TCP"><a href="#BIC-TCP" class="headerlink" title="BIC-TCP"></a>BIC-TCP</h4><p>&emsp;&emsp;BIC-TCP采用二分搜索的方式来决定拥塞窗口的增长尺度，首先它会记录拥塞窗口的一个最大值点，这个最大值就是TCP最近一次出现丢包时拥塞窗口的值；还会记录一个最小值点，即在一个RTT周期内没有出现丢包事件时窗口的大小。二分搜索就是取最小值和最大值的中间点，当拥塞窗口增长到这个中间值且没有出现丢包的话，就说明网络还可以容纳更多的数据包。那么将这个中值设为新的最小值，在新的最小值和最大值间搜索中间值。当当前拥塞窗口的值还远没有达到通道的容量时，其增长速度很快；相反，当拥塞窗口的值接近于通道的容量时，其拥塞窗口增长函数是一个简化的对数凹函数。这个凹函数使拥塞窗口在饱和点或平衡点比凸函数或线性函数保持更长的时间，在饱和点处，凹函数和线性函数它们具有最大的窗口增量，因此在丢包发生时会出现大量的数据包被丢失。<br><img src="../../../../pictures/paper read/20171223094737.png" alt=""><br>&emsp;&emsp;BIC-TCP的主要特征是在前面说过的其独特的窗口增长函数，图1给出了BIC-TCP的窗口增长函数。当出现丢包事件时，BIC-TCP通过乘以因子$\beta$来缩小窗口，缩小之前的窗口大小被设置为最大$W_max$，并且缩小之后的窗口大小被设置为最小值$W_min$。 然后，BIC-TCP使用这两个参数执行二分搜索，拥塞窗口的下一个取值会是$W_max$和$W_min$之间的“中点”$W_mid$。<br>&emsp;&emsp;为了防止拥塞窗口从$W_min$增长到$W_mid$的步长$step$太大，BIC-TCP还设置了一个常数$S_max$，当$step$&gt;$S_max$时，BIC-TCP会取下一个增长点为$W_min$+$S_max$而不是$W_mid$，如果没有出现丢包的话，再更新$W_min$，直到$step$&lt;$S_max$为止。与此同时BIC-TCP还设置一个另一个控制参数$S_min$，当窗口增量小于$S_min$时，BIC-TCP会将当前拥塞窗口值设为最大值。<br>&emsp;&emsp;如果窗口增长超过最大值，则说明当前窗口最大值还不是一个饱和点，网络还可以容纳更多的数据包，窗口还有增长的空间，一个新的窗口最大值需要被探索。于是BIC-TCP会进入一个新的阶段，叫做最大值探索阶段。最大探测使用一个与在加法增长和二分搜索阶段（这是对数;其倒数将是指数）完全对称的窗口增长函数。图1中给出了在最大探索阶段期间的窗口增长函数。在最大探测期间，窗口最初缓慢地增长以发现附近新的最大值，经过一段时间的缓慢增长，如果没有找到新的最大值（即，没出现包丢失），则它猜测新的最大值离得很远，所以它给窗口大小增加一个大的固定增量，使用加法增加切换到更快的增加速度。BIC-TCP的良好性能来自$W_max$附近的缓慢增加和在加法增加和最大探测期间的线性增加。</p>
<h3 id="什么是CUBIC"><a href="#什么是CUBIC" class="headerlink" title="什么是CUBIC"></a>什么是CUBIC</h3><p>&emsp;&emsp;CUBIC是BIC-TCP的下一代版本。 它通过用三次函数（包含凹和凸部分）代替BIC-TCP的凹凸窗口生长部分，大大简化了BIC-TCP的窗口调整算法。实际上，任何奇数阶多项式函数都具有这种形状。三次函数的选择是偶然的，并且不方便。CUBIC的关键特征是其窗口增长仅取决于两个连续拥塞事件之间的时间。一个拥塞事件是指出现TCP快速恢复的时间。因此，窗口增长与RTT无关。 这个特性允许CUBIC流在同一个瓶颈中竞争，有相同的窗口大小，而不依赖于它们的RTT，从而获得良好的RTT公平性。而且，当RTT较短时，由于窗口增长率是固定的，其增长速度可能比TCP标准慢。 由于TCP标准（例如，TCP-SACK）在短RTT下工作良好，因此该特征增强了协议的TCP友好性。</p>
<h4 id="CUBIC的窗口增长函数"><a href="#CUBIC的窗口增长函数" class="headerlink" title="CUBIC的窗口增长函数"></a>CUBIC的窗口增长函数</h4><p>&emsp;&emsp;BIC-TCP在高速网络中实现了良好的可扩展性，在自身的竞争流之间是公平的，并且具有低窗口振荡的稳定性。但BIC-TCP的窗口增长函数对于TCP来说还是过于激进，特别是在短RTT或低速网络中。于是有了CUBIC，CUBIC保留了BIC-TCP的稳定性和可扩展性的优点，同时简化了窗口控制和加强了TCP友好性。<br><img src="../../../../pictures/paper read/20171223095005.png" alt=""><br>&emsp;&emsp;CUBIC的窗口增长函数是一个三次函数，非常类似于BIC-TCP的窗口增长函数，CUBIC的函数图像如图2所示。CUBIC的详细运行过程如下，当出现丢包事件时，CUBIC同BIC-TCP一样，会记录这时的拥塞窗口大小作为$W_max$，接着通过因子$\beta$执行拥塞窗口的乘法减小，这里$\beta$是一个窗口降低常数，并进行正常的TCP快速恢复和重传。从快速恢复阶段进入拥塞避免后，使用三次函数的凹轮廓增加窗口。三次函数被设置在$W_max$处达到稳定点，然后使用三次函数的凸轮廓开始探索新的最大窗口，如果新的最大窗口存在的话。<br>&emsp;&emsp;CUBIC的窗口增长函数公式如下所示：<br>$$W(t)=C(t-K)^3+W_max \quad (1)$$<br>这里，C是一个CUBIC的参数，t是从窗口上次降低开始到现在的时间，是一个弹性值，而K是上述函数在没有进一步丢包的情况下将$W$增加到$W_max$经历的时间，其计算公式如下：<br>$$K=\sqrt[3]{\frac{W_max*\beta}{C}} \quad (2)$$<br>在拥塞避免阶段每收到一个ACK，CUBIC都会使用方程（1）计算在下个RTT的窗口增长速率。CUBIC使用$W(t+RTT)$作为拥塞窗口的候选值，假设当前拥塞窗口大小为$cwnd$。根据$cwnd$的值，CUBIC有三种运行模式。首先，如果cwnd小于（标准）TCP在上次丢包事件之后t时刻到达的窗口大小，那么CUBIC处于TCP模式（我们将在下面描述如何根据时间确定标准TCP的窗口大小）。否则，如果$cwnd$小于$W_max$，那么CUBIC在三次函数的凹轮廓区域，如果$cwnd$大于$W_max$，那么，CUBIC处于三次函数的凸轮廓区域。</p>
<h4 id="TCP友好型区域"><a href="#TCP友好型区域" class="headerlink" title="TCP友好型区域"></a>TCP友好型区域</h4><p>&emsp;&emsp;这小节主要说了怎么判断在发生丢包事件后，标准TCP在$t$时刻的窗口大小。</p>
<h4 id="凹区域"><a href="#凹区域" class="headerlink" title="凹区域"></a>凹区域</h4><p>&emsp;&emsp;当在拥塞避免阶段收到一个ACK，如果协议不处于TCP模式，且$cwnd$小于$W_max$，那么，协议就处于凹区域，在这个区域，$cwnd$的增量为<br>$$\frac{W(t+RTT)-cwnd}{cwnd}$$</p>
<h4 id="凸区域"><a href="#凸区域" class="headerlink" title="凸区域"></a>凸区域</h4><p>&emsp;&emsp;如果协议不处于TCP模式，且$cwnd$大于饱和点$W_max$，那么协议处于凸区域，$cwnd$的增量为<br>$$\frac{W(t+RTT)-cwnd}{cwnd}$$<br>其实凸区域的增长函数和凹区域的增长函数一样，只不过凸区域越过了饱和点，而其区域没有越过饱和点。</p>
<h4 id="乘法降低"><a href="#乘法降低" class="headerlink" title="乘法降低"></a>乘法降低</h4><p>&emsp;&emsp;当出现数据包丢失时，CUBIC会通过乘以因子$\beta$来降低拥塞窗口，这里取$\beta=0.2$，设置$\beta$小于0.5的副作用是收敛较慢。虽然更适应性的设置会导致更快的收敛，但是会使协议的分析变得更加困难，并影响协议的稳定性。</p>
<h4 id="快速收敛"><a href="#快速收敛" class="headerlink" title="快速收敛"></a>快速收敛</h4><p>&emsp;&emsp;为了提高CUBIC的收敛速度，在协议中加入了启发式。当新的流量加入网络时，网络中的现有流量需要放弃其带宽份额，以使新流量有一定的增长空间。下面详细描述一下快速收敛的过程。在发生丢包前，CUBIC会记录一个最大窗口值$W_max$，当发生丢包后，在降低窗口前，CUBIC又会记录当前的窗口值作为新的$W_max$，为了不至于混淆，可以将之前记录的$W_max$标记位$W_lastmax$。当发生丢包时，CUBIC会比较$W_lastmax$的$W_max$大小，如果$W_max$小于$W_lastmax$，这表明由于可用带宽的变化，该流所经历的饱和点正在降低。这种情况下，CUBIC的做法是通过进一步的减小$W_max$来释放更过的可用带宽。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;CUBIC是当前Linux系统上默认的拥塞控制算法。它的拥塞控制窗口增长函数是一个三次函数，这样设计的目的是为了在当前的快速和长距离网络环境中有更好的扩展性。CUBIC的拥塞窗口增长独立于RTT，因此能更好的保证流与流之间的公平性。&lt;br&gt;
    
    </summary>
    
      <category term="私人文献阅读" scheme="http://yoursite.com/categories/%E7%A7%81%E4%BA%BA%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="TCP/IP" scheme="http://yoursite.com/tags/TCP-IP/"/>
    
  </entry>
  
  <entry>
    <title>I/O复用</title>
    <link href="http://yoursite.com/2017/11/20/I-O%E5%A4%8D%E7%94%A8/"/>
    <id>http://yoursite.com/2017/11/20/I-O复用/</id>
    <published>2017-11-20T14:04:08.000Z</published>
    <updated>2017-11-20T14:48:54.399Z</updated>
    
    <content type="html"><![CDATA[<h3 id="I-O模型"><a href="#I-O模型" class="headerlink" title="I/O模型"></a>I/O模型</h3><p>在Unix下5种可用的I/O模型：<br>阻塞式I/O；<br>非阻塞式I/O；<br>I/O复用；<br>信号驱动式I/O；<br>异步I/O；</p>
<h4 id="阻塞式I-O模型"><a href="#阻塞式I-O模型" class="headerlink" title="阻塞式I/O模型"></a>阻塞式I/O模型</h4><p>&emsp;&emsp;阻塞式I/O模型的基本思想是当应用进程调用recvfrom系统调用时，如果内核到用户空间的数据没有准备好，那么进程一直阻塞于recvfrom调用，直到数据从内核复制到用户空间，这时recvfrom返回。<br><img src="../../../../pictures/阻塞式I-O模型.png" alt=""></p>
<h4 id="非阻塞式I-O模型"><a href="#非阻塞式I-O模型" class="headerlink" title="非阻塞式I/O模型"></a>非阻塞式I/O模型</h4><p>&emsp;&emsp;当应用进程调用recvfrom系统调用时，如果内核到用户空间的数据没有准备好，那么recvfrom返回一个EWOULDBLOCK错误。应用进程会不断的调用recvfrom，然后recvfrom不断的返回EWOULDBLOCK，直到内核到用户空间的数据准备好为止，然后recrfrom成功返回。<br>&emsp;&emsp;当一个应用进程对一个非阻塞描述符循环调用recvfrom时，这个过程称之为轮询（polling）。应用进程持续轮询内核，以查看某个操作是否就绪，这么做往往消耗大量CPU时间。<br><img src="../../../../pictures/非阻塞式I-O模型。png" alt=""></p>
<h4 id="I-O复用模型"><a href="#I-O复用模型" class="headerlink" title="I/O复用模型"></a>I/O复用模型</h4><p><img src="../../../../pictures/I-O复用模型.png" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;I-O模型&quot;&gt;&lt;a href=&quot;#I-O模型&quot; class=&quot;headerlink&quot; title=&quot;I/O模型&quot;&gt;&lt;/a&gt;I/O模型&lt;/h3&gt;&lt;p&gt;在Unix下5种可用的I/O模型：&lt;br&gt;阻塞式I/O；&lt;br&gt;非阻塞式I/O；&lt;br&gt;I/O复用；&lt;br&gt;信号驱动
    
    </summary>
    
      <category term="UNIX网络编程" scheme="http://yoursite.com/categories/UNIX%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
    
  </entry>
  
  <entry>
    <title>套接字编程简介</title>
    <link href="http://yoursite.com/2017/09/18/%E5%A5%97%E6%8E%A5%E5%AD%97%E7%BC%96%E7%A8%8B%E7%AE%80%E4%BB%8B/"/>
    <id>http://yoursite.com/2017/09/18/套接字编程简介/</id>
    <published>2017-09-18T04:41:16.716Z</published>
    <updated>2017-09-19T07:55:40.801Z</updated>
    
    <content type="html"><![CDATA[<h4 id="套接字地址结构"><a href="#套接字地址结构" class="headerlink" title="套接字地址结构"></a>套接字地址结构</h4><p>IPv4套接字地址结构通常也称为“网际套接字地址结构”，下面是其POSIX定义<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">struct in_addr &#123;</div><div class="line">    in_addr_t s_addr;</div><div class="line">&#125;;</div><div class="line"></div><div class="line">struct sockaddr_in &#123;</div><div class="line">    uint8_t         sin_len;</div><div class="line">    sa_family_t     sin_family;</div><div class="line">    in_port_t       sin_port;</div><div class="line"></div><div class="line">    struct in_addr  sin_addr;</div><div class="line"></div><div class="line">    char            sin_zero[8];</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>1.IPv4地址和TCP或UDP端口号在套接字地址结构中总是以网络字节序来存储；<br>2.sin_zero字段未曾使用，不过在填写这中套接字地址结构时，总是把该字段置为0；<br>3.套接字地址结构仅在给定主机上使用；</p>
<h4 id="值-结果参数"><a href="#值-结果参数" class="headerlink" title="值-结果参数"></a>值-结果参数</h4><p>当往一个套接字函数传递一个套接字地址结构时，该结构总是以引用形式来传递，也就是说传递的是指向该结构的一个指针。<br>（1）从进程到内核传递套接字地址结构的函数有三个：bind、connect、sendto。这些函数的一个参数是指向某个套接字地址结构的指针，另一个参数是该结构的整数大小，例如<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">struct sockaddr_in serv;</div><div class="line"></div><div class="line">connect(sockfd, (SA *) &amp;serv, sizeof(serv));</div></pre></td></tr></table></figure></p>
<p>（2）从内核到进程传递套接字地址结构的函数有4个：accept、recvfrom、getsockname和getpeername。这4个函数的其中两个参数是指向某个套接字地址结构的指针和指向表示该结构大小的整数变量的指针。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">struct sockaddr_un cli;</div><div class="line">socklen_t len;</div><div class="line">len = sizeof(cli);</div><div class="line">getpeername(unixfd, (SA *) &amp;cli, &amp;len);</div></pre></td></tr></table></figure></p>
<h4 id="字节排序函数"><a href="#字节排序函数" class="headerlink" title="字节排序函数"></a>字节排序函数</h4><p>小端字节序（little-endlian）：将低序字节存储在起始地址；<br>大端字节序（big-endian）：将高序字节存储在起始地址；<br>主机字节序：整数在内存中保存的顺序；<br>网络字节序：是TCP/IP中规定好的一种数据表示格式，他与具体的CPU类型、操作系统等无关，从而保证数据在不同主机之间传输时能够被正确解释。网络字节序采用big-endian。<br><img src="../../../../pictures/UNIX/20170919153411.png" alt=""></p>
<h4 id="字节操纵函数"><a href="#字节操纵函数" class="headerlink" title="字节操纵函数"></a>字节操纵函数</h4><p>操纵多字节字段的函数有两组，一组是名字以b开头的函数起源于4.2BSD几乎所有现今支持套接字函数的系统仍然提供它们；另一组是以mem开头的第二组函数起源于ANSI C标准，支持ANSI C函数库的所有系统都提供它们。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">#include &lt;strings.h&gt;</div><div class="line">//将目标字节串指定书目的字节置为0</div><div class="line">void bzero(void *dest, size_t nbytes); </div><div class="line"> //将指针syc指向的大小为nbytes的字节赋给指针dest</div><div class="line">void bcopy(const void *syc, void *dest, size_t nbytes);</div><div class="line">//比较大小，若相同返回0，否则返回非0</div><div class="line">int bmcp(const void *ptr1, const void *ptr2, size_t nbytes);</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">#include &lt;strings.h&gt;</div><div class="line">//将目标地址大小为len的字节置为值c</div><div class="line">void *memset(void *dest, int c, size_t len);</div><div class="line">//将指针syc指向的大小为nbytes的字节赋给指针dest</div><div class="line">void *memcpy(void *dest, const void *syc, size_t nbytes);</div><div class="line">//比较两个任意的字节串大小，若相同返回0，否则返回非0 </div><div class="line">int memcmp(const void *ptr1, const void *ptr2, size_t nbytes);</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;套接字地址结构&quot;&gt;&lt;a href=&quot;#套接字地址结构&quot; class=&quot;headerlink&quot; title=&quot;套接字地址结构&quot;&gt;&lt;/a&gt;套接字地址结构&lt;/h4&gt;&lt;p&gt;IPv4套接字地址结构通常也称为“网际套接字地址结构”，下面是其POSIX定义&lt;br&gt;&lt;figure
    
    </summary>
    
      <category term="UNIX网络编程" scheme="http://yoursite.com/categories/UNIX%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
    
  </entry>
  
  <entry>
    <title>程序的机器级表示</title>
    <link href="http://yoursite.com/2017/09/14/%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9C%BA%E5%99%A8%E7%BA%A7%E8%A1%A8%E7%A4%BA/"/>
    <id>http://yoursite.com/2017/09/14/程序的机器级表示/</id>
    <published>2017-09-14T01:03:38.000Z</published>
    <updated>2017-09-14T14:27:55.710Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;最近正在看《深入理解计算机系统》这本书，这本书虽然不是很好懂，但还是想硬着头皮给它看完，顺便做做笔记。<br><a id="more"></a></p>
<h4 id="程序编码"><a href="#程序编码" class="headerlink" title="程序编码"></a>程序编码</h4><p>&emsp;&emsp;源代码通过编译器编译后生成汇编码（以.s结尾），接下来，汇编器将汇编码转化成二进制目标码（以.o结尾），最后链接器将目标代码文件与实现库函数（如printf）的代码合并，并生成最终的可执行代码文件（没有后缀）。<br><img src="../../../../pictures/Computer System/20170914083600.png" alt=""><br>&emsp;&emsp;计算机系统使用了多种不同形式的抽象，对于机器级编程来说，有两种抽象尤为重要。第一种是机器级程序的格式和行为，定义为指令集体系结构（Instruction set architecture, ISA），它定义了处理器状态、指令的格式，以及每条指令对状态的影响。第二种抽象是，机器级程序的使用的地址是虚拟地址，提供的存储器模型看上去是一个非常大的字节数组。</p>
<h4 id="访问信息"><a href="#访问信息" class="headerlink" title="访问信息"></a>访问信息</h4><p>&emsp;&emsp;一个IA32中央处理单元（CPU）包含一组8个存储32位值的寄存器。这些寄存器用来存储整数数据和指针。如图2所示<br><img src="../../../../pictures/Computer System/20170914101843.png" alt=""><br>&emsp;&emsp;三种不同的操作数类型，第一种是立即数（immediate），也就是常数值，任何一个能放进一个32位的字里的数值都可以用作立即数。第二种类型是寄存器（register），它表示某个寄存器的内容。第三类操作数是存储器（memory）引用，它会根据计算出来的地址访问某个存储器位置。如图3所示，给出了多种不同的寻址模式。<br><img src="../../../../pictures/Computer System/20140505164651890.png" alt=""></p>
<h4 id="控制"><a href="#控制" class="headerlink" title="控制"></a>控制</h4><p>&emsp;&emsp;机器代码提供两种基本的低级机制来实现有条件的行为：测试数据值，然后根据测试的结果来改变控制流或者数据流。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;最近正在看《深入理解计算机系统》这本书，这本书虽然不是很好懂，但还是想硬着头皮给它看完，顺便做做笔记。&lt;br&gt;
    
    </summary>
    
      <category term="计算机系统" scheme="http://yoursite.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"/>
    
    
  </entry>
  
  <entry>
    <title>Token Flow Control in Data Center Networks解读</title>
    <link href="http://yoursite.com/2017/08/31/TFC/"/>
    <id>http://yoursite.com/2017/08/31/TFC/</id>
    <published>2017-08-31T00:45:22.000Z</published>
    <updated>2017-08-31T13:21:37.656Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;Token Flow Control (TFC)是为在数据中心网络中获得高带宽利用率，极低延迟，快速收敛，基本不丢包而提出的一种传输控制机制。<br><a id="more"></a></p>
<h3 id="问题是什么"><a href="#问题是什么" class="headerlink" title="问题是什么"></a>问题是什么</h3><h4 id="应用需求"><a href="#应用需求" class="headerlink" title="应用需求"></a>应用需求</h4><p>&emsp;&emsp;现代数据中心网络对服务性能要求一直在增加。比如支持online数据处理的流计算对平均和尾延迟比一些像MapReduce这类的offline处理模式更加敏感；在memcachedsystems中，零包丢失是一个重要的性能刻画尺度，因为丢包后的重传会严重影响网络传输性能。</p>
<h4 id="数据流自身特性"><a href="#数据流自身特性" class="headerlink" title="数据流自身特性"></a>数据流自身特性</h4><p>&emsp;&emsp;某些流的自身特性也导致了网络的低性能，比如short traffic bursts易导致网络拥塞和包丢失，致使flow completion time延长；highly concurrent flow也会带来网络拥塞，当并发高到一定程度，甚至会出现每条流的cwnd小到只有一个数据包这种情况； on-off pattern of flow transmission<br>&emsp;&emsp;不管是新的应用需求还是数据流自身特性对数据中心网路的性能要求都在日益增加。总的来说，就是要做到，fast convergence, zero packet loss, low latency。</p>
<h3 id="为什么这个问题很重要和已有工作"><a href="#为什么这个问题很重要和已有工作" class="headerlink" title="为什么这个问题很重要和已有工作"></a>为什么这个问题很重要和已有工作</h3><h4 id="Fast-Convergence"><a href="#Fast-Convergence" class="headerlink" title="Fast Convergence"></a>Fast Convergence</h4><p>&emsp;&emsp;在数据中心网络中，大约90%的流都是短流，短流一般只有几个数据包，所以为了减少flow completion time，传输协议使流快速的收敛到一个合适的共享带宽就很重要。现有的<strong>TCP及其TCP变体</strong>都是先经过慢启动，然后到达threshold，进入拥塞避免，对这种短流响应太慢，可能这些流还没收敛到公平共享带宽就已经结束了。<br>&emsp;&emsp;还有一个问题是有些流（silent flow）是间歇性的传输数据，在他们不传输数据的这个时间段内，但它们占据着带宽，致使带宽利用不充分。传输协议<strong>$D^{3}$</strong>虽然可以快速的收敛到一个合适的速率，但无法解决这种silent flow问题。</p>
<h4 id="Zero-Packet-Loss"><a href="#Zero-Packet-Loss" class="headerlink" title="Zero Packet Loss"></a>Zero Packet Loss</h4><p>&emsp;&emsp;在大规模数据中心网络中，TCP遭受的问题有TCP Incast, TCP outcast, long query completion time, out-of-order等。Long query completion time and out-of-order就不介绍了，这里解释一下什么是TCP Incast and TCP outcast:<br>&emsp;&emsp;<strong>TCP Incast:</strong> TCP Incast是指多个机器的大量TCP连接集中连接到一个机器，导致压力集中到某一个交换机，交换机的buffer很快用光，然后出现大规模的丢包事件，如图1所示。有兴趣的可以看看专门研究TCP Incast问题的paper。在blog后面会列出相关的paper。<br><img src="../../../../pictures/DCN/20170831103945.png" alt=""><br>&emsp;&emsp;<strong>TCP outcast:</strong> TCP outcast</p>
<h4 id="Low-Latency"><a href="#Low-Latency" class="headerlink" title="Low Latency"></a>Low Latency</h4><p>&emsp;&emsp;高延迟直接对一些云服务提供商的利润造成负面影响，许多云服务商采用分布式实时计算系统，例如Storm，网络时延是计算框架中整个时延的大头。还有一些web services，例如facebook，都要求极低延迟。而在数据中心网络中，round trip delay一般很小，通常在hundred microseonds级别，而queueing delay很大，要比round trip delay高出几个数量级，可以达到hundred milliseconds级别。</p>
<h3 id="TFC的设计"><a href="#TFC的设计" class="headerlink" title="TFC的设计"></a>TFC的设计</h3><p>&emsp;&emsp;在TFC的设计模型中，有两个量很重要，分别是<strong>Token</strong>和<strong>the Number of Effective Flows</strong>：</p>
<blockquote>
<p>Token T[n]. T[n] represents how many data can be transmited by a link in time slot n(n = 0, 1, …). T[n] can be computed as $c*t$, where c is the link bandwidth and t is the duration of a time slot.<br>Number of effective flows E[n]. E[n] stands for the number of full windows of data packets injected by all the passing flows in time slot n.</p>
</blockquote>
<p>之所以要计算有效流数，是因为有些流是间歇性的传输数据，所以间歇期时间要被剔除。还有一点要说明的是，这里的有效流，根据原文的解释，应该是在时间段$t$内，满发送窗口的个数。下面给出了$E[n]$的计算公式；<br>$$E[n] = \sum_{f} \frac{t}{rtt_f} \quad (1)$$<br>表达式（1）中的$t$是指持续时间长度，$rtt_f$表示流f的$rtt$，这样算是因为，一个$rtt$可以发送一个满窗口的数据包。<br>$$W[n+1] = \frac{T[n]}{E[n]} \quad (2)$$<br>知道了满窗口的个数和总共发送了多少数据包，当然就知道了拥塞窗口的大小。<br>下图是一个计算例子：<br><img src="../../../../pictures/DCN/20170831125800.png" alt=""></p>
<h4 id="Measuring-the-Number-of-Effective-Flows"><a href="#Measuring-the-Number-of-Effective-Flows" class="headerlink" title="Measuring the Number of Effective Flows"></a>Measuring the Number of Effective Flows</h4><p>&emsp;&emsp;精确的知道有效流数有以下几个方法。方法一每条流可以在每个回合发送一个额外特殊的数据包，switches只需要测量在时间段$n$内收到的特殊数据包数就可以知道有效流的个数，但这种方法引入的开销太大。方法二在时间段$n$内的有效流数$E[n]$可以通过等式$\frac{A[n]}{W[n-1]}$得到，但是这个$W[n-1]$是上一个时间段得到的，除非bottleneck switch在上一个时间段记录的拥塞窗口值一直到当前都保持不变。<br>&emsp;&emsp;TFC在这里通过在每个回合标记一个数据包来告诉switch有效流数，而不是发送一个额外的数据包。这样，switch只需要数被标记过的数据包就可以知道有效流数了。</p>
<h4 id="Duration-of-a-Time-Slot"><a href="#Duration-of-a-Time-Slot" class="headerlink" title="Duration of a Time Slot"></a>Duration of a Time Slot</h4><p>&emsp;&emsp;理论上这个时间长度可以是任意值但是，在实际环境中，考虑到收敛速度，计算有效流的精确性，还是需要确定一个合适的值。一方面呢，这个值不能太大，如果太大，switchs就不能即时的通过得到的有效流数更新拥塞窗口，以至于无法做到快速收敛。也不能太小，如果太小，这样计数的有效流数就会太小，就会得到一很大的拥塞窗口值，导致不准确。一般选择某条流的$rtt$作为基准，根据经验，在数据中心网络中,流与流之间的$rtt$相差不超过3倍。</p>
<h4 id="Achieving-Rare-Packets-Loss"><a href="#Achieving-Rare-Packets-Loss" class="headerlink" title="Achieving Rare Packets Loss"></a>Achieving Rare Packets Loss</h4><p>&emsp;&emsp;当并发流的数量足够大，即时每条流只发一个数据包，也会出现拥塞，然而这种情形在数据中心网络中还比较普遍。一个比较常见的方法就是改变MSS的大小，这样一来，每个数据包中，包头占的比重就会增加，带宽利用率因此会下降。另外一个方法就是延迟发送时间，每$\frac{MSS}{W}$个$RTT$发送一个数据包。这样的话就需要精确的测量$RTT$，以及一个高分辨率的计时器来计数$\frac{RTT}{W}$,然而采用高分辨率定时器会引入大量的中断，产生额外的负载，如频繁地打乱处理器高速缓存并增加耗电。<br>&emsp;&emsp;每一个switch都有了一个counter来记录还可以发送多少数据包，这个计数器会随着时间而增加。当一个ACK到达时switch时，如果它携带的拥塞窗口小于一个包大小，但是switch的counter记录的可发送的值大于一个数据包，那么，switch会将ACK头部的拥塞窗口值修改为一个数据包大小，然后，counter减1；如果counter小于1，那么这个ACK会被放入到一个delay queue中，等到counter大于1了，再做处理。还有如果ACK通报给sender的拥塞窗口值本身就大于一个数据包，那么ACK会直接被转发，counter减1。</p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>&emsp;&emsp;实施TFC算法呢需要修改数据包头和拥塞控制机制，包头呢，主要是动用了TCP头的保留位中的两位，分别叫做RM(Round MArk)和RMA(Round MArk Acknowledgment)，用来打标记方便switch计算有效流数；对拥塞控制机制的修改已经在前面说过了。<br>&emsp;&emsp;关于RM和RMA的使用，需要提出一点疑问，原文中是这样描述的：</p>
<blockquote>
<p>During the establishment phase, the sender and receiver negotiate<br>whether to use TFC or not. Then at the data transmission<br>phase, the sender sets the RM bit in the TFC header<br>of the first data packet to 1. After receiving a RMA marked<br>packet, the sender sets the RM bit in the TFC header of the<br>next sending data packet to 1.</p>
</blockquote>
<p>想法是挺好的，但是，万一这个带有标记的数据包丢了怎么办，paper没有给出说明。如果丢了，paper中对有效流的计数将无法实现。<br>&emsp;&emsp;要实现TFC的功能，switch需要做三件事，computing tokens, measuring the number of effective flows and updating congestion windows。这些功能都在上面介绍过了，这里就不多说了。实现结构图如下图示：<br><img src="../../../../pictures/DCN/20170831192042.png" alt=""></p>
<p><strong>参考文献：</strong><br><a href="https://nns.cs.tsinghua.edu.cn/paper/eurosys16_jz.pdf" target="_blank" rel="external">TFC: Token Flow Control in Data Center Networks</a><br><a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6203387" target="_blank" rel="external">ICTCP: Incast Congestion Control for TCP in Data-Center Networks</a><br><a href="https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final126.pdf" target="_blank" rel="external">The TCP Outcast Problem: Exposing Unfairness in Data Center Networks</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;Token Flow Control (TFC)是为在数据中心网络中获得高带宽利用率，极低延迟，快速收敛，基本不丢包而提出的一种传输控制机制。&lt;br&gt;
    
    </summary>
    
      <category term="私人文献阅读" scheme="http://yoursite.com/categories/%E7%A7%81%E4%BA%BA%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="DCN" scheme="http://yoursite.com/tags/DCN/"/>
    
  </entry>
  
  <entry>
    <title>iperf和iperf3的问题</title>
    <link href="http://yoursite.com/2017/08/28/iperf%E5%92%8Ciperf3%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2017/08/28/iperf和iperf3的问题/</id>
    <published>2017-08-28T00:13:08.000Z</published>
    <updated>2017-08-31T00:44:37.712Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;最近因为实验需要重现在data center networks中的TCP Incast问题，就是many client to one server发包，导致每条流分得的带宽很小，即sender window很小，当出现burst现象时，可能致使某条流整个的window都丢掉，引发timeout问题。<br><a id="more"></a></p>
<h4 id="iperf的问题"><a href="#iperf的问题" class="headerlink" title="iperf的问题"></a>iperf的问题</h4><p>由于服务器数量不够，只能通过测试工具iperf多开一些流，发现iperf开的流数量小于20条时还很正常，但到达30条及以上就会出现一些异常问题，如下图示：<br><img src="../../../../pictures/iperf/webwxgetmsgimg.png" alt=""><br>经分析，这个问题是iperf工具本身的设计bug，所以想到使用iperf3来试一试。</p>
<h4 id="iperf3的问题"><a href="#iperf3的问题" class="headerlink" title="iperf3的问题"></a>iperf3的问题</h4><p>iperf3从下载到安装倒是非常顺利，这里先给出源码下载及安装过程:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">$wget http://downloads.es.net/pub/iperf/iperf-3.1.3.tar.gz</div><div class="line">$tar zxvf iperf-3.1.3.tar.gz</div><div class="line">$cd iperf-3.1.3</div><div class="line">$./configure --prefix=/usr/local/bin/</div><div class="line">$make</div><div class="line">$make install</div></pre></td></tr></table></figure></p>
<p>但是当我通过iperf3 –version查看是否安装成功时，却出现了问题：<br><strong>问题一</strong><br>由于当时忘记了截图，只好手动复原一下问题<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">iperf3: error while loading shared libraries: libiperf.so.0: cannot open shared object file: No such file or directory</div></pre></td></tr></table></figure></p>
<p>提示当载入共享库Libiperf.so.0时，不能打开共享目标文件，估计是共享库不存在，于是我根据提示进行了调试，解决办法如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">$echo $LD_LIBRARY_PATH </div><div class="line"></div><div class="line">//如果上面的命令得到的是空，那就进行下面的操作</div><div class="line">$LD_LIBRATY_PATH=/usr/local/lib</div><div class="line">//进行下面这条操作的前提是你的/usr/local/bin/中有libiperf.so.0这个file</div><div class="line">$LD_LIBRARY_PATH=$LD_LIBRATY_PATH:/usr/local/bin/libiperf.so.0</div></pre></td></tr></table></figure></p>
<p>然后再试一试，效果如下：<br><img src="../../../../pictures/iperf/20170828084439.png" alt=""></p>
<p><strong>问题二</strong><br>经过上面的一番折腾，在一个client一个server的情况下，测试了同时开40条流和同时开80条流都很好。我满心欢喜的以为可以大干一场了，于是改为3个client，同时向一个server发包，but，but，Iperf3居然不支持many client to one server的情况，截图如下：<br><img src="../../../../pictures/iperf/20170828085457.png" alt=""><br>iperf都支持many client to one server，why，why，为什么升级版iperf3却不支持，那我的TCP Incast还重现个锤子，哎，只好自己写一个了。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;最近因为实验需要重现在data center networks中的TCP Incast问题，就是many client to one server发包，导致每条流分得的带宽很小，即sender window很小，当出现burst现象时，可能致使某条流整个的window都丢掉，引发timeout问题。&lt;br&gt;
    
    </summary>
    
      <category term="UNIX/LINUX" scheme="http://yoursite.com/categories/UNIX-LINUX/"/>
    
    
  </entry>
  
  <entry>
    <title>TCP重点系列之ACK处理</title>
    <link href="http://yoursite.com/2017/07/19/TCP%E9%87%8D%E7%82%B9%E7%B3%BB%E5%88%97%E4%B9%8BACK%E5%A4%84%E7%90%86/"/>
    <id>http://yoursite.com/2017/07/19/TCP重点系列之ACK处理/</id>
    <published>2017-07-19T13:15:25.000Z</published>
    <updated>2017-07-19T02:02:10.886Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;这篇博客介绍sender收到receiver发送过来的ACK后会怎么处理，这里主要介绍收到每一个ACK后的处理流程，后面的博客会具体介绍关于收到SACK后怎么处理，丢包后怎么处理等一系列过程。收到ACK包后都会进入到tcp_ack()函数，所以主要是介绍tcp_ack()函数。<br><a id="more"></a></p>
<h4 id="主要处理函数tcp-ack"><a href="#主要处理函数tcp-ack" class="headerlink" title="主要处理函数tcp_ack()"></a>主要处理函数tcp_ack()</h4><p>&emsp;&emsp;sender收到ACK后，主要是两种情况：一是按序ACK数据包，表明网络正常，这种情况下会走快速路径；另外一种情况是数据包没有被按序ACK，有可能是发生乱序或者丢包了，这种情况下会走慢速路径。下面就来看看源码吧！<br>@kernel version 4.10.13 /net/ipv4/tcp_input.c<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div></pre></td><td class="code"><pre><div class="line">* This routine deals with incoming acks, but not outgoing ones. */</div><div class="line">static int tcp_ack(struct sock *sk, const struct sk_buff *skb, int flag)</div><div class="line">&#123;</div><div class="line">    struct inet_connection_sock *icsk = inet_csk(sk);</div><div class="line">    struct tcp_sock *tp = tcp_sk(sk);</div><div class="line">    struct tcp_sacktag_state sack_state;</div><div class="line">    struct rate_sample rs = &#123;.prior_delivered = 0&#125;;</div><div class="line">    u32 prior_snd_una = tp-&gt;snd_una;</div><div class="line">    u32 ack_seq = TCP_SKB_CB(skb)-&gt;seq;</div><div class="line">    u32 ack = TCP_SKB_CB(skb)-&gt;ack_seq;</div><div class="line">    bool is_dupack = false;/* 定义布尔变量，判断是否是dupack */</div><div class="line">    u32 prior_fackets;</div><div class="line">    /* 保存上一次的packets_out值，packets_out表示发送还未确认的包个数 */</div><div class="line">    int prior_packets = tp-&gt;packets_out;</div><div class="line">    u32 delivered = tp-&gt;delivered;</div><div class="line">    u32 lost = tp-&gt;lost; /* 记录丢了多少个数据包 */</div><div class="line">    int acked = 0;  /* 记录ack多少个数据包 */</div><div class="line">    int rexmit = REXMIT_NONE;</div><div class="line">    struct skb_mstamp now;</div><div class="line"></div><div class="line">    sack_state.first_sackt.v64 = 0;</div><div class="line">    sack_state.rate = &amp;rs;</div><div class="line"></div><div class="line">    /* 用于访问写队列的队头 */</div><div class="line">    prefetch(sk-&gt;sk_write_queue.next);</div><div class="line"></div><div class="line">    /* If the ack is older than previous acks</div><div class="line">     * then we can probably ignore it.</div><div class="line">     * 如果ACK的数据包已经被ACK过，表明这是一个旧ACK，忽略即可</div><div class="line">     */</div><div class="line">    if (before(ack, prior_snd_una)) &#123;</div><div class="line">        /* RFC 5961 5.2 [Blind Data Injection Attack].[Mitigation] */</div><div class="line">        if (before(ack, prior_snd_una - tp-&gt;max_window)) &#123;</div><div class="line">            tcp_send_challenge_ack(sk);</div><div class="line">            return -1;</div><div class="line">        &#125;    </div><div class="line">        goto old_ack;</div><div class="line">    &#125;    </div><div class="line"></div><div class="line">    /* If the ack includes data we haven&apos;t sent yet, discard</div><div class="line">     * this segment (RFC793 Section 3.9).</div><div class="line">     * 如果ACK了尚未发送的包，这是一个无效的ACK</div><div class="line">     */</div><div class="line">    if (after(ack, tp-&gt;snd_nxt))</div><div class="line">        goto invalid_ack;</div><div class="line"></div><div class="line">    /* 获取当前时间戳，老版本中没见过，应该是后来打补丁加的 */</div><div class="line">    skb_mstamp_get(&amp;now); </div><div class="line"></div><div class="line">    /* icsk_pending在函数inet_connection_sock.h内的结构体inet_connection_sock&#123;&#125;</div><div class="line">     * 中定义，调度定时器事件（scheduled timer event）。下面列出定时器的标志：</div><div class="line">     * #define ICSK_TIME_RETRANS 1 /* 重传定时器 */</div><div class="line">     * #define ICSK_TIME_DACK 2 /* ack延迟定时器 */</div><div class="line">     * #define ICSK_TIME_PROBEO 3 /* 零窗口探测定时器 */</div><div class="line">     * #define ICSK_TIME_EARLY_RETRANS 4 /* ER延迟定时器 */</div><div class="line">     * #define ICSK_TIME_LOSS_PROBE 5 /* 尾丢失探测（PTO）定时器 */ </div><div class="line">     */</div><div class="line">    if (icsk-&gt;icsk_pending == ICSK_TIME_EARLY_RETRANS ||</div><div class="line">        icsk-&gt;icsk_pending == ICSK_TIME_LOSS_PROBE)</div><div class="line">        tcp_rearm_rto(sk); /* 删除或重启重传定时器 */</div><div class="line"></div><div class="line">    /* ACK了新的数据，打上FLAG_SND_UNA_ADVANCED标记，表明snd_una将向前移动。 */</div><div class="line">    if (after(ack, prior_snd_una)) &#123;</div><div class="line">        flag |= FLAG_SND_UNA_ADVANCED;</div><div class="line">        icsk-&gt;icsk_retransmits = 0;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    prior_fackets = tp-&gt;fackets_out;</div><div class="line">    /* in_flight = packets_out - left_out + retrans_out</div><div class="line">     * left_out = sacked_out + lost_out. </div><div class="line">     * in_fligth表示当前发出还没被ack的包的个数</div><div class="line">     */</div><div class="line">    rs.prior_in_flight = tcp_packets_in_flight(tp); </div><div class="line"></div><div class="line">    /* ts_recent update must be made after we are sure that the packet</div><div class="line">     * is in window.</div><div class="line">     */</div><div class="line">    if (flag &amp; FLAG_UPDATE_TS_RECENT)</div><div class="line">        tcp_replace_ts_recent(tp, TCP_SKB_CB(skb)-&gt;seq);</div><div class="line"></div><div class="line">    /* ACK了新包，不处于SLOWPATH，即处于快速路径， */</div><div class="line">    if (!(flag &amp; FLAG_SLOWPATH) &amp;&amp; after(ack, prior_snd_una)) &#123;</div><div class="line">        /* Window is constant, pure forward advance.</div><div class="line">         * No more checks are required.</div><div class="line">         * Note, we use the fact that SND.UNA&gt;=SND.WL2.</div><div class="line">         */</div><div class="line">        tcp_update_wl(tp, ack_seq);/* 函数内容是tp-&gt;snd_wl1 = ack_seq */</div><div class="line">        tp-&gt;snd_una = ack;/* 更新snd_una */</div><div class="line">        flag |= FLAG_WIN_UPDATE;/* 打上更新标志 */</div><div class="line"></div><div class="line">        tcp_in_ack_event(sk, CA_ACK_WIN_UPDATE);/* 接收窗口被更新了 */</div><div class="line">        /* 这是一个在include/net/ip.h里定义的宏，具体我也不清楚 */</div><div class="line">        NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPHPACKS);</div><div class="line">    &#125; else &#123;/* 如果处于SLOWPATH */</div><div class="line">        u32 ack_ev_flags = CA_ACK_SLOWSPATH;//表明有丢包，需要进入慢速处理过程</div><div class="line">        if (ack_seq != TCP_SKB_CB(skb)-&gt;end_seq)/* 此ACK携带了数据 */</div><div class="line">            flag |= FLAG_DATA; /* 打上FLAG_DATA标记 */</div><div class="line">        else</div><div class="line">            NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPPUREACKS);</div><div class="line"></div><div class="line">        /* 一个更新send window的函数，详细更新算法参见RFC793/RFC1122</div><div class="line">         * 如果满足更新条件，会给flag打上FLAG_WIN_UPDATE标记。</div><div class="line">         */</div><div class="line">        flag |= tcp_ack_update_window(sk, skb, ack, ack_seq);</div><div class="line"></div><div class="line">        if (TCP_SKB_CB(skb)-&gt;sacked)/* 如果是一个sack */</div><div class="line">            /* 处理SACK的函数，此函数较复杂，将在blog[]()中详细介绍 */</div><div class="line">            flag |= tcp_sacktag_write_queue(sk, skb, prior_snd_una， &amp;sack_state);    </div><div class="line"></div><div class="line">        /* 判断是否拥塞，由路由器在IP头中标记  */</div><div class="line">        if (tcp_enc_rcv_ecn_echo(tp, tcp_hdr(skb))) </div><div class="line">            flag |= FLAG_ECE;/* 显示拥塞标志 */</div><div class="line"></div><div class="line">        tcp_in_ca_event(sk, ack_ev_flags); /* 慢速路径事件钩子 */</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    /* We passed data and got it acked, remove any soft error</div><div class="line">     * log. Something worked...</div><div class="line">     */</div><div class="line">    sk-&gt;sk_err_soft = 0;</div><div class="line">    icsk-&gt;icsk_probes_out = 0;</div><div class="line">    tp-&gt;rcv_tstamp = tcp_time_stamp;</div><div class="line">    if (!prior_packets)</div><div class="line">        goto no_queue;</div><div class="line"></div><div class="line">    /* See if we can take anything off of the retransmit queue. */</div><div class="line">    previous_packets_out = tp-&gt;packets_out;/* 保存清理前的值 */</div><div class="line"></div><div class="line">    /* 清理重传队列中已被确认接收的包，并返回flag标记，此函数会在后面的blog中做详细介绍 */</div><div class="line">    flag |= tcp_clean_rtx_queue(sk, prior_fackets, prior_snd_una， &amp;acked, &amp;sack_state, &amp;now);</div><div class="line"></div><div class="line">     /* 判断此ACK是否可疑，可疑的条件会在下面说明 */</div><div class="line">    if (tcp_ack_is_dubious(sk, flag)) &#123;</div><div class="line">        /* 根据flag判断是否dupack，整个条件是说snd_una没有更新，</div><div class="line">         * 且是一个duplicate ack 。</div><div class="line">         */</div><div class="line">        is_dupack = !(flag &amp; (FLAG_SND_UNA_ADVANCED | FLAG_NOT_DUP));</div><div class="line">        /* 如果判断有丢包，就进行快速重传 */</div><div class="line">        tcp_fastretrans_alerk(sk, acked, is_dupack, &amp;flag, &amp;rexmit);</div><div class="line">    &#125;</div><div class="line">    if (tp-&gt;tlp_high_seq)</div><div class="line">        tcp_process_tlp_ack(sk, ack, flag);</div><div class="line"></div><div class="line">    if (flag &amp; FLAG_FORWARD_PROGRCESS || !(flag &amp; FLAG_NOT_DUP)) &#123;</div><div class="line">        struct dst_entry *dst = __sk_dst_get(sk);</div><div class="line">        if (dst)</div><div class="line">            dst_confirm(dst);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    if (icsk-&gt;icsk_pending == ICSK_TIME_RETRANS)</div><div class="line">        tcp_schedule_loss_prode(sk);</div><div class="line">    delivered = tp-&gt;delivered - delivered;</div><div class="line">    lost = tp-&gt;lost - lost;</div><div class="line">    tcp_rate_gen(sk, delivered, lost, &amp;now, &amp;rs);</div><div class="line">    tcp_cong_control(sk, ack, delivered, flag, &amp;rs);</div><div class="line">    tcp_xmit_recorery(sk, rexmit);</div><div class="line">    return 1;</div><div class="line"></div><div class="line">no_queue:</div><div class="line">    /* If data was DSACKed, see if we can undo a cwnd reduction. */</div><div class="line">    if (flag &amp; FLAG_DSACKING_ACK)</div><div class="line">        tcp_fastretrans_alert(sk, acked, is_dupack, &amp;flag, &amp;rexmit);</div><div class="line">    /* If this ack opens up a zero window, clear backoff.  It was</div><div class="line">     * being used to time the probes, and is probably far higher than</div><div class="line">     * it needs to be for normal retransmission.</div><div class="line">     */</div><div class="line">    if (tcp_send_head(sk))</div><div class="line">        tcp_ack_probe(sk);</div><div class="line"></div><div class="line">    if (tp-&gt;tlp_high_seq)</div><div class="line">        tcp_process_tlp_ack(sk, ack, flag);</div><div class="line">    return 1;</div><div class="line">/* 下面分别是对无效ACK和旧ACK的处理，就不做过多介绍。 */</div><div class="line">invalid_ack:</div><div class="line">    SOCK_DEBUG(sk, &quot;Ack %u after %u:%u\n&quot;, ack, tp-&gt;snd_una, tp-&gt;snd_nxt);</div><div class="line">    return -1;</div><div class="line"></div><div class="line">old_ack:</div><div class="line">    /* If data was SACKed, tag it and see if we should send more data.</div><div class="line">     * If data was DSACKed, see if we can undo a cwnd reduction.</div><div class="line">     */</div><div class="line">    if (TCP_SKB_CB(skb)-&gt;sacked) &#123;</div><div class="line">        flag |= tcp_sacktag_write_queue(sk, skb, prior_snd_una);</div><div class="line">        tcp_fastretrans_alert(sk, acked, is_dupack, &amp;flag, &amp;rexmit);</div><div class="line">        tcp_xmit_recovery(sk, rexmit);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    SOCK_DEBUG(sk, &quot;Ack %u before %u:%u\n&quot;, ack, tp-&gt;snd_una, tp-&gt;snd_nxt);</div><div class="line">    return 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h4 id="部分相关函数"><a href="#部分相关函数" class="headerlink" title="部分相关函数"></a>部分相关函数</h4><p>&emsp;&emsp;这里给出部分在tcp_ack()调用到的比较重要的函数，还有一些会在以后的博客中介绍。<br>获取当前时间戳<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">static inline void skb_mstamp_get(struct skb_mstamp *cl)</div><div class="line">&#123;</div><div class="line">    u64 val = local_clock();</div><div class="line"></div><div class="line">    do_div(val, NSEC_PER_USEC); /* 单位换算 */</div><div class="line">    cl-&gt;stamp_us = (u32)val;</div><div class="line">    cl-&gt;stamp_jiffies = (u32)jiffies;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>枚举变量<br>/<em> Information about inbound ACK, passed to cong_ops-&gt;in_ack_event() </em>/<br>enum tcp_ca_ack_event_flags {<br>    CA_ACK_SLOWSPATH  = (1&lt;&lt;0),    /<em> In slow path processing </em>/<br>    CA_ACK_WIN_UPDATE = (1&lt;&lt;0),    /<em> ACK updated window </em>/<br>    CA_ACK_ECE        = (1&lt;&lt;2),    /<em> ECE bit is set on ack </em>/<br>};</p>
<p>封装调用函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">static inline void tcp_in_ack_event(struct sock *sk, u32 flags)</div><div class="line">&#123;</div><div class="line">    const struct inet_connection_sock *icsk = inet_csk(sk);</div><div class="line"></div><div class="line">    if (icsk-&gt;icsk_ca_ops-&gt;in_ack_event)</div><div class="line">        /* in_ack_event()函数的声明在include/net/tcp.h文件内的结构体tcp_congestion_ops &#123;&#125;中 */</div><div class="line">        icsk-&gt;icsk_ca_ops-&gt;in_ack_event(sk, flags); </div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;这篇博客介绍sender收到receiver发送过来的ACK后会怎么处理，这里主要介绍收到每一个ACK后的处理流程，后面的博客会具体介绍关于收到SACK后怎么处理，丢包后怎么处理等一系列过程。收到ACK包后都会进入到tcp_ack()函数，所以主要是介绍tcp_ack()函数。&lt;br&gt;
    
    </summary>
    
      <category term="TCP/IP" scheme="http://yoursite.com/categories/TCP-IP/"/>
    
    
  </entry>
  
  <entry>
    <title>TCP拥塞控制之：BBR</title>
    <link href="http://yoursite.com/2017/05/25/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E4%B9%8BBBR/"/>
    <id>http://yoursite.com/2017/05/25/TCP拥塞控制之BBR/</id>
    <published>2017-05-25T06:49:05.000Z</published>
    <updated>2017-07-19T12:32:06.008Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;BBR是Google在2016年提出的一种拥塞控制算法，在Linux kernel@4.9及以后的版本中已添加该算法。在Google通过paper将BBR公布前，BBR算法应该在Google自家World Area Network中早已投入使用。Google后来提出基于SDN的B4网络（paper叫做B4，很有名的一篇paper），其拥塞控制算法也是使用的BBR。<br><a id="more"></a><br>&emsp;&emsp;丢包即拥塞的思想已经沿用了很多年，很多拥塞控制算法也是基于此的，比如当前Linux kernel的默认拥塞控制算法CUBIC，还有Reno和FAST TCP等，都是基于这一思想进行的拥塞控制。在技术受限的年代，这一思想（丢包即拥塞）没有错，但是，现在，当NIC（network interface controllers）的处理能力从Mbps升级到Gpbs，memory chips从KB升级到GB，拥塞和丢包的关系就没那么紧密了。<br>&emsp;&emsp;在现在high BDP网络环境下，丢包即拥塞思想带来的问题包括：当因为bottelneck buffers满而出现丢包时，会引起bufferbloat现象，网络延迟高；但是，当bottleneck buffers很小时，这时出现丢包，网络会误认为是发生了拥塞，从而降低发送窗口，这样就会造成low throughput。想要解决上面的问题，那么就需要抛弃基于丢包的拥塞控制思想，换个新的。</p>
<p><img src="../../../../pictures/paper read/20170525154759.png" alt=""><br>&emsp;&emsp;上图其实是两个图，只不过有共同的横坐标，想当初弱智的我看了半天，才明白这是两个图。图中的一些符号解释如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">RTprop = round-trip propagation</div><div class="line">BtlBw = bottleneck bandwidth</div><div class="line">blue lines show the RTprop constraint;</div><div class="line">green lines show the BtlBw constraint;</div><div class="line">red lines show the bottleneck buffer;</div></pre></td></tr></table></figure></p>
<p>基于丢包的拥塞控制如图中指出的那样，其作用域在bandwidth limited，这时bottleneck buffers慢慢被填满，最后导致buffer溢出，出现丢包。在早前，memory价格较贵时，buffer sizes约等于一个link BDP，现在由于技术的进步，memory价格一直下降，buffer sizes越来越大，都快高出link BDP一个数量级。这样，delay也由以前的milliseconds升到了seconds，自然也带来了bufferbloat（缓冲区爆满，排队延迟影响网络整体性能）。其实之前有paper专门针对bottelneck buffer设置为多大给出了其研究结果，等于一个link BDP是最好的。</p>
<h3 id="Characterizing-the-bottleneck"><a href="#Characterizing-the-bottleneck" class="headerlink" title="Characterizing the bottleneck"></a>Characterizing the bottleneck</h3><p>&emsp;&emsp;要达到highest throughput和lowest delay，connection必须同时满足两个条件：</p>
<blockquote>
<ol>
<li>the bottleneck packet arrival rate equals BtlBw;</li>
<li>the total data in flight is equal to the BDP(BtlBw*Rtprop);</li>
</ol>
</blockquote>
<p>第一个条件保证bottelneck被100%的利用，第二个条件防止bottleneck出现饥饿，但又不会溢出。<br>&emsp;&emsp;因为$BtlBw$和$PTprop$在整个过程中一直是变动的，所以需要一直不断的测量。在任何时刻$t$，<br>$$RTT_t = RTprop_t + \eta_t$$<br>这里$\eta&gt;=0$表示‘noise’，比如接收端的延迟ack策略，ack aggregation策略等。因此$RTprop$是不可能准确测量的，只能估算，像大多数算法测量最小$RTT$做的那样：<br>$$\hat{RT}prop = RTprop + min(\eta_t) = min(RTT_t)$$<br>&emsp;&emsp;根据从receiver返回的ack，我们可以知道当前ack确认数据包的$RTT$和离开sender留存在网络中的确切数据包数。因为我们可以准确知道当前的发送序号snd_nxt，以及其确认序号snd_una，如果开启了SACK也可以准确知道，只不过需要walk一遍SACK段。这样我们便可以测量平均delivery rate:$deliveryRate = \Delta delivered/\Delta t$。在这个过程中delivered是可以准确知道的，而$\Delta t$则会大于真实interval，因为受网络噪声的影响，所以$delivery rate &lt;= bottleneck rate$，那么我们可以这样评估BtlBw:<br>$$\hat{BtlBw} = max(deliveryRate_t)$$</p>
<h3 id="MATCHING-THE-PACKET-FLOW-TO-THE-DELIVERY-PATH"><a href="#MATCHING-THE-PACKET-FLOW-TO-THE-DELIVERY-PATH" class="headerlink" title="MATCHING THE PACKET FLOW TO THE DELIVERY PATH"></a>MATCHING THE PACKET FLOW TO THE DELIVERY PATH</h3><p>The core BBR algorithm has two parts:</p>
<h4 id="When-an-ack-is-received"><a href="#When-an-ack-is-received" class="headerlink" title="When an ack is received"></a>When an ack is received</h4><p>&emsp;&emsp;每一个ack都会提供一个新的RTT和delivery rate值，用来更新$RTprop$和$BtlBw$，伪代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">function onAck(packet)</div><div class="line">    rtt = now - packet.sendtime</div><div class="line">    update_min_filter(RTpropFilter, rtt)</div><div class="line">    delivery_time = now</div><div class="line">    deliveryRate = (delivered - packet.delivered)/(now - packet.delivered_time)</div><div class="line">    if (deliveryRate &gt; BtlBwFilter.curentMax || !packet.app_limited)</div><div class="line">        update_max_filter(BtlBwFilter, deliveryRate)</div><div class="line">    if (app_limited_until &gt; 0)</div><div class="line">        app_limited_until -= packet.size</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;在数据传输过程中，senders可能成为application limited，也就是application有机会发送更多的数据，但是没有数据可以发送，这是一个很普遍的现象。</p>
<h4 id="When-data-is-sent"><a href="#When-data-is-sent" class="headerlink" title="When data is sent"></a>When data is sent</h4><p>&emsp;&emsp;为了使packet-arrival rate和bottleneck link’s departure rate相匹配，BBR必须paces每一个数据包。pacing_rate是BBR的主要控制参数，另外一个参数是cwnd_gain，用来限定inflight为小倍数的BDP，伪代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">function send(packet)</div><div class="line">    bdp = BtlBwFilter.currentMax*RTpropFilter.currentMin</div><div class="line">    if (inflight &gt;= cwnd_gain*bdp)</div><div class="line">        //wait for ack or timeout</div><div class="line">        return</div><div class="line">    if (now &gt;= nextSendTime)</div><div class="line">        packet = nextPacketToSend()</div><div class="line">        if (!packet)</div><div class="line">            app_limited_until = inflight</div><div class="line">            return</div><div class="line">        packet.app_limited = (app_limited_until &gt; 0)</div><div class="line">        packet.sendtime = now</div><div class="line">        packet.delivered = delivered</div><div class="line">        packet.delivered_time = delivered_time</div><div class="line">        ship(packet)</div><div class="line">        nextSendTime = now + packet.size/(pacing_gain * BtlBwFilter.currentMax)</div><div class="line">    timerCallbackAt(send, nextSendTime)</div></pre></td></tr></table></figure></p>
<h4 id="Steady-state-behavior"><a href="#Steady-state-behavior" class="headerlink" title="Steady-state behavior"></a>Steady-state behavior</h4><p>&emsp;&emsp;由上面可知，测量$BtlBw$和$RTprop$都有独立的函数去完成，在bottleneck的约束下会形成一个控制循环，那么带来的效果如下图所示：<br><img src="../../../../pictures/paper read/20170620164658.png" alt=""><br>图中蓝线是RTT， 绿线是inflight，红线代表delivery rate，delivery rate上方的粗灰线表示BtlBw max filter的状态。<br>&emsp;&emsp;BBR通过保证inflight大多数时候为一个BDP来最小化delay。这样bottleneck就被转移到了sender，因为sender看不到BtlBw的变化，因此BBR需要周期性的通过pacing_gain &gt; 1来测量BtlBw是否变化，当发现形成queueing delay时， 将pacing_gain设为小于1便可消除queueing delay。<br>&emsp;&emsp;BBR除了探测网络带宽是否变化外，还会周期性的探测往返传播延迟（RTProp），因为要考虑到传输路径等一些其他能影响到传播延迟的因素。每收到一个ack都会更新RTProp，但当RTProp有一段时间（比如10s）没更新了，BBR便会进入探测RTT模式，其探测方式主要是通过将inflight减少为4个数据包（比如设置cwnd=4），这种状态维持至少一个往返延迟，然后回到探测前的状态。需要注意的是并不是只对一条数据流这样设置来探测，而是所有的数据流一起进入探测模式。</p>
<h3 id="BBR自己的状态机"><a href="#BBR自己的状态机" class="headerlink" title="BBR自己的状态机"></a>BBR自己的状态机</h3><p>首先给出其状态切换图<br><img src="../../../../pictures/state/20170719170709.png" alt=""><br>&emsp;&emsp;google的BBR是一种对丢包不敏感的拥塞控制算法，理论上它是不care外部的TCP拥塞状态（loss, recovery）的，它只根据自己测量的即时rate来调整cwnd的大小，即BBR只负责发送多少数据包，至于发哪些数据包它不管。而传统的拥塞控制算法，当碰到丢包时，网络便交给了快速恢复算法（比如PRR）接管，拥塞控制算法是不能插足的，直到重传结束返回到open状态。所以当网络丢包率比较大的时候，网络可能一直处于重传阶段，而CUBIC可能就短暂的接管过网络，之后一直是PRR接管，造成带宽利用率低下。<br>&emsp;&emsp;BBR自己的状态机的PROBE_RTT保证即时探测min rtt，从而保证网络的低延迟；而PROBE_BW保证即时探测网络带宽变化，从而保证充分利用带宽；DRAIN保证STARTUP结束时带来的queueing delay即时被排空。<br>&emsp;&emsp;还有一点需要注意的是BBR没有ssthresh，因为根据计算的delivery rate就可以大致推断sender的发送速率是否达到网络带宽上限。</p>
<p><strong>总结</strong><br>&emsp;&emsp;其实BBR的思想和CUBIC相比很简单，其最终的效果据google自己说很好。本人在自己搭建的环境中，在同样的参数下，对比过CUBIC和BBR，快速恢复算法都使用的PRR，BBR明显的比CUBIC要好。但没有实际跑过和vegas、westwood等传统的拥塞控制算法做对比。不过各类拥塞控制算法都有其适用环境，具体看需求。</p>
<p><strong>参考文献：</strong><br><a href="http://delivery.acm.org/10.1145/3030000/3022184/p50-vanjacobson.pdf?ip=159.226.43.30&amp;id=3022184&amp;acc=OPEN&amp;key=33E289E220520BFB%2ED25FD1BB8C28ADF7%2E4D4702B0C3E38B35%2E6D218144511F3437&amp;CFID=950630525&amp;CFTOKEN=77242094&amp;__acm__=1497963804_1df76caeda50f66015a40a5651745817" target="_blank" rel="external">BBR Congestion-Based Congestion Control</a><br><a href="http://an.kaist.ac.kr/courses/2009/cs540/papers/Nick.pdf" target="_blank" rel="external">Sizing Router Buffers</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;BBR是Google在2016年提出的一种拥塞控制算法，在Linux kernel@4.9及以后的版本中已添加该算法。在Google通过paper将BBR公布前，BBR算法应该在Google自家World Area Network中早已投入使用。Google后来提出基于SDN的B4网络（paper叫做B4，很有名的一篇paper），其拥塞控制算法也是使用的BBR。&lt;br&gt;
    
    </summary>
    
      <category term="私人文献阅读" scheme="http://yoursite.com/categories/%E7%A7%81%E4%BA%BA%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/"/>
    
    
  </entry>
  
  <entry>
    <title>TCP拥塞控制之：FAST TCP</title>
    <link href="http://yoursite.com/2017/05/18/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E4%B9%8BFASTTCP/"/>
    <id>http://yoursite.com/2017/05/18/TCP拥塞控制之FASTTCP/</id>
    <published>2017-05-18T11:11:52.000Z</published>
    <updated>2017-05-22T01:46:18.005Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;经典的TCP拥塞控制算法TCP Reno从被提出后很长一段时间一直作为Linux kernel的默认算法，但随着Internet在规模、传输速度、负载、连接数上的增长，TCP Reno迟早会成为性能瓶颈。<br><a id="more"></a></p>
<h3 id="问题与背景"><a href="#问题与背景" class="headerlink" title="问题与背景"></a>问题与背景</h3><p>&emsp;&emsp;当前的Linux kernel的默认拥塞控制算法是于2008年提出的CUBIC，本文介绍的FAST TCP算法于2004年被提出，主要针对高速和长延迟网络，虽然有点老，但还是可以了解了解的。原文主要是和TCP Reno作比较，所以提出的问题也是针对TCP Reno的（时代所限制，如果是现在提出的算法多半是要和CUBIC作比较的）。</p>
<h4 id="TCP-Reno的问题"><a href="#TCP-Reno的问题" class="headerlink" title="TCP Reno的问题"></a>TCP Reno的问题</h4><p>&emsp;&emsp;TCP Reno在large bandwidth-delay products网络上表现差主要体现在以下四个方面（摘自原文）：</p>
<blockquote>
<ol>
<li>At the packet level, linear increase by one packet per Pound-Trip Time(RTT) is too slow, and multiplicative decrease per loss event is too drastic.</li>
<li>At teh flow level, maintaining large average congestion windows requires an extremely small equilibrium loss probability.</li>
<li>At the packet level, oscillation is unavoidable because TCP uses a binary congestion sigmal(packet loss).</li>
<li>At the flow level, the dynamics is unstable leading to severe oscillations that can only be reduced by the accurate estimation of packet loss probability and a stable design of the flow dynamics.</li>
</ol>
</blockquote>
<p>&emsp;&emsp;在前人的工作中有很多算法是基于丢包检测提出的，比如HSTCP和STCP，而FAST TCP是通过测量queueing delay来作为网络拥塞程度的参考。</p>
<h4 id="flow-level和packet-level的区别"><a href="#flow-level和packet-level的区别" class="headerlink" title="flow level和packet level的区别"></a>flow level和packet level的区别</h4><p>&emsp;&emsp;一个拥塞控制算法可以从两个level(flow level and packet level)去设计。flow level相比于packet level是一个宏观上的概念，其设计目标是达到高带宽利用率、低排队延迟和丢包、公平和稳定。而packet level是通过端到端控制的约束来设计实施那些flow level的目标。</p>
<h3 id="FAST-TCP的设计"><a href="#FAST-TCP的设计" class="headerlink" title="FAST TCP的设计"></a>FAST TCP的设计</h3><p>&emsp;&emsp;在说FAST TCP的设计之前先来看一个方程；<br>$$\check{w}_i(t) = \kappa_i(t)(1 - \frac{p_i(t)}{u_i(t)})\label{eq.Sample}$$<br>方程（1）可以用来描述各种已知的TCP拥塞控制算法，不同的拥塞控制算法的区别在于它们对gain function$\kappa_i$和marginal utility function$u_i$以及congestion measures $p_i$是丢失率还是排队延迟。<br>&emsp;&emsp;当然啦，FAST TCP与其他的拥塞控制算法的区别也是在那三个函数的选择上。下面对这三个函数的作用简单介绍下（还是摘自原文，翻译真的很麻烦）。</p>
<blockquote>
<p><strong>$\kappa_i$:</strong> the choice of the gain function $\kappa_i$ determines the dynamic properties sush as stability and responsiveness, but does not affect the equilibrium properties.<br><strong>$u_i$:</strong> the choice of the marginal utility function $u_i$ mainly determines equilibrium properties such as the equilibrium rate allocation and its fairness.<br><strong>$p_i$:</strong> in the absence of explicit feedback, the choice of congestion measure $p_i$ is limited to loss probability or queueing delay. The dynamics of $p_i(t)$ is determined at links.</p>
</blockquote>
<h4 id="implementation-strategy"><a href="#implementation-strategy" class="headerlink" title="implementation strategy"></a>implementation strategy</h4><p>&emsp;&emsp;FAST TCP 通过适当的flow and packet level 设计来解决上文提到的TCP Reno 在large windows环境下所遇到的四个问题。<br>&emsp;&emsp;首先，评估当前状态$\frac{p_i(t)}{u_i(t)}$距equilibrium（值为1）有多远，如果当前状态接近于equilibrium，那么就缓慢调整window，反之，则激进一点调整。而在TCP Reno中，其窗口调整取决于当前窗口大小。基于delay的方法避免了在TCP Reno中window缓慢增长，迅速下降的问题。<br>&emsp;&emsp;其次，选择一个multi-bit 的拥塞测试，消除由于binary feedback造成的packet level oscillation。这里binary feedback表示window要么增，要么降，没有其他选择。<br>&emsp;&emsp;最后，拥塞测量函数$p_i(t)$采用测量queueing delay而不是测量loss probability，通过调整window从而控制queueing delay可以使网络稳定在overflowing point的下方区域，如下图（b）中的F点。这样既消除了高queueing<br>delay，又避免了不必要的数据包丢失。更重要的是，这样还保留了root for buffering “mice” traffic。<br><img src="../../../../pictures/TCP/20170519171625.png" alt=""></p>
<h3 id="FAST-TCP的架构和算法"><a href="#FAST-TCP的架构和算法" class="headerlink" title="FAST TCP的架构和算法"></a>FAST TCP的架构和算法</h3><p>&emsp;&emsp;在FAST TCP这篇paper中， 将TCP拥塞控制机制分割成了四部分，这四部分功能相互独立，以便能够设计分离和异步升级。如下图所示，FAST TCP的架构。<br><img src="../../../../pictures/TCP/20170520104134.png" alt=""><br>&emsp;&emsp;其中，data control 部分决定发送那些数据包，window contorl部分决定可以发多少数据包，burstiness control决定什么时候发送这些数据包，上述决定都是在estimation部分提供的信息的基础上做出的。这里只说一下estimation和window control。</p>
<h4 id="Estimation"><a href="#Estimation" class="headerlink" title="Estimation"></a>Estimation</h4><p>&emsp;&emsp;对于每一个被发送的数据包，estimation部分计算两类反馈信息。当收到一个正常的ACK，计算出相应数据包的RTT，更新平均queueing delay和最小RTT。当收到一个乱序ACK（三个dupack或者timeout），estimation会将数据包的丢失信息报告给其他部分。estimation既可以进行multi-bit的queueing delay采样，也可以进行ont-bit的loss-or-no-loss采样。<br>最后得到的RTT一般都会采用加权移动平均处理，FAST TCP也不例外，$T_i(k)$表示第k个RTT的样本值，$\overline{T}_i(k)$，平均RTT的更新公式如下：<br>$$\overline{T}_i(k+1) = (1 - \eta)\overline{T}_i(k) + \etaT_i(k)$$<br>这里，$t_k$表示收到第k个RTT样本值的时间，$\eta$为加权值。记$d_i(k)$为到目前为止的最小RTT，那么平均queueing delay的计算公式如下：<br>$$\hat{q}_i(k) = \overline{T}_i(k) - d_i(k)$$</p>
<h4 id="Window-control"><a href="#Window-control" class="headerlink" title="Window control"></a>Window control</h4><p>&emsp;&emsp;window control会根据estimation提供的拥塞信息（queueing delay and packet loss）来决定拥塞窗口的调整。FAST TCP不同于传统TCP的关键在于其对拥塞窗口的计算与sender state是独立的。<br>&emsp;&emsp;在正常情况下，根据estimation提供的平均RTT和平均queueing delay，FAST TCP会周期性的更新其拥塞窗口$CWnd$。 更新公式如下：<br>$$w &lt;— min\lbrace2w, (1-\gamma)w + \gamma(\frac{baseRTT}{RTT}w + \alpha(w, qdelay))\rbrace$$<br>这里，$\gamma\in(0, ]$，qdelay是端到端的平均queueing delay。</p>
<p>&emsp;&emsp;这篇博客只是对原文基本思想的表述，还有许多细节问题没有提到，有兴趣的朋友可以考虑看看原文，原文地址在博客的参考文献中给出。</p>
<p><strong>参考文献</strong><br><a href="http://infocom2004.ieee-infocom.org/Papers/52_2.PDF" target="_blank" rel="external">FAST TCP: Motivation, Architecture, Algorithms, Performance</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;经典的TCP拥塞控制算法TCP Reno从被提出后很长一段时间一直作为Linux kernel的默认算法，但随着Internet在规模、传输速度、负载、连接数上的增长，TCP Reno迟早会成为性能瓶颈。&lt;br&gt;
    
    </summary>
    
      <category term="私人文献阅读" scheme="http://yoursite.com/categories/%E7%A7%81%E4%BA%BA%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/"/>
    
    
  </entry>
  
  <entry>
    <title>TCP拥塞算法之：Vegas</title>
    <link href="http://yoursite.com/2017/05/18/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E4%B9%8BVegas/"/>
    <id>http://yoursite.com/2017/05/18/TCP拥塞控制之Vegas/</id>
    <published>2017-05-17T17:06:38.000Z</published>
    <updated>2017-09-14T00:00:10.705Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;vegas是一种主动调整cwnd的拥塞控制算法，主要思想是设置两个阈值,alpha和beta,然后通过计算目标速率(Expected)和实际速率(Actual)差(diff)，再比较diff与alpha和beta的关系，对cwnd进行调节。vegas这篇paper的主要贡献是提供了一种拥塞检测的方法。<br><a id="more"></a></p>
<h3 id="区分拥塞还是非拥塞状态"><a href="#区分拥塞还是非拥塞状态" class="headerlink" title="区分拥塞还是非拥塞状态"></a>区分拥塞还是非拥塞状态</h3><h4 id="定义理论速率Expected和实际速率Actual："><a href="#定义理论速率Expected和实际速率Actual：" class="headerlink" title="定义理论速率Expected和实际速率Actual："></a>定义理论速率Expected和实际速率Actual：</h4><p>$$Expected = cwnd/BaseRTT$$<br>$$Actual = cwnd/RTT$$<br>这里cwnd是当前的TCP窗口大小，BaseRTT是测量的最小往返时间，RTT是所测量的经平滑后的往返时间。</p>
<h4 id="定义速率差Diff"><a href="#定义速率差Diff" class="headerlink" title="定义速率差Diff"></a>定义速率差Diff</h4><p>$$Diff = Expected - Actual$$<br>$$diff = Diff*baseRTT$$</p>
<h4 id="设置alpha和beta的值："><a href="#设置alpha和beta的值：" class="headerlink" title="设置alpha和beta的值："></a>设置alpha和beta的值：</h4><pre><code>alpha = 2;
beta = 4;
</code></pre><h3 id="基于链路状态的拥塞控制"><a href="#基于链路状态的拥塞控制" class="headerlink" title="基于链路状态的拥塞控制"></a>基于链路状态的拥塞控制</h3><h4 id="慢开始算法-cwnd-lt-ssthresh"><a href="#慢开始算法-cwnd-lt-ssthresh" class="headerlink" title="慢开始算法(cwnd &lt;= ssthresh)"></a>慢开始算法(cwnd &lt;= ssthresh)</h4><p>&emsp;&emsp;慢开始算法同Reno算法的慢开始的处理方法一样，每收到一个ACK，cwnd加1，这样cwnd会程指数增长，即每经过一个RTT，<br>    $$cwnd = cwnd*2$$</p>
<h4 id="自适应增长算法-cwnd-gt-ssthresh"><a href="#自适应增长算法-cwnd-gt-ssthresh" class="headerlink" title="自适应增长算法(cwnd &gt; ssthresh)"></a>自适应增长算法(cwnd &gt; ssthresh)</h4><p>Reno的处理方法:<br>对于cwnd而言，会设置一个ssthresh(slow-start threshold)来控制cwnd的增长。<br>当cwnd &gt;ssthresh，会降低cwnd的增长速度，避免出现拥塞(congestion)具体的控制方法是，每经过一个RTT，<br>    $$cwnd = cwnd + 1$$<br>也可以这样理解，每收到一个ACK，<br>    $$cwnd = cwnd + 1/cwnd$$</p>
<p>vegas的处理方法:<br>当cwnd &gt; ssthresh时<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">if (diff &lt; alpha)</div><div class="line">set: cwnd = cwnd + 1 //每收到一个ACK</div><div class="line">else if (diff &gt;= beta)</div><div class="line">set: cwnd = cwnd - 1 //每收到两个ACK</div><div class="line">else</div><div class="line">set: cwnd = cwnd</div></pre></td></tr></table></figure></p>
<p>理论知识介绍到此，下面来看看在内核中的具体代码实现。</p>
<h3 id="代码实现注解"><a href="#代码实现注解" class="headerlink" title="代码实现注解"></a>代码实现注解</h3><p>@linux kernel version 3.12/src/net/ipv4/tcp_vegas.c<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div><div class="line">280</div><div class="line">281</div><div class="line">282</div><div class="line">283</div><div class="line">284</div><div class="line">285</div><div class="line">286</div><div class="line">287</div><div class="line">288</div><div class="line">289</div><div class="line">290</div><div class="line">291</div><div class="line">292</div><div class="line">293</div><div class="line">294</div><div class="line">295</div><div class="line">296</div><div class="line">297</div><div class="line">298</div><div class="line">299</div><div class="line">300</div><div class="line">301</div><div class="line">302</div><div class="line">303</div><div class="line">304</div><div class="line">305</div><div class="line">306</div><div class="line">307</div><div class="line">308</div><div class="line">309</div><div class="line">310</div><div class="line">311</div><div class="line">312</div><div class="line">313</div><div class="line">314</div><div class="line">315</div><div class="line">316</div><div class="line">317</div><div class="line">318</div><div class="line">319</div><div class="line">320</div><div class="line">321</div><div class="line">322</div><div class="line">323</div><div class="line">324</div><div class="line">325</div><div class="line">326</div><div class="line">327</div><div class="line">328</div><div class="line">329</div></pre></td><td class="code"><pre><div class="line">/*头文件包含，这里就不解释了*/</div><div class="line">#include &lt;linux/mm.h&gt; </div><div class="line">#include &lt;linux/module.h&gt; </div><div class="line">#include &lt;linux/skbuff.h&gt; </div><div class="line">#include &lt;linux/inet_diag.h&gt; </div><div class="line"> </div><div class="line">#include &lt;net/tcp.h&gt; </div><div class="line"> </div><div class="line">#include &quot;tcp_vegas.h&quot; </div><div class="line"></div><div class="line">/*gamma参数在后面代码中遇到时作分析*/</div><div class="line">static int gamma = 1; </div><div class="line">/*sysctl命令被用于在内核运行时动态地修改内核的运行参数,</div><div class="line"> *0644表示可读写权限,</div><div class="line"> *sysctl_tcp_vegas_alpha表示在</div><div class="line"> */pro/sys/net/ipv4/目录下有一个tcp_vegas_alpha参数，可以进行动态修改。</div><div class="line"> *修改命令为：echo targetvalue &gt; /pro/sys/net/ipv4/tcp_vegas_alpha,这样就没必要*进入到内核去修改，因为在修改内核后还得重新编译内核。</div><div class="line"> */</div><div class="line">module_param(sysctl_tcp_vegas_alpha, int, 0644); </div><div class="line">MODULE_PARM_DESC(sysctl_tcp_vegas_alpha, &quot;lower bound of packets in network&quot;); </div><div class="line">module_param(sysctl_tcp_vegas_beta, int, 0644); </div><div class="line">MODULE_PARM_DESC(sysctl_tcp_vegas_beta, &quot;upper bound of packets in network&quot;); </div><div class="line">module_param(gamma, int, 0644); </div><div class="line">MODULE_PARM_DESC(gamma, &quot;limit on increase (scale by 2)&quot;); </div><div class="line"> </div><div class="line"> </div><div class="line">/* There are several situations when we must &quot;re-start&quot; Vegas: </div><div class="line"> * </div><div class="line"> *  o when a connection is established </div><div class="line"> *  o after an RTO </div><div class="line"> *  o after fast recovery </div><div class="line"> *  o when we send a packet and there is no outstanding </div><div class="line"> *    unacknowledged data (restarting an idle connection) </div><div class="line"> * </div><div class="line"> * In these circumstances we cannot do a Vegas calculation at the </div><div class="line"> * end of the first RTT, because any calculation we do is using </div><div class="line"> * stale info -- both the saved cwnd and congestion feedback are </div><div class="line"> * stale. </div><div class="line"> * </div><div class="line"> * Instead we must wait until the completion of an RTT during </div><div class="line"> * which we actually receive ACKs. </div><div class="line"> */ </div><div class="line">static void vegas_enable(struct sock *sk) </div><div class="line">&#123; </div><div class="line">    const struct tcp_sock *tp = tcp_sk(sk); </div><div class="line">    struct vegas *vegas = inet_csk_ca(sk); </div><div class="line"> </div><div class="line">    /* Begin taking Vegas samples next time we send something. */ </div><div class="line">    vegas-&gt;doing_vegas_now = 1; </div><div class="line"> </div><div class="line">    /* Set the beginning of the next send window. */ </div><div class="line">    vegas-&gt;beg_snd_nxt = tp-&gt;snd_nxt; </div><div class="line"> </div><div class="line">    vegas-&gt;cntRTT = 0; </div><div class="line">    vegas-&gt;minRTT = 0x7fffffff; </div><div class="line">&#125; </div><div class="line"> </div><div class="line">/* Stop taking Vegas samples for now. */ </div><div class="line">static inline void vegas_disable(struct sock *sk) </div><div class="line">&#123; </div><div class="line">    struct vegas *vegas = inet_csk_ca(sk); </div><div class="line"> </div><div class="line">    vegas-&gt;doing_vegas_now = 0; </div><div class="line">&#125; </div><div class="line"> /*初始化*/</div><div class="line">void tcp_vegas_init(struct sock *sk) </div><div class="line">&#123; </div><div class="line">    struct vegas *vegas = inet_csk_ca(sk); </div><div class="line"> </div><div class="line">    vegas-&gt;baseRTT = 0x7fffffff; </div><div class="line">    vegas_enable(sk); </div><div class="line">&#125; </div><div class="line">EXPORT_SYMBOL_GPL(tcp_vegas_init); </div><div class="line"> </div><div class="line">/* Do RTT sampling needed for Vegas. </div><div class="line"> * Basically we: </div><div class="line"> *   o min-filter RTT samples from within an RTT to get the current </div><div class="line"> *     propagation delay + queuing delay (we are min-filtering to try to </div><div class="line"> *     avoid the effects of delayed ACKs) </div><div class="line"> *   o min-filter RTT samples from a much longer window (forever for now) </div><div class="line"> *     to find the propagation delay (baseRTT) </div><div class="line"> */ </div><div class="line">void tcp_vegas_pkts_acked(struct sock *sk, u32 cnt, s32 rtt_us) </div><div class="line">&#123; </div><div class="line">    struct vegas *vegas = inet_csk_ca(sk); </div><div class="line">    u32 vrtt; </div><div class="line"> </div><div class="line">    if (rtt_us &lt; 0) </div><div class="line">        return; </div><div class="line"> </div><div class="line">    /* Never allow zero rtt or baseRTT */ </div><div class="line">    vrtt = rtt_us + 1; </div><div class="line"> </div><div class="line">    /* Filter to find propagation delay: */ </div><div class="line">    if (vrtt &lt; vegas-&gt;baseRTT) </div><div class="line">        vegas-&gt;baseRTT = vrtt; </div><div class="line"> </div><div class="line">    /* Find the min RTT during the last RTT to find </div><div class="line">     * the current prop. delay + queuing delay: </div><div class="line">     */ </div><div class="line">    vegas-&gt;minRTT = min(vegas-&gt;minRTT, vrtt); </div><div class="line">    /*对rtt采样统计*/</div><div class="line">    vegas-&gt;cntRTT++; </div><div class="line">&#125; </div><div class="line">EXPORT_SYMBOL_GPL(tcp_vegas_pkts_acked); </div><div class="line"> /*状态判断，是否开启vegas*/</div><div class="line">void tcp_vegas_state(struct sock *sk, u8 ca_state) </div><div class="line">&#123; </div><div class="line"> </div><div class="line">    if (ca_state == TCP_CA_Open) </div><div class="line">        vegas_enable(sk); </div><div class="line">    else </div><div class="line">        vegas_disable(sk); </div><div class="line">&#125; </div><div class="line">EXPORT_SYMBOL_GPL(tcp_vegas_state); </div><div class="line"> </div><div class="line">/* </div><div class="line"> * If the connection is idle and we are restarting, </div><div class="line"> * then we don&apos;t want to do any Vegas calculations </div><div class="line"> * until we get fresh RTT samples.  So when we </div><div class="line"> * restart, we reset our Vegas state to a clean </div><div class="line"> * slate. After we get acks for this flight of </div><div class="line"> * packets, _then_ we can make Vegas calculations </div><div class="line"> * again. </div><div class="line"> */ </div><div class="line">void tcp_vegas_cwnd_event(struct sock *sk, enum tcp_ca_event event) </div><div class="line">&#123; </div><div class="line">    if (event == CA_EVENT_CWND_RESTART || </div><div class="line">        event == CA_EVENT_TX_START) </div><div class="line">        tcp_vegas_init(sk); </div><div class="line">&#125; </div><div class="line">EXPORT_SYMBOL_GPL(tcp_vegas_cwnd_event); </div><div class="line"> /*设置ssthresh*/</div><div class="line">static inline u32 tcp_vegas_ssthresh(struct tcp_sock *tp) </div><div class="line">&#123; </div><div class="line">    return  min(tp-&gt;snd_ssthresh, tp-&gt;snd_cwnd-1); </div><div class="line">&#125; </div><div class="line"> /*tcp_vegas_cong_avoid()函数是vegas算法实现的重点*/</div><div class="line">static void tcp_vegas_cong_avoid(struct sock *sk, u32 ack, u32 in_flight) </div><div class="line">&#123; </div><div class="line">    struct tcp_sock *tp = tcp_sk(sk); </div><div class="line">    struct vegas *vegas = inet_csk_ca(sk); </div><div class="line"> /*cwnd和in_flight比较，判断cwnd是否受限，受限则直接返回*/</div><div class="line">    if (!tcp_is_cwnd_limited(sk, in_flight)) &#123; </div><div class="line">        return; </div><div class="line">    &#125; </div><div class="line"> /*如果现在不能使用vegas，则使用reno进行拥塞控制*/</div><div class="line">    if (!vegas-&gt;doing_vegas_now) &#123; </div><div class="line">        tcp_reno_cong_avoid(sk, ack, in_flight); </div><div class="line">        return; </div><div class="line">    &#125; </div><div class="line"> /*每收到一个ACK，便和beg_snd_nxt比较，判断是ACK新包还是ACK重传包*/</div><div class="line">    if (after(ack, vegas-&gt;beg_snd_nxt)) &#123; </div><div class="line">        /* Do the Vegas once-per-RTT cwnd adjustment. */ </div><div class="line"> </div><div class="line">        /* Save the extent of the current window so we can use this </div><div class="line">         * at the end of the next RTT. </div><div class="line">         */ </div><div class="line">        /*更新滑动窗口的左边界*/</div><div class="line">        vegas-&gt;beg_snd_nxt  = tp-&gt;snd_nxt;     </div><div class="line"> </div><div class="line">        /* We do the Vegas calculations only if we got enough RTT </div><div class="line">         * samples that we can be reasonably sure that we got </div><div class="line">         * at least one RTT sample that wasn&apos;t from a delayed ACK. </div><div class="line">         * If we only had 2 samples total, </div><div class="line">         * then that means we&apos;re getting only 1 ACK per RTT, which </div><div class="line">         * means they&apos;re almost certainly delayed ACKs. </div><div class="line">         * If  we have 3 samples, we should be OK. </div><div class="line">         */ </div><div class="line"> </div><div class="line">        if (vegas-&gt;cntRTT &lt;= 2) &#123; </div><div class="line">            /* We don&apos;t have enough RTT samples to do the Vegas </div><div class="line">             * calculation, so we&apos;ll behave like Reno. </div><div class="line">             */ </div><div class="line">            tcp_reno_cong_avoid(sk, ack, in_flight); </div><div class="line">        &#125; else &#123; </div><div class="line">            u32 rtt, diff; </div><div class="line">            u64 target_cwnd; </div><div class="line"> </div><div class="line">            /* We have enough RTT samples, so, using the Vegas </div><div class="line">             * algorithm, we determine if we should increase or </div><div class="line">             * decrease cwnd, and by how much. </div><div class="line">             */ </div><div class="line"> </div><div class="line">            /* Pluck out the RTT we are using for the Vegas </div><div class="line">             * calculations. This is the min RTT seen during the </div><div class="line">             * last RTT. Taking the min filters out the effects </div><div class="line">             * of delayed ACKs, at the cost of noticing congestion </div><div class="line">             * a bit later. </div><div class="line">             */ </div><div class="line">            rtt = vegas-&gt;minRTT; </div><div class="line"> </div><div class="line">            /* Calculate the cwnd we should have, if we weren&apos;t </div><div class="line">             * going too fast. </div><div class="line">             * </div><div class="line">             * This is: </div><div class="line">             *     (actual rate in segments) * baseRTT </div><div class="line">             */ </div><div class="line">            target_cwnd = tp-&gt;snd_cwnd * vegas-&gt;baseRTT / rtt; </div><div class="line"> </div><div class="line">            /* Calculate the difference between the window we had, </div><div class="line">             * and the window we would like to have. This quantity </div><div class="line">             * is the &quot;Diff&quot; from the Arizona Vegas papers. </div><div class="line">             */ </div><div class="line">            /*这里要说明下，diff的计算和paper中说的有点出入,</div><div class="line">             *将公式展开后得diff = snd_cwnd*rtt/baseRTT - snd_cwnd</div><div class="line">             *而在paper中说的是diff = snd_cwnd - snd_cwnd*baseRTT/rtt</div><div class="line">             */</div><div class="line">            diff = tp-&gt;snd_cwnd * (rtt-vegas-&gt;baseRTT) / vegas-&gt;baseRTT; </div><div class="line">            /*更新变量*/</div><div class="line">            tp-&gt;snd_diff = diff; </div><div class="line">            tp-&gt;vegas_baseRTT = vegas-&gt;baseRTT; </div><div class="line">            tp-&gt;vegas_minRTT = vegas-&gt;minRTT; </div><div class="line">            if (diff &gt; gamma &amp;&amp; tp-&gt;snd_cwnd &lt;= tp-&gt;snd_ssthresh) &#123; </div><div class="line">                /* Going too fast. Time to slow down </div><div class="line">                 * and switch to congestion avoidance. </div><div class="line">                 */ </div><div class="line"> </div><div class="line">                /* Set cwnd to match the actual rate </div><div class="line">                 * exactly: </div><div class="line">                 *   cwnd = (actual rate) * baseRTT </div><div class="line">                 * Then we add 1 because the integer </div><div class="line">                 * truncation robs us of full link </div><div class="line">                 * utilization. </div><div class="line">                 */ </div><div class="line">                tp-&gt;snd_cwnd = min(tp-&gt;snd_cwnd, (u32)target_cwnd+1); </div><div class="line">                tp-&gt;snd_ssthresh = tcp_vegas_ssthresh(tp); </div><div class="line"> </div><div class="line">            &#125; else if (tp-&gt;snd_cwnd &lt;= tp-&gt;snd_ssthresh) &#123; </div><div class="line">                /* Slow start.  */ </div><div class="line">                tcp_slow_start(tp); </div><div class="line">            &#125; else &#123; </div><div class="line">                /* Congestion avoidance. */ </div><div class="line"> </div><div class="line">                /* Figure out where we would like cwnd </div><div class="line">                 * to be. </div><div class="line">                 */ </div><div class="line">                /*如果diff &gt; beta,说明网络拥塞严重，需要降低cwnd*/</div><div class="line">                if (diff &gt; sysctl_tcp_vegas_beta) &#123; </div><div class="line">                    /* The old window was too fast, so </div><div class="line">                     * we slow down. </div><div class="line">                     */ </div><div class="line">                    tp-&gt;snd_cwnd--; </div><div class="line">                    tp-&gt;snd_ssthresh </div><div class="line">                        = tcp_vegas_ssthresh(tp); </div><div class="line">                &#125;</div><div class="line">                /*如果diff &lt; alpha,说明网络中数据包的数量还有增长空间*/</div><div class="line">                 else if (diff &lt; sysctl_tcp_vegas_alpha) &#123; </div><div class="line">                    /* We don&apos;t have enough extra packets </div><div class="line">                     * in the network, so speed up. </div><div class="line">                     */ </div><div class="line">                    tp-&gt;snd_cwnd++; </div><div class="line">                &#125;</div><div class="line">                /*如果alpha &lt; diff &lt; beta,维持原样*/ </div><div class="line">                else &#123; </div><div class="line">                    /* Sending just as fast as we </div><div class="line">                     * should be. </div><div class="line">                     */ </div><div class="line">                &#125; </div><div class="line">            &#125; </div><div class="line">            /*cwnd最小为2*/</div><div class="line">            if (tp-&gt;snd_cwnd &lt; 2) </div><div class="line">                tp-&gt;snd_cwnd = 2; </div><div class="line">            else if (tp-&gt;snd_cwnd &gt; tp-&gt;snd_cwnd_clamp) </div><div class="line">                tp-&gt;snd_cwnd = tp-&gt;snd_cwnd_clamp; </div><div class="line"> </div><div class="line">            tp-&gt;snd_ssthresh = tcp_current_ssthresh(sk); </div><div class="line">        &#125; </div><div class="line"> </div><div class="line">        /* Wipe the slate clean for the next RTT. */ </div><div class="line">        vegas-&gt;cntRTT = 0; </div><div class="line">        vegas-&gt;minRTT = 0x7fffffff; </div><div class="line">    &#125; </div><div class="line">    /* Use normal slow start */ </div><div class="line">    else if (tp-&gt;snd_cwnd &lt;= tp-&gt;snd_ssthresh) </div><div class="line">        tcp_slow_start(tp); </div><div class="line"> </div><div class="line">&#125; </div><div class="line"> </div><div class="line">/* Extract info for Tcp socket info provided via netlink. */ </div><div class="line">void tcp_vegas_get_info(struct sock *sk, u32 ext, struct sk_buff *skb) </div><div class="line">&#123; </div><div class="line">    const struct vegas *ca = inet_csk_ca(sk); </div><div class="line">    if (ext &amp; (1 &lt;&lt; (INET_DIAG_VEGASINFO - 1))) &#123; </div><div class="line">        struct tcpvegas_info info = &#123; </div><div class="line">            .tcpv_enabled = ca-&gt;doing_vegas_now, </div><div class="line">            .tcpv_rttcnt = ca-&gt;cntRTT, </div><div class="line">            .tcpv_rtt = ca-&gt;baseRTT, </div><div class="line">            .tcpv_minrtt = ca-&gt;minRTT, </div><div class="line">        &#125;; </div><div class="line"> </div><div class="line">        nla_put(skb, INET_DIAG_VEGASINFO, sizeof(info), &amp;info); </div><div class="line">    &#125; </div><div class="line">&#125; </div><div class="line">EXPORT_SYMBOL_GPL(tcp_vegas_get_info);</div><div class="line"></div><div class="line">static struct tcp_congestion_ops tcp_vegas __read_mostly = &#123;</div><div class="line">    .flags      = TCP_CONG_RTT_STAMP,</div><div class="line">    .init       = tcp_vegas_init,</div><div class="line">    .ssthresh   = tcp_reno_ssthresh,</div><div class="line">    .cong_avoid = tcp_vegas_cong_avoid,</div><div class="line">    .min_cwnd   = tcp_reno_min_cwnd,</div><div class="line">    .pkts_acked = tcp_vegas_pkts_acked,</div><div class="line">    .set_state  = tcp_vegas_state,</div><div class="line">    .cwnd_event = tcp_vegas_cwnd_event,</div><div class="line">    .get_info   = tcp_vegas_get_info,</div><div class="line"></div><div class="line">    .owner      = THIS_MODULE,</div><div class="line">    .name       = &quot;vegas&quot;,</div><div class="line">&#125;;</div><div class="line"></div><div class="line">static int __init tcp_vegas_register(void)</div><div class="line">&#123;</div><div class="line">    BUILD_BUG_ON(sizeof(struct vegas) &gt; ICSK_CA_PRIV_SIZE);</div><div class="line">    tcp_register_congestion_control(&amp;tcp_vegas);</div><div class="line">    return 0;</div><div class="line">&#125;</div><div class="line"></div><div class="line">static void __exit tcp_vegas_unregister(void)</div><div class="line">&#123;</div><div class="line">    tcp_unregister_congestion_control(&amp;tcp_vegas);</div><div class="line">&#125;</div><div class="line"></div><div class="line">module_init(tcp_vegas_register);</div><div class="line">module_exit(tcp_vegas_unregister);</div><div class="line"></div><div class="line">MODULE_AUTHOR(&quot;Stephen Hemminger&quot;);</div><div class="line">MODULE_LICENSE(&quot;GPL&quot;);</div><div class="line">MODULE_DESCRIPTION(&quot;TCP Vegas&quot;);</div></pre></td></tr></table></figure></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>vegas拥塞控制算法用于控制传输速率和delay会有很好的效果，但其缺点是在现在的高带宽网络环境下，其竞争带宽时不够激进，比不上其他拥塞控制算法，比如cubic, veno等。</p>
<p><strong>参考文献</strong><br><a href="http://www.cs.toronto.edu/syslab/courses/csc2209/06au/papers/vegas.pdf" target="_blank" rel="external">TCP Vegas: End to End Congestion Avoidance on a Global Internet</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;vegas是一种主动调整cwnd的拥塞控制算法，主要思想是设置两个阈值,alpha和beta,然后通过计算目标速率(Expected)和实际速率(Actual)差(diff)，再比较diff与alpha和beta的关系，对cwnd进行调节。vegas这篇paper的主要贡献是提供了一种拥塞检测的方法。&lt;br&gt;
    
    </summary>
    
      <category term="TCP/IP" scheme="http://yoursite.com/categories/TCP-IP/"/>
    
    
  </entry>
  
  <entry>
    <title>混合慢启动算法:Hybrid</title>
    <link href="http://yoursite.com/2017/05/14/%E6%B7%B7%E5%90%88%E6%85%A2%E5%90%AF%E5%8A%A8%E7%AE%97%E6%B3%95/"/>
    <id>http://yoursite.com/2017/05/14/混合慢启动算法/</id>
    <published>2017-05-14T13:03:43.000Z</published>
    <updated>2017-05-14T13:08:58.521Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;传统的单纯采用指数增长的慢启动算法有一个无法避免的问题，在临界进入拥塞避免阶段时，特别是在高带宽长距离网络中，容易出现大规模丢包，进而导致大量数据包重传，也有可能出现timeout，致使网络带宽利用率下降。<br>&emsp;&emsp;这里，本文将介绍一种新的慢启动方法——Hybrid Slow Start，它在传统的慢启动算法中加入了判断机制，强制从慢启动转入拥塞避免。这里主要说说其在CUBIC中是怎么实现的，Hybrid Slow Start算法原理本身就不做过多介绍了，有兴趣可以看看本文最后给出的参考文献。<br><a id="more"></a></p>
<h3 id="变量介绍"><a href="#变量介绍" class="headerlink" title="变量介绍"></a>变量介绍</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">#define HYSTART_ACK_TRAIN      0x1 //进入拥塞避免的条件</div><div class="line">#define HYSTART_DELAY          0x2 //进入拥塞避免的条件</div><div class="line">#define HYSTART_MIN_SAMPLES    8   //表示至少取一个RTT的前8个ACK作为样本</div><div class="line">#define HYSTART_DELAY_MIN      (4u&lt;&lt;3) </div><div class="line">#define HYSTART_DELAY_MAX      (16u&lt;&lt;3)</div><div class="line">/* if x &gt; HYSTART_DELAY_MAX，return HYSTART_DELAY_MAX </div><div class="line"> * else if x &lt; HYSTART_DELAY_MIN，return HYATART_DELAY_MIN</div><div class="line"> * else return x</div><div class="line"> */</div><div class="line">#define HYSTART_DELAY_THRESH clamp(x, HYSTART_DELAY_MIN, HYSTART_DELAY_MAX)</div><div class="line">static int hystart __read_mostly = 1;</div><div class="line">static int hystart_detect __read_mostly = HYSTART_ACK_TRAIN | HYSART_DELAY;</div><div class="line">static int hystart_low_window __read_mostly = 16;</div><div class="line">static int hystart_ack_delta __read_mostly = 2;</div><div class="line"></div><div class="line">struct bictcp &#123;</div><div class="line">  ...</div><div class="line">  u32    delay_min;   //全局最小rtt</div><div class="line">  u32    round_start; //记录慢启动的起始时间</div><div class="line">  u32    curr_rtt;    //记录样本中的最小rtt</div><div class="line">  u8      found;</div><div class="line">  u8      sample_cnt; //样本计数变量</div><div class="line">  ...</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h3 id="两类退出slow-start机制"><a href="#两类退出slow-start机制" class="headerlink" title="两类退出slow start机制"></a>两类退出slow start机制</h3><p>在Hybrid Slow Start算法中给出了种类判断机制用来退出慢启动进入拥塞避免，分别是ACKs train length和Increase in packet delays。</p>
<h4 id="ACKS-train-length"><a href="#ACKS-train-length" class="headerlink" title="ACKS train length"></a>ACKS train length</h4><p>这里给出一段原文描述，在这段描述中说了怎么测ACKs train length以及为什么要用ACKs train length。</p>
<blockquote>
<p>The ACK train length is measured by calculating the sum of inter-arrival times of all the closely spaced ACKs within an RTT round. The train length is strongly affected by the bottleneck bandwidth, routing delays and buffer sizes along the path, and is easily stretched out by congestion caused by cross traffic in the path, so by estimating the train length we can reliably find a safe exit point of Slow Start. </p>
</blockquote>
<h4 id="Increase-in-packet-delays"><a href="#Increase-in-packet-delays" class="headerlink" title="Increase in packet delays"></a>Increase in packet delays</h4><p>同样还是一段原文描述，如果你问我为什么不直接翻译成中文，我不会回答你这个问题的。</p>
<blockquote>
<p>Increase in packet delays during Slow Start may indicate the possibility of the bottleneck router being congested.</p>
</blockquote>
<p>但是Increase in packet delays的测量会受到bursty transmission的影响，所以只测一个RTT中刚开始的几个数据包的往返时间来避免bursty transission的影响，在后面给出的code中会看到。</p>
<h3 id="函数实现"><a href="#函数实现" class="headerlink" title="函数实现"></a>函数实现</h3><p>hystart重置函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">static inline void bictcp_hystart_reset(struct sock *sk)</div><div class="line">&#123;</div><div class="line">    struct tcp_sock *tp = tcp_sk(sk);</div><div class="line">    struct bictcp *ca = inet_csk_ca(sk);</div><div class="line">    </div><div class="line">    ca-&gt;round_start = ca-&gt;last_ack = bictcp_clock(); //记录慢启动的开始时间</div><div class="line">    ca-&gt;end_seq = tp-&gt;snd_nxt;</div><div class="line">    ca-&gt;curr_rtt = 0;   //重置样本最小rtt为0</div><div class="line">    ca-&gt;sample_cnt = 0; //重置样本计数为0</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>Hybrid Slow Start实现的核心部分<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line">static void hystart_update(struct sock *sk, u32 delay)</div><div class="line">&#123;</div><div class="line">    struct tcp_sock *tp = tcp_sk(sk);</div><div class="line">    struct bictcp *ca = inet_csk_ca(sk);</div><div class="line"></div><div class="line">    //如果ca-&gt;found &amp; hystart_detect为真，表示应该进入拥塞避免</div><div class="line">    if (!(ca-&gt;found &amp; hystart_detect)) &#123;</div><div class="line">        u32 now = bictcp_clock(); //获取当前时间</div><div class="line"></div><div class="line">        /* first detection parameter - ack-train detection */</div><div class="line">        /* 前后到来的两个ACK的间隔时间小于hystart_ack_delta才有效 */</div><div class="line">        if ((s32)(now - ca-&gt;last_ack) &lt;= hystart_ack_delta) &#123;</div><div class="line">            ca-&gt;last_ack = now;  //更新上一个ACK到来的时间</div><div class="line">            /* 每次慢启动时会重置round_start为0，结合前面的if条件，下面的</div><div class="line">             * if成立的条件是：从慢启动开始到现在经过的时间如果大于</div><div class="line">             * delay_min&gt;&gt;4，那么可以进入拥塞避免了。至于为什么选</div><div class="line">             * delay_min&gt;&gt;4这个值，鬼知道。</div><div class="line">             */</div><div class="line">            if ((s32)(now - ca-&gt;round_start) &gt; ca-&gt;delay_min &gt;&gt; 4)</div><div class="line">                ca-&gt;found |= HYSTART_ACK_TRAIN;</div><div class="line">        &#125;   </div><div class="line"></div><div class="line">        /* obtain the minimum delay of more than sampling packets */</div><div class="line">        /* 如果样本计数小于HYSTART_MIN_SAMPLES(默认为8) */</div><div class="line">        if (ca-&gt;sample_cnt &lt; HYSTART_MIN_SAMPLES) &#123;</div><div class="line">            if (ca-&gt;curr_rtt == 0 || ca-&gt;curr_rtt &gt; delay)</div><div class="line">                ca-&gt;curr_rtt = delay;/* 更新样本中的最小rtt */</div><div class="line"></div><div class="line">            ca-&gt;sample_cnt++;</div><div class="line">        &#125; else &#123;//如果样本大于8了，那么就可以判断是否要进入拥塞避免了</div><div class="line">            /* 如果前面8个样本中的最小rtt大于全局最小rtt与阈值的和，那么表示网络出</div><div class="line">             * 现了拥塞，应立马进入拥塞避免阶段，HYSTART_DELAY_THRESH()的返</div><div class="line">             * 回值在前面的变量介绍中有说明。</div><div class="line">            if (ca-&gt;curr_rtt &gt; ca-&gt;delay_min +</div><div class="line">                HYSTART_DELAY_THRESH(ca-&gt;delay_min&gt;&gt;4))</div><div class="line">                ca-&gt;found |= HYSTART_DELAY;</div><div class="line">        &#125;   </div><div class="line">        /*  </div><div class="line">         * Either one of two conditions are met,</div><div class="line">         * we exit from slow start immediately.</div><div class="line">         */</div><div class="line">        /* 如果为真就进入拥塞避免 */</div><div class="line">        if (ca-&gt;found &amp; hystart_detect)</div><div class="line">            tp-&gt;snd_ssthresh = tp-&gt;snd_cwnd;</div><div class="line">    &#125;   </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;最近做实验需要探测网络带宽，需要用到Hybrid Slow Start，所以看了paper和其在Linux CUBIC算法中的实现，然后就写了这篇blog。<br>参考文献：<a href="https://pdfs.semanticscholar.org/25e9/ef3f03315782c7f1cbcd31b587857adae7d1.pdf" target="_blank" rel="external">Hybrid Slow Start for High-Bandwidth and Long-Distance Networks</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;传统的单纯采用指数增长的慢启动算法有一个无法避免的问题，在临界进入拥塞避免阶段时，特别是在高带宽长距离网络中，容易出现大规模丢包，进而导致大量数据包重传，也有可能出现timeout，致使网络带宽利用率下降。&lt;br&gt;&amp;emsp;&amp;emsp;这里，本文将介绍一种新的慢启动方法——Hybrid Slow Start，它在传统的慢启动算法中加入了判断机制，强制从慢启动转入拥塞避免。这里主要说说其在CUBIC中是怎么实现的，Hybrid Slow Start算法原理本身就不做过多介绍了，有兴趣可以看看本文最后给出的参考文献。&lt;br&gt;
    
    </summary>
    
      <category term="TCP/IP" scheme="http://yoursite.com/categories/TCP-IP/"/>
    
    
  </entry>
  
  <entry>
    <title>移动端拥塞控制算法之：Verus</title>
    <link href="http://yoursite.com/2017/04/24/%E7%A7%BB%E5%8A%A8%E7%BD%91%E7%BB%9C%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E4%B9%8B%EF%BC%9AVerus/"/>
    <id>http://yoursite.com/2017/04/24/移动网络拥塞控制算法之：Verus/</id>
    <published>2017-04-24T06:19:49.000Z</published>
    <updated>2017-05-17T16:31:14.163Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;Verus是一种端到端的拥塞控制协议，它根据测量delay来快速反应移动网络的容量变化，而不是去尝试预测移动网络的动态信道。<br><a id="more"></a></p>
<h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><p>&emsp;&emsp;Verus是一种端到端的拥塞控制协议，它根据测量delay来快速反应移动网络的容量变化，而不是去尝试预测移动网络的动态信道。Verus的关键idea是学习历史数据（delay profile）来得到在一个short epochs内，端到端的packet dealy和outstanding window size之间的关系。然后运用这种关系，观察在short-term内数据报延迟的变化，对window size做出适当的调整。</p>
<h4 id="移动网络信道的难以预测主要有三点："><a href="#移动网络信道的难以预测主要有三点：" class="headerlink" title="移动网络信道的难以预测主要有三点："></a>移动网络信道的难以预测主要有三点：</h4><blockquote>
<p>First, the state of a cellular channel between a mobile device and a base station undergoes several complex state transitions that affect channel availability in short time scales.<br>Second, the frame scheduling algorithms used in cellular networks cause burstiness in the cellular channel.<br>Third, while prior work has considered only self-inflicted queuing delay as a cause for high delays, we find that competing traffic does affect end-to-end delay characteristics, especially under high contention or when the cellular channel is near saturation. </p>
</blockquote>
<h4 id="通过实验观察到的三点网络特性："><a href="#通过实验观察到的三点网络特性：" class="headerlink" title="通过实验观察到的三点网络特性："></a>通过实验观察到的三点网络特性：</h4><blockquote>
<p><strong>Burst scheduling:</strong> Typical traffic characteristics observed at a receiver are highly bursty with variable burst sizes and burst inter-arrival periods. Mobility further amplifies these characteristics.<br><strong>Competing traffic:</strong> When two or more flows contend for radio resources and their sending rates approach network capacity, we observe cross-flow dependencies.<br><strong>Channel unpredictability:</strong> Standard prediction mechanisms even using the most recent samples are far from capturing the bursty behavior of the channel.</p>
</blockquote>
<h3 id="Verus协议"><a href="#Verus协议" class="headerlink" title="Verus协议"></a>Verus协议</h3><p>&emsp;&emsp;Verus从传统的TCP拥塞控制算法中借鉴了一些东西，比如慢开始和丢包后的多路降低（multiplicative decrease），但Verus在发送窗口的增长机制上做了改变。不同于传统的TCP算法在拥塞避免阶段每一个$RTT$，$CWnd$才增1，而Verus增加和降低发送窗口每$\xi$ms——记为epoch，当信道条件允许发送更多的数据包时，verus通过快速增加发送窗口来适应动态改变的无线信道。<br>在每一个epoch，Verus的发送窗口函数如下：<br>                  $$W(t+1) = f(d(t) + \delta(t))$$<br>这里，$W(t+1)$是下一时刻的发送窗口，$d(t)$是网络延迟，$\delta(t)$是延迟增量（可为负数），$f$是delay profile 函数。</p>
<h4 id="delay-profile"><a href="#delay-profile" class="headerlink" title="delay profile"></a>delay profile</h4><p>&emsp;&emsp;Verus通过下面四个步骤来建立delay profile：</p>
<blockquote>
<p><strong>Delay Estimator</strong>: estimates the network RTT using delay measurements reported from the receiver’s acknowledgments<br><strong>Delay Profiler</strong>: tracks the relationship between delay and sending window that does not cause network congestion<br><strong>Window Estimator:</strong> estimates the sending window using the estimated delay and delay profile<br><strong>Loss Handler</strong>: handles losses and adjusts the sending window</p>
</blockquote>
<p>具体建立delay profile的计算过程和公式推导在这里就不详细介绍了，最后会得到下面给出的一张图，这张图反映的是delay estimate和sending window之间的关系。通过当前时刻测得的delay，估算下一时刻的delay，然后根据这张图找出下一时刻的sending window值。<br><img src="../../../../pictures/Cellular/20170424165913.png" alt=""><br>这里只是很简单的介绍了verus的思想， 想要深入了解verus算法的话还是看其paper更好一点，下面会给出这篇paper的地址。</p>
<p><strong>参考文献：</strong><br><a href="https://cs.nyu.edu/~jchen/publications/sigcomm15-zaki.pdf" target="_blank" rel="external">Adaptive Congestion Control for Unpredictable Celler Networks</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;Verus是一种端到端的拥塞控制协议，它根据测量delay来快速反应移动网络的容量变化，而不是去尝试预测移动网络的动态信道。&lt;br&gt;
    
    </summary>
    
      <category term="私人文献阅读" scheme="http://yoursite.com/categories/%E7%A7%81%E4%BA%BA%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/"/>
    
    
  </entry>
  
  <entry>
    <title>TCP重点系列之拥塞状态机</title>
    <link href="http://yoursite.com/2017/04/19/TCP%E9%87%8D%E7%82%B9%E7%B3%BB%E5%88%97%E4%B9%8B%E6%8B%A5%E5%A1%9E%E7%8A%B6%E6%80%81%E6%9C%BA/"/>
    <id>http://yoursite.com/2017/04/19/TCP重点系列之拥塞状态机/</id>
    <published>2017-04-19T14:47:30.000Z</published>
    <updated>2017-07-19T12:39:42.358Z</updated>
    
    <content type="html"><![CDATA[<p>这篇博客主要介绍TCP拥塞状态(state)在不同场景的转换及通过flag怎么识别是正常的ACK还是SACK，这一块知识比较杂乱，仔细看这部分内容，还是因为研究timeout问题需要。<br><a id="more"></a></p>
<h4 id="state"><a href="#state" class="headerlink" title="state"></a>state</h4><p>当sender收到一个ack时，Linux TCP通过状态机(state)来决定发送行为，是应该降低cwnd呢，还是保持cwnd不变，还是继续增加cwnd，这很重要。如果处理不当，可能会导致丢包或者timeout。<br>主要有五种状态，分别是：Open，Disorder，CWR，Recovery和Loss，下面对这五种状态做一个简要介绍，英文部分摘自这篇文章<a href="https://pdfs.semanticscholar.org/0e9c/968d09ab2e53e24c4dca5b2d67c7f7140f8e.pdf" target="_blank" rel="external">Congestion Control in Linux TCP</a>，有兴趣的话可以下载下来读读。</p>
<h4 id="Open"><a href="#Open" class="headerlink" title="Open"></a>Open</h4><p>This is the normal state in which the TCP sender follows the fast path of execution optimized for the common case in processing incoming acknowledgements. When an acknowledgement arrives, the sender increases the congestion window according to either slow start or congestion avoidance,<br>depending on whether the congestion window is smaller or larger than the slow start threshold, respectively.<br>当网络中没有发生丢包，也就不需要重传，sender按照正常的流程处理到来的ACK。</p>
<h4 id="Disorder"><a href="#Disorder" class="headerlink" title="Disorder"></a>Disorder</h4><p>When the sender detects duplicate ACKs or selective acknowledgements, it moves to the Disorder state. In this state the congestion window is not adjusted, but each incoming packet triggers transmission of a new segment. Therefore, the TCP sender follows the packet conservation principle [Jac88], which states that a new packet is not sent out until an old packet has left the network. In practice the behavior in this state is similar to the limited transmit proposal by IETF [ABF01], which was suggested to allow more efficient recovery by using fast retransmit when congestion window is small, or when a large number of segments are lost in the last window of transmission.<br>当sender检测到dupack或者SACK，将会转移到Disorder状态，当处在这个这个状态中时，<br>cwnd将不做调整，但每收到一个dupack或SACK，sender将发送一个新包。</p>
<h4 id="CWR"><a href="#CWR" class="headerlink" title="CWR"></a>CWR</h4><p>The TCP sender may receive congestion notifications either by Explicit Congestion Notification, ICMP source quench [Pos81a], or from a local device. When receiving a congestion notification, the Linux sender does not reduce the congestion window at once, but by one segment for every second incoming ACK until the window size is halved. When the sender is in process of reducing the congestion window size and it does not have outstanding retransmissions, it is in CWR (Congestion Window Reduced) state. CWR state can be interrupted by Recovery or Loss states described below.<br>当sender收到ACK包含显示拥塞通知（ECN），这个ECN由路由器写在IP头中，告诉TCP<br>sender网络拥塞，sender不会立马降低cwnd，而是每收到两个ACK才将cwnd减一，直到减为之前的一半，当cwnd正在减小cwnd，网络中有没有重传包时，这个状态就叫CWR，CWR可以被Recovery或者Loss中断。</p>
<h4 id="Recovery"><a href="#Recovery" class="headerlink" title="Recovery"></a>Recovery</h4><p>After a sufficient amount of successive duplicate ACKs arrive at the sender, it retransmits the first unacknowledged segment and enters the Recovery state. By default, the threshold for entering Recovery is three successive duplicate ACKs, a value recommended by the TCP congestion control specification. During the Recovery state, the congestion window size is reduced by one segment for<br>every second incoming acknowledgement, similar to the CWR state. The window reduction ends when the congestion window size is equal to ssthresh, i.e.<br>half of the window size when entering the Recovery state. The congestion window is not increased during the recovery state, and the sender either retransmits the segments marked lost, or makes forward transmissions on new data according to the packet conservation principle. The sender stays in<br>the Recovery state until all of the segments outstanding when the Recovery state was entered are successfully acknowledged. After this the sender goes back to the Open state. A retransmission timeout can also interrupt the Recovery state.<br>当sender连续收到多个（默认3）dupack时，意味着丢包了，这是sender会重传第一个未被ACK的包，并进入Recovery状态。在Recovery状态期间，cwnd的处理同CWR大致一样，cwnd不会降低，要么重传标记了lost的包，要么根据保守原则发送新包。直到网络中所有的包都被ACK，才会退出Recovery进入Open状态，Recovery状态可以被loss状态打断。</p>
<h4 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h4><p>When an RTO expires, the sender enters the Loss state. All outstanding segments are marked lost, and the congestion window is set to one segment,<br>hence the sender starts increasing the congestion window using the slow start algorithm. A major difference between the Loss and Recovery states is that in the Loss state the congestion window is in increased after the sender has reset it to one segment, but in the Recovery state the congestion window size can only be reduced. The Loss state cannot be interrupted by any other state, thus the sender exits to the Open state only after all data outstanding when the Loss state began have successfully been acknowledged. For example, fast retransmit cannot be triggered during the Loss state, which is in conformance with the NewReno specification.<br>当超时后，TCP sender进入Loss状态，所有在网络中的包被标记为lost，cwnd重置为1，通过slow start重新增加cwnd，Loss与Recovery状态的不同点在于，cwnd会重置为1，但是Recovery状态不会，它会降到之前的一半。Loss状态不能被其它任何状态中断，只有当网络中所有的包被成功ACK后，才能重新进入Open状态。</p>
<p>下面是这五种状态的转换图<br><img src="../../../../pictures/state/20170719170346.png" alt=""></p>
<h4 id="flag"><a href="#flag" class="headerlink" title="flag"></a>flag</h4><p>这里flag的介绍基本上是照搬kernel，只有少数地方做了中文注释，因为英文注释的很清楚了，我也就不啰嗦了。<br>@kernel version 4.10.13 /net/ipv4/tcp_input.c<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">#define FLAG_DATA       0x01 /* Incoming frame contained data.      */</div><div class="line">#define FLAG_WIN_UPDATE     0x02 /* Incoming ACK was a window update.   */</div><div class="line">#define FLAG_DATA_ACKED     0x04 /* This ACK acknowledged new data.     */</div><div class="line">#define FLAG_RETRANS_DATA_ACKED 0x08 /* 重传数据被ACK了。 */</div><div class="line">#define FLAG_SYN_ACKED      0x10 /* This ACK acknowledged SYN.      */</div><div class="line">#define FLAG_DATA_SACKED    0x20 /* New SACK.               */</div><div class="line">#define FLAG_ECE        0x40 /* ECE是用来表明TCP端是具备ECN功能的。  */</div><div class="line">#define FLAG_LOST_RETRANS   0x80 /* This ACK marks some retransmission lost */</div><div class="line">#define FLAG_SLOWPATH   0x100 /* Do not skip RFC checks for window update.*/</div><div class="line">#define FLAG_ORIG_SACK_ACKED 0x200 /* Never retransmitted data are (s)acked  */</div><div class="line">#define FLAG_SND_UNA_ADVANCED   0x400 /* Snd_una was changed (!= FLAG_DATA_ACKED) */</div><div class="line">#define FLAG_DSACKING_ACK   0x800 /* DSACK表示收到了重复数据  */</div><div class="line">#define FLAG_SACK_RENEGING  0x2000 /* snd_una advanced to a sacked seq */</div><div class="line">#define FLAG_UPDATE_TS_RECENT   0x4000 /* tcp_replace_ts_recent() */</div><div class="line"></div><div class="line">#define FLAG_ACKED      (FLAG_DATA_ACKED|FLAG_SYN_ACKED)</div><div class="line">#define FLAG_NOT_DUP        (FLAG_DATA|FLAG_WIN_UPDATE|FLAG_ACKED)</div><div class="line">#define FLAG_CA_ALERT       (FLAG_DATA_SACKED|FLAG_ECE)</div><div class="line">#define FLAG_FORWARD_PROGRESS   (FLAG_ACKED|FLAG_DATA_SACKED)</div><div class="line"></div><div class="line">#define TCP_REMNANT (TCP_FLAG_FIN|TCP_FLAG_URG|TCP_FLAG_SYN|TCP_FLAG_PSH)</div><div class="line">#define TCP_HP_BITS (~(TCP_RESERVED_BITS|TCP_FLAG_PSH))</div></pre></td></tr></table></figure></p>
<h4 id="tcp-skb-cb"><a href="#tcp-skb-cb" class="headerlink" title="tcp_skb_cb"></a>tcp_skb_cb</h4><p>这一块也主要是搬运的kernel，然后做些简单的注释，这一块和上面的flag的mark真正怎么在kernel被标记的，有点复杂，我读了好久的code，还是感到有点模糊。<br>@kernel version 4.10.13 /include/net/tcp.h<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">struct tcp_skb_cb &#123;</div><div class="line">    __u32       seq;        /* Starting sequence number */</div><div class="line">    __u32       end_seq;    /* SEQ + FIN + SYN + datalen    */</div><div class="line">    union &#123;</div><div class="line">        __u32   tcp_tw_isn;</div><div class="line">        struct &#123;</div><div class="line">            u16 tcp_gso_segs;</div><div class="line">            u16 tcp_gso_size;</div><div class="line">        &#125;;</div><div class="line">    &#125;;</div><div class="line">    __u32       when;       /* used to compute rtt&apos;s    */</div><div class="line"></div><div class="line">    __u8        sacked;     /* State flags for SACK/FACK.   */</div><div class="line">#define TCPCB_SACKED_ACKED  0x01    /* SKB ACK&apos;d by a SACK block    */</div><div class="line">#define TCPCB_SACKED_RETRANS    0x02    /* 是一个重传过的数据包  */</div><div class="line">#define TCPCB_LOST      0x04    /* 数据包丢了  */</div><div class="line">#define TCPCB_TAGBITS       0x07    /* All tag bits         */</div><div class="line">#define TCPCB_REPAIRED      0x10    /* SKB repaired (no skb_mstamp) */</div><div class="line">#define TCPCB_EVER_RETRANS  0x80    /* Ever retransmitted frame */</div><div class="line">#define TCPCB_RETRANS       (TCPCB_SACKED_RETRANS|TCPCB_EVER_RETRANS | </div><div class="line">                                       TCPCB_REPAINED)</div><div class="line"></div><div class="line">    __u8        ip_dsfield; /* IPv4 tos or IPv6 dsfield */</div><div class="line">    __u8        txstamp_ack:1,  /* Record TX timestamp for ack? */</div><div class="line">            eor:1,  /* Is skb MSG_EOR marked? */</div><div class="line">            unused:6;   /* Sequence number ACK&apos;d */</div><div class="line">    /* 1 byte hole */</div><div class="line">    __u32       ack_seq;    /* Sequence number ACK&apos;d    */</div><div class="line">    ......</div><div class="line">&#125;;</div><div class="line"></div><div class="line">#define TCP_SKB_CB(__skb)   ((struct tcp_skb_cb *)&amp;((__skb)-&gt;cb[0]))</div></pre></td></tr></table></figure></p>
<h4 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h4><p><a href="https://pdfs.semanticscholar.org/0e9c/968d09ab2e53e24c4dca5b2d67c7f7140f8e.pdf" target="_blank" rel="external">Congestion Control in Linux TCP</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇博客主要介绍TCP拥塞状态(state)在不同场景的转换及通过flag怎么识别是正常的ACK还是SACK，这一块知识比较杂乱，仔细看这部分内容，还是因为研究timeout问题需要。&lt;br&gt;
    
    </summary>
    
      <category term="TCP/IP" scheme="http://yoursite.com/categories/TCP-IP/"/>
    
    
  </entry>
  
  <entry>
    <title>TCP重点系列之sack处理</title>
    <link href="http://yoursite.com/2017/03/07/TCP%E9%87%8D%E7%82%B9%E7%B3%BB%E5%88%97%E4%B9%8Bsack%E5%A4%84%E7%90%86/"/>
    <id>http://yoursite.com/2017/03/07/TCP重点系列之sack处理/</id>
    <published>2017-03-07T07:46:48.000Z</published>
    <updated>2017-11-26T14:29:07.436Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;Linux kernel对收到sack的处理相比ack的处理要复杂的多。在receiver收到每个数据包后，都要walk一遍receiver window (rwnd)，将walk信息记录在ack包的sack选项中，然后发送给sender。sender处理sack的函数主要是tcp_sacktag_write_queue()，废话不多说，下面就来看看。<br><a id="more"></a></p>
<h4 id="宏定义"><a href="#宏定义" class="headerlink" title="宏定义"></a>宏定义</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">/* 相当于计算数组长度 */</div><div class="line">#define ARRAY_SIZE(arr) (sizeof(arr)/sizeof((arr)[0]) + __must_be_array(arr))</div><div class="line">#define TCP_SKB_CB(__skb)   (struct tcp_skb_cb *)&amp;((__skb)-&gt;cb[0])</div></pre></td></tr></table></figure>
<h4 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h4><p>@kernel version 4.10.13 /include/net/tcp.h<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">/*tcp_sack_block用于保存sack块*/</div><div class="line">struct tcp_sack_block &#123;</div><div class="line">    u32 start_seq; /* sack块的起始序号 */</div><div class="line">    u32 end_seq; /* sack块的结束序号 */</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">/*它是TCP协议的socket表示，是对struct inet_connection_sock的扩展。*/</div><div class="line">struct tcp_sock &#123;</div><div class="line">    ......</div><div class="line">    u32 lost_out;/* 丢包数 */</div><div class="line">    u32 sacked_out;/* 乱序数 */</div><div class="line">    u32 fackets_out;/* fackets_out = lost_out + sacked_out */</div><div class="line">    ......</div><div class="line">    /* recv_sack_cache[]保存的是之前的sack段，有助于提高效率 */</div><div class="line">    struct tcp_sack_block recv_sack_cache[4];</div><div class="line">    ......</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">/*存储着skb中所保存的tcp的控制信息*/</div><div class="line">struct tcp_skb_cb &#123;</div><div class="line">    __u32       seq;        /* 开始序号 */</div><div class="line">    __u32       end_seq;    /* SEQ + FIN + SYN + datalen    */</div><div class="line">    __u8        tcp_flags;  /* TCP header flags. (tcp[13])  */</div><div class="line">    ......</div><div class="line">    __u8        sacked;     /* State flags for SACK/FACK.   */</div><div class="line">    __u32       ack_seq;    /* Sequence number ACK&apos;d    */</div><div class="line">    ......</div><div class="line">&#125;;</div><div class="line"></div><div class="line">#define TCP_SKB_CB(__skb)   ((struct tcp_skb_cb *)&amp;((__skb)-&gt;cb[0]))</div></pre></td></tr></table></figure>
<h4 id="tcp-sacktag-write-queue-函数"><a href="#tcp-sacktag-write-queue-函数" class="headerlink" title="tcp_sacktag_write_queue()函数"></a>tcp_sacktag_write_queue()函数</h4><p>@kernel version 4.10.13 /net/ipv4/tcp_input.c<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div></pre></td><td class="code"><pre><div class="line">tcp_sacktag_write_queue(struct sock *sk, const struct sk_buff *ack_skb, u32 prior_snd_una, struct tcp_sacktag_state *state) </div><div class="line">&#123;</div><div class="line">    struct tcp_sock *tp = tcp_sk(sk);</div><div class="line">    /* 让指针ptr指向sack选项的起始地址 */</div><div class="line">    const unsigned char *ptr = (skb_transport_header(ack_skb) +</div><div class="line">                    TCP_SKB_CB(ack_skb)-&gt;sacked);</div><div class="line"></div><div class="line">    /* 在blog 《TCP重点系列之sack介绍》中说过，sack选项开头有两个字段，一个</div><div class="line">     * 是enabling option，一个是sackoption，ptr+2就是为了跳过这两个字段，指向</div><div class="line">     * sack的第一个段。 </div><div class="line">     */</div><div class="line">    struct tcp_sack_block_wire *sp_wire = (struct tcp_sack_block_wire *)(ptr+2);</div><div class="line"></div><div class="line">    /* TCP_NUM_SACKS是一个宏，值为4，sack最多只有4个段 */</div><div class="line">    struct tcp_sack_block sp[TCP_NUM_SACKS];</div><div class="line">    struct tcp_sack_block *cache;</div><div class="line">    struct sk_buff *skb;</div><div class="line"></div><div class="line">    /* nunm_sacks为sack段数（包括dsack），右移三位是因为一个sack段占8位 */</div><div class="line">    int num_sacks = min(TCP_NUM_SACKS, (ptr[1] - TCPOLEN_SACK_BASE) &gt;&gt; 3);</div><div class="line">    int used_sacks; /* 记录排除dsack后实际有效的sack块数 */</div><div class="line">    bool found_dup_sack = false;</div><div class="line">    int i, j;</div><div class="line">    int first_sack_index;</div><div class="line"></div><div class="line">    state-&gt;flag = 0; </div><div class="line">    state-&gt;reord = tp-&gt;packets_out;</div><div class="line"></div><div class="line">    /* sacked_out = 0, fackets_out必须等于0</div><div class="line">     * 如果开启了sack选项， 那么sacked_out表示被sack的乱序包的个数，</div><div class="line">     * 而fackets_out = lost_out + sacked_out.</div><div class="line">     */</div><div class="line">    if (!tp-&gt;sacked_out) &#123;</div><div class="line">        if (WARN_ON(tp-&gt;fackets_out))</div><div class="line">            tp-&gt;fackets_out = 0; </div><div class="line">        /* tp-&gt;highest_sack置为发送队列的第一个数据包，因为没有SACK快 */</div><div class="line">        tcp_highest_sack_reset(sk); </div><div class="line">    &#125;    </div><div class="line">    /* 检查第一个sack段是否为d-sack */</div><div class="line">    found_dup_sack = tcp_check_dsack(sk, ack_skb, sp_wire,</div><div class="line">                     num_sacks, prior_snd_una);</div><div class="line">    /* 如果是d-sack，则打上d-sack标志 */</div><div class="line">    if (found_dup_sack) &#123;</div><div class="line">        state-&gt;flag |= FLAG_DSACKING_ACK;</div><div class="line">        /* google BBR算法有用到delivered计算即时带宽 */</div><div class="line">        tp-&gt;delivered++; /* A spurious retransmission is delivered */</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    /* Eliminate too old ACKs, but take into</div><div class="line">     * account more or less fresh ones, they can</div><div class="line">     * contain valid SACK info.</div><div class="line">     */</div><div class="line">     /* 无效的ACK */</div><div class="line">    if (before(TCP_SKB_CB(ack_skb)-&gt;ack_seq, prior_snd_una - tp-&gt;max_window))</div><div class="line">        return 0;</div><div class="line">    /* packets_out为0表示网络中没有包，那么跳转到out */</div><div class="line">    if (!tp-&gt;packets_out)</div><div class="line">        goto out;</div><div class="line">    </div><div class="line">    /* 开始遍历sack段 */</div><div class="line">    used_sacks = 0;</div><div class="line">    first_sack_index = 0;</div><div class="line">    for (i = 0; i &lt; num_sacks; i++) &#123;</div><div class="line">        /* 只有当i为0且found_dup_sack为1时，dup_sack才为真，i为0表示是第一块，</div><div class="line">         * 因为d-sack都记录在sack快的第一块 */</div><div class="line">        bool dup_sack = !i &amp;&amp; found_dup_sack;</div><div class="line"></div><div class="line">        /* 将sack块复制到结构体sp中 */</div><div class="line">        sp[used_sacks].start_seq = get_unaligned_be32(&amp;sp_wire[i].start_seq);</div><div class="line">        sp[used_sacks].end_seq = get_unaligned_be32(&amp;sp_wire[i].end_seq);</div><div class="line"></div><div class="line">        /* 检查sack块的有效性 */</div><div class="line">        if (!tcp_is_sackblock_valid(tp, dup_sack,</div><div class="line">                        sp[used_sacks].start_seq,</div><div class="line">                        sp[used_sacks].end_seq)) &#123;</div><div class="line">            int mib_idx;</div><div class="line">            /* 如果是d-sack */</div><div class="line">            if (dup_sack) &#123;</div><div class="line">                /* undo_maker是拥塞撤销标志 */</div><div class="line">                if (!tp-&gt;undo_marker)</div><div class="line">                    /* undo_maker为0表示取消撤销 */</div><div class="line">                    mib_idx = LINUX_MIB_TCPDSACKIGNOREDNOUNDO;//还没搞懂</div><div class="line">                else</div><div class="line">                    mib_idx = LINUX_MIB_TCPDSACKIGNOREDOLD;//还没搞懂</div><div class="line">            &#125; else &#123;</div><div class="line">                /* Don&apos;t count olds caused by ACK reordering */</div><div class="line">              if ((TCP_SKB_CB(ack_skb)-&gt;ack_seq != tp-&gt;snd_una) &amp;&amp;</div><div class="line">                    !after(sp[used_sacks].end_seq, tp-&gt;snd_una))</div><div class="line">                    continue;</div><div class="line">                mib_idx = LINUX_MIB_TCPSACKDISCARD;</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            NET_INC_STATS_BH(sock_net(sk), mib_idx);</div><div class="line">            if (i == 0)</div><div class="line">                first_sack_index = -1;</div><div class="line">            continue;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        /* Ignore very old stuff early 忽略已确认过的块 */</div><div class="line">        if (!after(sp[used_sacks].end_seq, prior_snd_una))</div><div class="line">            continue;</div><div class="line"></div><div class="line">        used_sacks++;/* 实际有效的sack块数 */</div><div class="line">    &#125;</div><div class="line"> </div><div class="line">    /* order SACK blocks to allow in order walk of the retrans queue </div><div class="line">     * 对实际使用的SACK块，按起始序列号，从小到大进行冒泡排序</div><div class="line">     */</div><div class="line">    for (i = used_sacks - 1; i &gt; 0; i--) &#123;</div><div class="line">        for (j = 0; j &lt; i; j++) &#123;</div><div class="line">            if (after(sp[j].start_seq, sp[j + 1].start_seq)) &#123;</div><div class="line">                swap(sp[j], sp[j + 1]); /* 交换sack块 */</div><div class="line"></div><div class="line">                /* Track where the first SACK block goes to */</div><div class="line">                if (j == first_sack_index) //</div><div class="line">                    first_sack_index = j + 1;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    /* skb指向发送队列的第一个包 */</div><div class="line">    skb = tcp_write_queue_head(sk);</div><div class="line">    state-&gt;fack_count = 0;</div><div class="line">    i = 0;</div><div class="line"></div><div class="line">    /* 如果没有乱序，那么之前保存的sack段就没有价值，所以将cache指向数组尾，</div><div class="line">     * 后面会给出关系图说明。</div><div class="line">     */</div><div class="line">    if (!tp-&gt;sacked_out) &#123;</div><div class="line">        /* It&apos;s already past, so skip checking against it */</div><div class="line">        cache = tp-&gt;recv_sack_cache + ARRAY_SIZE(tp-&gt;recv_sack_cache);</div><div class="line">    &#125; else &#123;</div><div class="line">        /* 如果有乱序，那么跳过空的block */</div><div class="line">        cache = tp-&gt;recv_sack_cache;</div><div class="line">        /* Skip empty blocks in at head of the cache */</div><div class="line">        while (tcp_sack_cache_ok(tp, cache) &amp;&amp; !cache-&gt;start_seq &amp;&amp;</div><div class="line">               !cache-&gt;end_seq)</div><div class="line">            cache++;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    /* 遍历实际有效的sack块 */</div><div class="line">    while (i &lt; used_sacks) &#123;</div><div class="line">        u32 start_seq = sp[i].start_seq;</div><div class="line">        u32 end_seq = sp[i].end_seq;</div><div class="line">        bool dup_sack = (found_dup_sack &amp;&amp; (i == first_sack_index));</div><div class="line">        struct tcp_sack_block *next_dup = NULL;</div><div class="line"></div><div class="line">        if (found_dup_sack &amp;&amp; ((i + 1) == first_sack_index))</div><div class="line">            next_dup = &amp;sp[i + 1];</div><div class="line"></div><div class="line">        /* Skip too early cached blocks </div><div class="line">         * 如果cache指向的块的结束序号小于当前sack块的开始序号，那比较下一个</div><div class="line">         * cache指向的下一个块。</div><div class="line">         */</div><div class="line">        while (tcp_sack_cache_ok(tp, cache) &amp;&amp;</div><div class="line">               !before(start_seq, cache-&gt;end_seq))</div><div class="line">            cache++;</div><div class="line"></div><div class="line">        /* Can skip some work by looking recv_sack_cache?</div><div class="line">         * 查看cache指向的块和当前sack块有无交集，避免重复工作。</div><div class="line">         */</div><div class="line">        if (tcp_sack_cache_ok(tp, cache) &amp;&amp; !dup_sack &amp;&amp;</div><div class="line">            after(end_seq, cache-&gt;start_seq)) &#123;</div><div class="line"></div><div class="line">            /* Head todo? 处理start_seq到cache-&gt;start_seq之间的段 */</div><div class="line">            if (before(start_seq, cache-&gt;start_seq)) &#123;</div><div class="line">                /* 跳到start_seq对应的数据段 */</div><div class="line">                skb = tcp_sacktag_skip(skb, sk, &amp;state, start_seq);</div><div class="line">                /* 遍历start_seq到cache-&gt;start_seq之间的段 */</div><div class="line">                skb = tcp_sacktag_walk(skb, sk, next_dup,</div><div class="line">                               &amp;state,</div><div class="line">                               start_seq,</div><div class="line">                               cache-&gt;start_seq,</div><div class="line">                               dup_sack);</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            /* Rest of the block already fully processed?</div><div class="line">             * 如果sack块剩下的部分完全包含在cache快中，就直接跳转到advance_sp</div><div class="line">             */</div><div class="line">            if (!after(end_seq, cache-&gt;end_seq))</div><div class="line">                goto advance_sp;</div><div class="line"></div><div class="line">            skb = tcp_maybe_skipping_dsack(skb, sk, next_dup,</div><div class="line">                               &amp;state,</div><div class="line">                               cache-&gt;end_seq);</div><div class="line"></div><div class="line">            /* ...tail remains todo... */</div><div class="line">            if (tcp_highest_sack_seq(tp) == cache-&gt;end_seq) &#123;</div><div class="line">                /* ...but better entrypoint exists! */</div><div class="line">                /* skb指向highest sack sequence nunmber */</div><div class="line">                skb = tcp_highest_sack(sk);</div><div class="line">                /* skb=NULL，表明sack块已经遍历完了 */</div><div class="line">                if (!skb)</div><div class="line">                    break;</div><div class="line">                state-&gt;fack_count = tp-&gt;fackets_out;</div><div class="line">                cache++;/* cache指向下一个块 */</div><div class="line">                goto walk;/* 继续和更新后的cache比较 */</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            /* 找到end_seq &gt; cache-&gt;end_seq的skb */</div><div class="line">            skb = tcp_sacktag_skip(skb, sk, &amp;state, cache-&gt;end_seq);</div><div class="line">            /* Check overlap against next cached too (past this one already) */</div><div class="line">            cache++;/* 比较cache指向的下一个块*/</div><div class="line">            continue;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        /* */</div><div class="line">        if (!before(start_seq, tcp_highest_sack_seq(tp))) &#123;</div><div class="line">            skb = tcp_highest_sack(sk);</div><div class="line">            if (!skb)</div><div class="line">                break;</div><div class="line">            state-&gt;fack_count = tp-&gt;fackets_out;</div><div class="line">        &#125;</div><div class="line">        /* skb跳到start_seq处 */</div><div class="line">        skb = tcp_sacktag_skip(skb, sk, &amp;state, start_seq);</div><div class="line"></div><div class="line">walk:</div><div class="line">        skb = tcp_sacktag_walk(skb, sk, next_dup, &amp;state,</div><div class="line">                       start_seq, end_seq, dup_sack);</div><div class="line"></div><div class="line">advance_sp:</div><div class="line">        i++;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    /* Clear the head of the cache sack blocks so we can skip it next time </div><div class="line">     * 清除recv_sack_cache中旧的sack块，保存当前的sack块</div><div class="line">     */</div><div class="line">    for (i = 0; i &lt; ARRAY_SIZE(tp-&gt;recv_sack_cache) - used_sacks; i++) &#123;</div><div class="line">        tp-&gt;recv_sack_cache[i].start_seq = 0;</div><div class="line">        tp-&gt;recv_sack_cache[i].end_seq = 0;</div><div class="line">    &#125;</div><div class="line">    for (j = 0; j &lt; used_sacks; j++)</div><div class="line">        tp-&gt;recv_sack_cache[i++] = sp[j];</div><div class="line"></div><div class="line">    if ((state-&gt;reord &lt; tp-&gt;fackets_out) &amp;&amp;</div><div class="line">        ((inet_csk(sk)-&gt;icsk_ca_state != TCP_CA_Loss) || tp-&gt;undo_marker))</div><div class="line">        /* 更新乱序长度 */</div><div class="line">        tcp_update_reordering(sk, tp-&gt;fackets_out - state-&gt;reord, 0);</div><div class="line"></div><div class="line">    tcp_verify_left_out(tp);</div><div class="line"></div><div class="line">out:</div><div class="line"></div><div class="line">#if FASTRETRANS_DEBUG &gt; 0</div><div class="line">    WARN_ON((int)tp-&gt;sacked_out &lt; 0);</div><div class="line">    WARN_ON((int)tp-&gt;lost_out &lt; 0);</div><div class="line">    WARN_ON((int)tp-&gt;retrans_out &lt; 0);</div><div class="line">    WARN_ON((int)tcp_packets_in_flight(tp) &lt; 0);</div><div class="line">#endif</div><div class="line">    return state-&gt;flag;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h4 id="相关函数"><a href="#相关函数" class="headerlink" title="相关函数"></a>相关函数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">@kernel version 4.10.13 /net/ipv4/tcp_input.c</div><div class="line">static bool tcp_check_dsack(struct sock *sk, const struct sk_buff *ack_skb, </div><div class="line">        struct tcp_sack_block_wire *sp, int num_sacks, u32 prior_snd_una)</div><div class="line">&#123;</div><div class="line">    struct tcp_sock *tp=tcp_sk(sk);</div><div class="line">    u32 start_seq_0 = get_unaligned_be32(&amp;sp[0].start_seq);</div><div class="line">    u32 end_seq_0 = get_unaligned_be32(&amp;sp[0].end_seq);</div><div class="line">    bool = dup_sack = false;</div><div class="line"></div><div class="line">    /* sack块的起始sequence number小于当前ack的sequence number，是一个dsack */</div><div class="line">    if (before(start_seq_0, TCP_SKB_CB(ack_skb)-&gt;ack_seq)) &#123;</div><div class="line">        dup_sack = true;</div><div class="line">        tcp_dsack_seen(tp);</div><div class="line">        NET_INC_STATS(sock_net(sk), LINUX_MIB_TCPDSACKRECV);</div><div class="line">    &#125; else if &#123;</div><div class="line">        u32 end_seq_1 = get_unaligned_be32(&amp;sp[1].end_seq);</div><div class="line">        u32 start_seq_1 = get_unaligned_be32(&amp;sp[1].start_seq);</div><div class="line">        /* 第一个sack块包含在第二个sack块中，是一个dsack */</div><div class="line">        if (!after(end_seq_0, end_seq_1) &amp;&amp; !before(start_seq_0, start_seq_1)) &#123;</div><div class="line">            dup_sack = true;</div><div class="line">            tcp_dsack_seen(tp);</div><div class="line">            NET_INC_STATS(sock_net(sk), LINUX_MIB_TCPDSACKOFORECV);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    if (dup_sack &amp;&amp; tp-&gt;undo_marker &amp;&amp; tp-&gt;undo_retrans &gt; 0 &amp;&amp; !after(end_seq_0, prior_snd_una) &amp;&amp; after(end_seq_0, tp-&gt;undo_marker))</div><div class="line">        tp-&gt;undo_retrans--;</div><div class="line"></div><div class="line">    return dup_sack;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">static int tcp_sack_cache_ok(const struct tcp_sock *tp, const struct tcp_sack_block *cache)</div><div class="line">&#123;</div><div class="line">    return cache &lt; tp-&gt;recv_sack_cache + ARRAY_SIZE(tp-&gt;recv_sack_cache);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">static struct sk_buff *tcp_sacktag_skip(struct sk_buff *skb, struct sock *sk, struct tcp_sacktag_state *state, u32 skip_to_seq)</div><div class="line">&#123;</div><div class="line">    tcp_for_write_queue_from(skb, sk) &#123;</div><div class="line">        if (skb == tcp_send_head(sk))</div><div class="line">            break;</div><div class="line">        if (after(TCP_SKB_CB(skb)-&gt;end_seq, skip_to_seq))</div><div class="line">            break;</div><div class="line"></div><div class="line">        state-&gt;fack_count += tcp_skb_pcount(skb);</div><div class="line">    &#125;</div><div class="line">    return skb;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;Linux kernel对收到sack的处理相比ack的处理要复杂的多。在receiver收到每个数据包后，都要walk一遍receiver window (rwnd)，将walk信息记录在ack包的sack选项中，然后发送给sender。sender处理sack的函数主要是tcp_sacktag_write_queue()，废话不多说，下面就来看看。&lt;br&gt;
    
    </summary>
    
      <category term="TCP/IP" scheme="http://yoursite.com/categories/TCP-IP/"/>
    
    
  </entry>
  
  <entry>
    <title>TCP重点系列之sack介绍</title>
    <link href="http://yoursite.com/2017/03/01/TCP%E9%87%8D%E7%82%B9%E7%B3%BB%E5%88%97%E4%B9%8Bsack%E4%BB%8B%E7%BB%8D/"/>
    <id>http://yoursite.com/2017/03/01/TCP重点系列之sack介绍/</id>
    <published>2017-03-01T12:04:16.000Z</published>
    <updated>2017-08-23T09:08:36.210Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;在早期的TCP拥塞控制中都是通过收到duplicate ack（默认3个）来trigger fast retransmition，但是当有多个丢包时，这样每次重传一个包，收到重传包的ack后，再通过 duplicate ack trigger retransmit下一个包，容易造成timeout，于是有人提出了sack来解决这个问题。<br><a id="more"></a></p>
<h4 id="什么是sack"><a href="#什么是sack" class="headerlink" title="什么是sack"></a>什么是sack</h4><p>&emsp;&emsp;sack的全称是selective acknowledgment，也就是选择性确认，添加sack功能需要在TCP包<br>头加两个选项，一个是开启选项（enabling option），另一个是sack选项（sack option）本身。开启sack选项后，receiver会将自己收到了哪些包，没收到哪些包的信息记录在sack段中告诉给sender，这样sender便可以一次性重传所有的丢包。</p>
<h4 id="enabling-option"><a href="#enabling-option" class="headerlink" title="enabling option"></a>enabling option</h4><p>enabling option是一个占两字节的选项，在建立连接时通过SYN来告诉对方自己是否支持sack。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">TCP Sack-Permitted Option</div><div class="line">Kind: 4</div><div class="line">+-----------+------------+</div><div class="line">|  Kind = 4 | Length = 2 |</div><div class="line">+-----------+------------+</div></pre></td></tr></table></figure></p>
<h4 id="sack-option"><a href="#sack-option" class="headerlink" title="sack option"></a>sack option</h4><p>开启sack后，从receiver向sender发送的ack会在sack option字段中携带一些确认信息，<br>而不是单纯的duplicate ack。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">TCP SACK Option</div><div class="line">Kind: 5</div><div class="line">Length: Variable</div><div class="line">                          +-------------+-------------+</div><div class="line">                          | Kind = 5    |   Length    |</div><div class="line">+------------+------------+-------------+-------------+</div><div class="line">|            Left Edge of list Block                  |</div><div class="line">+------------+------------+-------------+-------------+</div><div class="line">|            Right Edge of list Block                 |</div><div class="line">+------------+------------+-------------+-------------+</div><div class="line">|                                                     |</div><div class="line">/                      .  .  .                        /</div><div class="line">|                                                     |</div><div class="line">+------------+------------+-------------+-------------+</div><div class="line">|            Left Edge of list Block                  |</div><div class="line">+------------+------------+-------------+-------------+</div><div class="line">|            Right Edge of list Block                 |</div><div class="line">+------------+------------+-------------+-------------+</div></pre></td></tr></table></figure></p>
<p>sack选项一般占40字节，其中kind占4字节，length占4字节，剩下32字节，每8字节为一个sack段，一个sack段用来记录一个连续block的开始序号和结束序号，所以最多只能记录4段连续的block。在实际情况中，经常会最多只有三段block，因为sack会经常与时间戳选项结合，用于测量RTT，这需要占用额外的8字节。</p>
<h4 id="为什么要引入sack"><a href="#为什么要引入sack" class="headerlink" title="为什么要引入sack"></a>为什么要引入sack</h4><p>&emsp;&emsp;在早期的TCP拥塞控制中，通过收到duplicate ack（默认为3个），连续三次ack某一个包来告诉sender某个丢包了，然后进入fast retransmition state，sender重传这个包，当receiver收到这个重传包后，便会发一个ack（ack新的包）给sender，告诉sender下一个要发送的包是哪一个。可以看到，通过duplicate ack每次只能重传一个包，如果有多个丢包，在等待重传过程中，很容易timeout，造成带宽利用率下降（underutilized）。<br>&emsp;&emsp;而如果开启sack，每一个sack段记录的是已经收到的连续的包，sack段与sack段之间断片的，也就是还没收到的（可能已经丢失，也可能是reorder）。通过sack段便可以知道多个可能已经丢失的包，这样便可以一次性的重传，而不是一个一个重传，避免因等待时间长造成的timeout问题。<br>&emsp;&emsp;要注意的是开启sack选项，也是有弊端的，因为丢包意味着网络很可能已经拥塞，这时如果一次重传多个包，很可能会造成网络更加拥塞。</p>
<h4 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h4><p><a href="https://tools.ietf.org/pdf/rfc2018.pdf" target="_blank" rel="external">RFC 2018 TCP Selective Acknowledgment Options</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;在早期的TCP拥塞控制中都是通过收到duplicate ack（默认3个）来trigger fast retransmition，但是当有多个丢包时，这样每次重传一个包，收到重传包的ack后，再通过 duplicate ack trigger retransmit下一个包，容易造成timeout，于是有人提出了sack来解决这个问题。&lt;br&gt;
    
    </summary>
    
      <category term="TCP/IP" scheme="http://yoursite.com/categories/TCP-IP/"/>
    
    
  </entry>
  
  <entry>
    <title>TCP重点系列之快速重传tcp_fastretrans_alert</title>
    <link href="http://yoursite.com/2017/02/14/TCP%E9%87%8D%E7%82%B9%E7%B3%BB%E5%88%97%E4%B9%8B%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0/"/>
    <id>http://yoursite.com/2017/02/14/TCP重点系列之快速重传/</id>
    <published>2017-02-14T03:11:15.000Z</published>
    <updated>2017-07-19T01:57:07.019Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要分析在TCP拥塞状态机的实现中，丢包后进入快速重传时，主要函数tcp_fastretrans_alert()的实现，及对一些相关函数也做了介绍。<br><a id="more"></a></p>
<h4 id="变量介绍"><a href="#变量介绍" class="headerlink" title="变量介绍"></a>变量介绍</h4><p>@kernel version 4.10.13 /include/net/tcp.h<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">u32 packets_out; /* 表示离开网络但没被确认的包 */</div><div class="line">u32 sacked_out; </div><div class="line">/* Packets, which arrived to receiver out of order and hence not ACKed.</div><div class="line"> * With SACK this number is simply amount of SACKed data. Even withou</div><div class="line"> * SACKs it is easy to give pretty reliable estimate of this number, counting</div><div class="line"> * duplicate ACKs.</div><div class="line"> * 上面是sacked_out的英文解释，其实应该分两种情况来看，开和没开SACK选项：</div><div class="line"> * 如果开了SACK选项，那么这个值无疑就是表示被SACK的乱序包的个数，</div><div class="line"> * 如果没开SACK选项，那么该值就是表示dupack的个数。具体可参考tcp_add_reno_sack()函数相关代码.</div><div class="line"> */</div><div class="line">u32 fackets_out;/* SACK数和丢失包的总和，fackets_out = lost_out + sacked_out */</div></pre></td></tr></table></figure></p>
<h4 id="tcp-fastretrans-alert-函数被调用条件"><a href="#tcp-fastretrans-alert-函数被调用条件" class="headerlink" title="tcp_fastretrans_alert()函数被调用条件"></a>tcp_fastretrans_alert()函数被调用条件</h4><p>(1) 每一个到来的ACK，其状态不是Open.<br>(2) ACK不是普通ack，即是：<br>    SACK，<br>    Duplicate ACK，<br>    ECE ECN</p>
<h4 id="tcp-fastretrans-alert-函数实现细节"><a href="#tcp-fastretrans-alert-函数实现细节" class="headerlink" title="tcp_fastretrans_alert()函数实现细节"></a>tcp_fastretrans_alert()函数实现细节</h4><p>@kernel version 4.10.13 /net/ipv4/tcp_input.c<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div></pre></td><td class="code"><pre><div class="line">static void tcp_fastretrans_alert(struct sock *sk, int pkts_acked,</div><div class="line">                   bool is_dupack, int *ack_flag, int *rexmit)</div><div class="line">&#123;</div><div class="line">    struct inet_connection_sock *icsk = inet_csk(sk);</div><div class="line">    struct tcp_sock *tp = tcp_sk(sk);</div><div class="line">    int fast_rexmit = 0, flag = *ack_flag;</div><div class="line">    /* is_dupack表示重复ack，FLAG_DATA_SACKED表示SACK中添加了新的数据*/</div><div class="line">    int do_lost = is_dupack || ((flag &amp; FLAG_DATA_SACKED) &amp;&amp;</div><div class="line">                    (tcp_fackets_out(tp) &gt; tp-&gt;reordering));</div><div class="line"></div><div class="line">    /* 如果packets_out为0，但sacked_out不为0，那么sacked_out应改为0 */</div><div class="line">    if (WARN_ON(!tp-&gt;packets_out &amp;&amp; tp-&gt;sacked_out))</div><div class="line">        tp-&gt;sacked_out = 0; </div><div class="line">    /* 如果sacked_out为0， 那么fackets_out应为0 */</div><div class="line">    if (WARN_ON(!tp-&gt;sacked_out &amp;&amp; tp-&gt;fackets_out))</div><div class="line">        tp-&gt;fackets_out = 0; </div><div class="line"></div><div class="line">    /* Now state machine starts.</div><div class="line">     * A. ECE, hence prohibit cwnd undoing, the reduction is required. </div><div class="line">     * 禁止cwnd撤销，并减小cwnd.</div><div class="line">     */</div><div class="line">    if (flag &amp; FLAG_ECE)</div><div class="line">        tp-&gt;prior_ssthresh = 0; </div><div class="line"></div><div class="line">    /* B. In all the states check for reneging SACKs.</div><div class="line">     * 检查是否为虚假SACK，虚假SACK是指：最新收到的ACK的ack_seq指向已记录的SACK</div><div class="line">     * 块，这说明记录的SACK并没有反应接收方的真实的状态.</div><div class="line">     */</div><div class="line">    if (tcp_check_sack_reneging(sk, flag))</div><div class="line">        return;</div><div class="line"></div><div class="line">    /* C. Check consistency of the current state. </div><div class="line">     * 丢失的包应该比发送出去的包少，即left_out &lt; packets_out.</div><div class="line">     */</div><div class="line">    tcp_verify_left_out(tp);</div><div class="line"></div><div class="line">    /* D. Check state exit conditions. State can be terminated</div><div class="line">     *    when high_seq is ACKed. </div><div class="line">     * 如果state = TCP_CA_Open，就不应该有重传包.</div><div class="line">     */</div><div class="line">    if (icsk-&gt;icsk_ca_state == TCP_CA_Open) &#123;</div><div class="line">        WARN_ON(tp-&gt;retrans_out != 0);</div><div class="line">        tp-&gt;retrans_stamp = 0; //将重传发送时间置0.</div><div class="line">        /* 如果snd_una &gt;= high_seq，state接下来应该从其他状态返回到Open状态 */</div><div class="line">    &#125; else if (!before(tp-&gt;snd_una, tp-&gt;high_seq)) &#123;</div><div class="line">        /* state的几种不同值表示网络处在不同的状态，在这篇blog[]()中有详细介绍. */</div><div class="line">        switch (icsk-&gt;icsk_ca_state) &#123;</div><div class="line">        case TCP_CA_CWR:</div><div class="line">            /* CWR is to be held something *above* high_seq</div><div class="line">             * is ACKed for CWR bit to reach receiver. */</div><div class="line">             /* 如果snd_una &gt; high_seq，结束快速重传，返回Open状态 */</div><div class="line">            if (tp-&gt;snd_una != tp-&gt;high_seq) &#123;</div><div class="line">                tcp_end_cwnd_reduction(sk);</div><div class="line">                tcp_set_ca_state(sk, TCP_CA_Open);</div><div class="line">            &#125;</div><div class="line">            break;</div><div class="line"></div><div class="line">        case TCP_CA_Recovery:</div><div class="line">            if (tcp_is_reno(tp)) /* 不是sack */</div><div class="line">                tcp_reset_reno_sack(tp); /* 重置sack_out = 0 */</div><div class="line">            if (tcp_try_undo_recovery(sk)) /* 尝试撤销 */</div><div class="line">                return;</div><div class="line">            /* 结束快速重传 */    </div><div class="line">            tcp_end_cwnd_reduction(sk);</div><div class="line">            break;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    if (sysctl_tcp_recovery &amp; TCP_RACK_LOST_RETRANS &amp;&amp; tcp_rack_mark_(sk)) &#123;</div><div class="line">        flag |= FLAG_LOST_RETRANS;</div><div class="line">        *ack_flag |= FLAG_LOST_RETRANS;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    /* 非正常ack处理情况 */</div><div class="line">    /* E. Process state. */</div><div class="line">    switch (icsk-&gt;icsk_ca_state) &#123;</div><div class="line">    case TCP_CA_Recovery:</div><div class="line">        /* FLAG_SND_UNA_ADVANCED表示snd_una更新了 */</div><div class="line">        if (!(flag &amp; FLAG_SND_UNA_ADVANCED)) &#123;</div><div class="line">            /* 不是sack，是一个dupack则增加sacked_out */</div><div class="line">            if (tcp_is_reno(tp) &amp;&amp; is_dupack)</div><div class="line">                tcp_add_reno_sack(sk);</div><div class="line">        &#125; else &#123;</div><div class="line">            if (tcp_try_undo_partial(sk, acked))</div><div class="line">                do_lost = tcp_is_reno(tp) || </div><div class="line">                    tcp_fackets_out(tp) &gt; tp-&gt;reordering;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        if (tcp_try_undo_dsack(sk)) &#123;</div><div class="line">            tcp_try_keep_open(sk);</div><div class="line">            return;</div><div class="line">        &#125;</div><div class="line">        break;</div><div class="line">        /* timeout后的处理*/</div><div class="line">    case TCP_CA_Loss:</div><div class="line">        tcp_process_loss(sk, flag, is_dupack, rexmit);</div><div class="line">        if (icsk-&gt;icsk_ca_state != TCP_CA_Open &amp;&amp; !(flag &amp; FLAG_LOST_RETRANS))</div><div class="line">            return;</div><div class="line">        /* Fall through to processing in Open state. */</div><div class="line">    default:</div><div class="line">        if (tcp_is_reno(tp)) &#123;</div><div class="line">            if (flag &amp; FLAG_SND_UNA_ADVANCED)</div><div class="line">                tcp_reset_reno_sack(tp); /* 重置sacked_out = 0 */</div><div class="line">            if (is_dupack)</div><div class="line">                tcp_add_reno_sack(sk);</div><div class="line">        &#125;</div><div class="line">    </div><div class="line">        if (icsk-&gt;icsk_ca_state &lt;= TCP_CA_Disorder)</div><div class="line">            tcp_try_undo_dsack(sk);</div><div class="line"></div><div class="line">        if (!tcp_time_to_recover(sk, flag)) &#123;</div><div class="line">            tcp_try_to_open(sk, flag);</div><div class="line">            return;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        /* MTU probe failure: don&apos;t reduce cwnd */</div><div class="line">        if (icsk-&gt;icsk_ca_state &lt; TCP_CA_CWR &amp;&amp;</div><div class="line">            icsk-&gt;icsk_mtup.probe_size &amp;&amp;</div><div class="line">            tp-&gt;snd_una == tp-&gt;mtu_probe.probe_seq_start) &#123;</div><div class="line">            tcp_mtup_probe_failed(sk);</div><div class="line">            /* Restores the reduction we did in tcp_mtup_probe() */</div><div class="line">            tp-&gt;snd_cwnd++;</div><div class="line">            tcp_simple_retransmit(sk);/* 做一个简单的转发，而不使用回退机制 */</div><div class="line">            return;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        /* Otherwise enter Recovery state */</div><div class="line">        tcp_enter_recovery(sk, (flag &amp; FLAG_ECE)); /* 进入恢复状态 */</div><div class="line">        fast_rexmit = 1;/* 快速重传标志 */</div><div class="line">    &#125;</div><div class="line">    /* 打上lost标志 */</div><div class="line">    if (do_lost) &#123;</div><div class="line">        /* 更新记分牌，标记丢失和超时的数据包 */</div><div class="line">        tcp_update_scoreboard(sk, fast_rexmit);</div><div class="line">    &#125;</div><div class="line">    /* 重传有lost标志的包 */</div><div class="line">    tcp_xmit_retransmit_queue(sk);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h4 id="tcp-add-reno-sack-函数"><a href="#tcp-add-reno-sack-函数" class="headerlink" title="tcp_add_reno_sack()函数"></a>tcp_add_reno_sack()函数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">/* Emulate SACKs for SACKless connection: account for a new dupack. */</div><div class="line"></div><div class="line">static void tcp_add_reno_sack(struct sock *sk)</div><div class="line">&#123;</div><div class="line">    struct tcp_sock *tp = tcp_sk(sk);</div><div class="line">    u32 prior_sacked = tp-&gt;sacked_out;</div><div class="line"></div><div class="line">    tp-&gt;sacked_out++; /* 收到重复ack，sacked_out++*/</div><div class="line">    /* 检查乱序情况，该函数具体定义在下面介绍 */</div><div class="line">    tcp_check_reno_reordering(sk, 0); </div><div class="line">    if (tp-&gt;sacked_out &gt; prior_sacked)</div><div class="line">        /* some out_of-order packet is delivered. */</div><div class="line">        tp-&gt;delivered++; </div><div class="line">    tcp_verify_left_out(tp);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="tcp-check-reno-reordering-函数"><a href="#tcp-check-reno-reordering-函数" class="headerlink" title="tcp_check_reno_reordering()函数"></a>tcp_check_reno_reordering()函数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">/* If we receive more dupacks than we expected counting segments</div><div class="line"> * in assumption of absent reordering, interpret this as reordering.</div><div class="line"> * The only another reason could be bug in receiver TCP.</div><div class="line"> */</div><div class="line">static void tcp_check_reno_reordering(struct sock *sk, const int addend)</div><div class="line">&#123;</div><div class="line">    struct tcp_sock *tp = tcp_sk(sk);</div><div class="line">    /* 检查sack的数量是否超过了限度，是则更新reordering */</div><div class="line">    if (tcp_limit_reno_sacked(tp))</div><div class="line">        tcp_update_reordering(sk, tp-&gt;packets_out + addend, 0);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="tcp-limit-reno-sacked-函数"><a href="#tcp-limit-reno-sacked-函数" class="headerlink" title="tcp_limit_reno_sacked()函数"></a>tcp_limit_reno_sacked()函数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">/* Limits sacked_out so that sum with lost_out isn&apos;t ever larger than</div><div class="line"> * packets_out. Returns false if sacked_out adjustement wasn&apos;t necessary.</div><div class="line"> */</div><div class="line">static bool tcp_limit_reno_sacked(struct tcp_sock *tp) </div><div class="line">&#123;</div><div class="line">    u32 holes;</div><div class="line"></div><div class="line">    holes = max(tp-&gt;lost_out, 1U); </div><div class="line">    holes = min(holes, tp-&gt;packets_out);</div><div class="line"></div><div class="line">    if ((tp-&gt;sacked_out + holes) &gt; tp-&gt;packets_out) &#123;</div><div class="line">        tp-&gt;sacked_out = tp-&gt;packets_out - holes;</div><div class="line">        return true;</div><div class="line">    &#125;    </div><div class="line">    return false;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="tcp-update-scoreboard-函数"><a href="#tcp-update-scoreboard-函数" class="headerlink" title="tcp_update_scoreboard()函数"></a>tcp_update_scoreboard()函数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">/* Account newly detected lost packet(s) */</div><div class="line">static void tcp_update_scoreboard(struct sock *sk, int fast_rexmit)</div><div class="line">&#123;</div><div class="line">    struct tcp_sock *tp = tcp_sk(sk);</div><div class="line"></div><div class="line">    if (tcp_is_reno(tp)) &#123;/* 不是SACK */</div><div class="line">        tcp_mark_head_lost(sk, 1, 1);/* 标记一个丢失 */</div><div class="line">    &#125; else if (tcp_is_fack(tp)) &#123;/* 如果是fack */</div><div class="line">        int lost = tp-&gt;fackets_out - tp-&gt;reordering;/* 计算所有的丢包数 */</div><div class="line">        if (lost &lt;= 0)</div><div class="line">            lost = 1; </div><div class="line">        tcp_mark_head_lost(sk, lost, 0);/* 给所有丢包打标记 */</div><div class="line">    &#125; else &#123;/* 是一个简单的sack */</div><div class="line">        int sacked_upto = tp-&gt;sacked_out - tp-&gt;reordering;</div><div class="line">        if (sacked_upto &gt;= 0)</div><div class="line">            tcp_mark_head_lost(sk, sacked_upto, 0);</div><div class="line">        else if (fast_rexmit)</div><div class="line">            tcp_mark_head_lost(sk, 1, 1);</div><div class="line">    &#125;    </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="tcp-mark-head-lost-函数"><a href="#tcp-mark-head-lost-函数" class="headerlink" title="tcp_mark_head_lost()函数"></a>tcp_mark_head_lost()函数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div></pre></td><td class="code"><pre><div class="line">* Detect loss in event &quot;A&quot; above by marking head of queue up as lost.</div><div class="line"> * For FACK or non-SACK(Reno) senders, the first &quot;packets&quot; number of segments</div><div class="line"> * are considered lost. For RFC3517 SACK, a segment is considered lost if it</div><div class="line"> * has at least tp-&gt;reordering SACKed seqments above it; &quot;packets&quot; refers to</div><div class="line"> * the maximum SACKed segments to pass before reaching this limit.</div><div class="line"> * high_seq：可以标记为lost的段序号的最大值。</div><div class="line"> * mark_head: 为1表示只需要标志发送队列的第一个段。</div><div class="line"> */</div><div class="line">static void tcp_mark_head_lost(struct sock *sk, int packets, int mark_head)</div><div class="line">&#123;</div><div class="line">    struct tcp_sock *tp = tcp_sk(sk);</div><div class="line">    struct sk_buff *skb;</div><div class="line">    int cnt, oldcnt, lost;</div><div class="line">    unsigned int mss;</div><div class="line">    /* Use SACK to deduce losses of new sequences sent during recovery */</div><div class="line">    const u32 loss_high = tcp_is_sack(tp) ?  tp-&gt;snd_nxt : tp-&gt;high_seq;</div><div class="line">    /* 丢失的包不可能必发出去的包还多 */</div><div class="line">    WARN_ON(packets &gt; tp-&gt;packets_out);</div><div class="line">    /* 如果已经有被标记的段了 */</div><div class="line">    if (tp-&gt;lost_skb_hint) &#123;</div><div class="line">        skb = tp-&gt;lost_skb_hint;/* 让skb指向这个段，便于后面的遍历 */</div><div class="line">        cnt = tp-&gt;lost_cnt_hint;/* 已经标记了多少段 */</div><div class="line">        /* Head already handled? */</div><div class="line">        /* 已经有标记但，skb不等于发送队列的第一个包，则返回 */</div><div class="line">        if (mark_head &amp;&amp; skb != tcp_write_queue_head(sk))</div><div class="line">            return;</div><div class="line">    &#125; else &#123;</div><div class="line">        skb = tcp_write_queue_head(sk);/* 获得发送队列第一个包 */</div><div class="line">        cnt = 0;/* 初始化标记了0个数据 */</div><div class="line">    &#125;</div><div class="line">    tcp_for_write_queue_from(skb, sk) &#123;/* 根据取出来的skb，遍历重传队列 */</div><div class="line">        if (skb == tcp_send_head(sk))</div><div class="line">            break;/* 如果遍历到snd_nxt，则停止 */</div><div class="line">        /* TODO: do this better */</div><div class="line">        /* this is not the most efficient way to do this... */</div><div class="line">        tp-&gt;lost_skb_hint = skb;</div><div class="line">        tp-&gt;lost_cnt_hint = cnt;/* 暗示已经标记有多少丢包 */</div><div class="line">        /* loss_high是最大的标记为lost的序号，end_seq不可能大于它 */</div><div class="line">        if (after(TCP_SKB_CB(skb)-&gt;end_seq, loss_high))</div><div class="line">            break;</div><div class="line"></div><div class="line">        oldcnt = cnt;</div><div class="line">        if (tcp_is_fack(tp) || tcp_is_reno(tp) ||</div><div class="line">            (TCP_SKB_CB(skb)-&gt;sacked &amp; TCPCB_SACKED_ACKED))</div><div class="line">            cnt += tcp_skb_pcount(skb);/* 此段已经被sacked */</div><div class="line"></div><div class="line">        /* 主要用于判断时机 */</div><div class="line">        if (cnt &gt; packets) &#123;</div><div class="line">            if ((tcp_is_sack(tp) &amp;&amp; !tcp_is_fack(tp)) ||</div><div class="line">                (TCP_SKB_CB(skb)-&gt;sacked &amp; TCPCB_SACKED_ACKED) ||</div><div class="line">                (oldcnt &gt;= packets))</div><div class="line">                break;</div><div class="line"></div><div class="line">            mss = tcp_skb_mss(skb);</div><div class="line">            /* If needed, chop off the prefix to mark as lost. */</div><div class="line">            lost = (packets - oldcnt) * mss;</div><div class="line">            if (lost &lt; skb-&gt;len &amp;&amp; tcp_fragment(sk, skb, lost, mss, </div><div class="line">                GFP_ATOMIC) &lt; 0)</div><div class="line">                break;</div><div class="line">            cnt = packets;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        tcp_skb_mark_lost(tp, skb);</div><div class="line"></div><div class="line">        if (mark_head)/* 只标记一段的话，那么就可以退出了 */</div><div class="line">            break;</div><div class="line">    &#125;</div><div class="line">    tcp_verify_left_out(tp);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="tcp-skb-mark-lost-函数"><a href="#tcp-skb-mark-lost-函数" class="headerlink" title="tcp_skb_mark_lost()函数"></a>tcp_skb_mark_lost()函数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">static void tcp_skb_mark_lost(struct tcp_sock *tp, struct sk_buff *skb)</div><div class="line">&#123;</div><div class="line">    if (!(TCP_SKB_CB(skb)-&gt;sacked &amp; (TCPCB_LOST|TCPCB_SACKED_ACKED))) &#123;</div><div class="line">        tcp_verify_retransmit_hint(tp, skb);/* 更新重传队列 */</div><div class="line"></div><div class="line">        tp-&gt;lost_out += tcp_skb_pcount(skb);/* 统计丢包数 */</div><div class="line">        tcp_sum_lost(tp, skb);</div><div class="line">        TCP_SKB_CB(skb)-&gt;sacked |= TCPCB_LOST;/* 打上丢包标记 */</div><div class="line">    &#125;    </div><div class="line">&#125;</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要分析在TCP拥塞状态机的实现中，丢包后进入快速重传时，主要函数tcp_fastretrans_alert()的实现，及对一些相关函数也做了介绍。&lt;br&gt;
    
    </summary>
    
      <category term="TCP/IP" scheme="http://yoursite.com/categories/TCP-IP/"/>
    
    
  </entry>
  
  <entry>
    <title>Linux系统内核参数的添加方法</title>
    <link href="http://yoursite.com/2017/01/15/Linux%E7%B3%BB%E7%BB%9F%E5%86%85%E6%A0%B8%E5%8F%82%E6%95%B0%E7%9A%84%E6%B7%BB%E5%8A%A0%E6%96%B9%E6%B3%95/"/>
    <id>http://yoursite.com/2017/01/15/Linux系统内核参数的添加方法/</id>
    <published>2017-01-15T01:39:01.000Z</published>
    <updated>2017-05-17T16:41:16.441Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;在Linux系统下，使用sysctl命令可以查看和修改系统参数，但是如果想要添加一个系统参数应该怎么办呢？这篇博客的目的就是要来说这个事的。添加一个系统参数是一件很麻烦的事，大多时候是用来做测试用。<br><a id="more"></a></p>
<h4 id="在ctl-table中注册内核参数"><a href="#在ctl-table中注册内核参数" class="headerlink" title="在ctl_table中注册内核参数"></a>在ctl_table中注册内核参数</h4><p>在source/net/ipv4/sysctl_net_ipv4.c文件中有这样一个结构体数组<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">static struct ctl_table ipv4-table[] = &#123;</div><div class="line">    ......</div><div class="line">&#125;,</div><div class="line">&#123;</div><div class="line">    ......</div><div class="line">&#125;</div><div class="line">......</div></pre></td></tr></table></figure></p>
<p>在目录/proc/sys/net/ipv4/下面所有的系统参数都得先到这里注册，下面给出一个具体例子。<br><img src="../../../../pictures/TCP/20170115100648.png" alt=""><br>这两个参数是拥塞控制算法Vegas在拥塞控制阶段调节cwnd用的，相信很多人都不陌生。<br>这里是struct ctl_table的具体定义。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">/* 结构位置：include/linux/sysctl.h */</div><div class="line">struct ctl_table</div><div class="line">&#123;</div><div class="line">    const char    *procname;    /* Text ID for /proc/sys, or zero */</div><div class="line">    void          *data;</div><div class="line">    int           maxlen;</div><div class="line">    umode_t       mode;</div><div class="line">    struct        ctl_table *child;  /* Deprecated */</div><div class="line">    proc_handler  *proc_handler;     /* Callback for text formatting */</div><div class="line">    struct ctl_tabel_poll *poll;</div><div class="line">    void *extral;</div><div class="line">    void *extra2;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>现在简单介绍一下这些结构体成员变量。<br><em>procname 表示在/proc/sys/下显示的文件名称，
</em>data 表示对应于内核中的变量名称，<br>maxlen 表示允许的最大长度，<br>mode   表示访问权限<br>proc_handler表示回调函数，有一些常用取值：<br>porc_dointvec 读写包含一个或多个整数的数组，<br>proc_dostring 读写一个字符串，<br>proc_dointvec_minmax 写的整数必须在min~max范围内。</p>
<h4 id="声明内核参数"><a href="#声明内核参数" class="headerlink" title="声明内核参数"></a>声明内核参数</h4><p>用于TCP的内核参数在source/include/net/tcp.h声明。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">/* 进入tcp.h文件可以看到大量的变量声明，这里只列出上文提及到的两个变量 */</div><div class="line">...</div><div class="line">extern int sysctl_tcp_vegas_alpha;</div><div class="line">extern int sysctl_tcp_vegas_beta</div><div class="line">...</div></pre></td></tr></table></figure></p>
<h4 id="定义内核参数"><a href="#定义内核参数" class="headerlink" title="定义内核参数"></a>定义内核参数</h4><p>内核参数的定义可能在不同的文件中，这个根据内核参数的用途而定。<br>systcl_tcp_vegas_alpha和sysctl_tcp_vegas_beta这两个变量的定义位置：<br>source/net/ipv4/tcp_retrans.c<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">int sysctl_tcp_vegas_alpha = 2;</div><div class="line">int sysctl_tcp_vegas_beta = 4;</div></pre></td></tr></table></figure></p>
<p>经过上面这些步奏，内核参数就添加成功了，但我们编译重启系统后，就会发现在目录：<br>/proc/sys/net/ipv4/下有两个文件分别是tcp_vegas_alpha和tcp_vegas_beta，以后就可以通过echo命令动态修改这两个值了。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;在Linux系统下，使用sysctl命令可以查看和修改系统参数，但是如果想要添加一个系统参数应该怎么办呢？这篇博客的目的就是要来说这个事的。添加一个系统参数是一件很麻烦的事，大多时候是用来做测试用。&lt;br&gt;
    
    </summary>
    
      <category term="TCP/IP" scheme="http://yoursite.com/categories/TCP-IP/"/>
    
    
  </entry>
  
  <entry>
    <title>UNIX环境高级编程（第三版）头文件&quot;apue.h&quot;问题</title>
    <link href="http://yoursite.com/2017/01/15/UNIX%E7%8E%AF%E5%A2%83%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%EF%BC%88%E7%AC%AC%E4%B8%89%E7%89%88%EF%BC%89%E5%A4%B4%E6%96%87%E4%BB%B6%E2%80%9Capue.h%E2%80%9D%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2017/01/15/UNIX环境高级编程（第三版）头文件“apue.h”问题/</id>
    <published>2017-01-15T01:39:01.000Z</published>
    <updated>2017-05-14T13:17:50.278Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;初次学UNIX环境高级编程（第三版）都会遇到头文件”apue.h”怎么添加的问题，这里说下从下载源码到编译通过的整个过程。当然在编译中会遇到各种error，本人也踩了好几个坑，好在都解决了。<br><a id="more"></a></p>
<h4 id="下载源码及解压"><a href="#下载源码及解压" class="headerlink" title="下载源码及解压"></a>下载源码及解压</h4><p>先新建一个自己准备存放源码的目录，然后下载<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">cd /home/</div><div class="line">mkdir learnApue</div><div class="line">cd learnApue</div><div class="line">wget http://www.apuebook.com/src.tar.gz</div><div class="line">tar -zxvf src.tar.gz</div></pre></td></tr></table></figure></p>
<p>解压后的文件在目录”aupe.3e”下。</p>
<h4 id="头文件配置"><a href="#头文件配置" class="headerlink" title="头文件配置"></a>头文件配置</h4><p>经过上面的步骤，当前所在目录应该是”/home/learnApue/“<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">cd ./src.3e/apue.3e</div><div class="line">cp ./include/apue.h /usr/include/</div><div class="line">cp ./lib/error.c /usr/include/</div></pre></td></tr></table></figure></p>
<h4 id="编辑”-usr-include-apue-h”"><a href="#编辑”-usr-include-apue-h”" class="headerlink" title="编辑”/usr/include/apue.h”"></a>编辑”/usr/include/apue.h”</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vim /usr/include/apue.h</div></pre></td></tr></table></figure>
<p>光标移动到文件最后一行”#endif”的前面，然后添加如下代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">#include &quot;error.c&quot;</div></pre></td></tr></table></figure></p>
<p>保存退出</p>
<h4 id="make报错及其解决方案"><a href="#make报错及其解决方案" class="headerlink" title="make报错及其解决方案"></a>make报错及其解决方案</h4><p>经过上面的操作，然后就可以编译了，这时你所在目录应该是”/home/learnApue/src.3e/apue.3e/“<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">make</div></pre></td></tr></table></figure></p>
<p>正常情况下都会报error，下面是我遇到的error</p>
<h5 id="error类型1"><a href="#error类型1" class="headerlink" title="error类型1"></a>error类型1</h5><p><img src="../../../../pictures/UNIX/20170514211405.png" alt=""><br>根据错误提示，systype.sh无法执行，我的方法是更改权限然后再编译<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">chmod 755 systype.sh</div><div class="line">make</div></pre></td></tr></table></figure></p>
<h5 id="error类型2"><a href="#error类型2" class="headerlink" title="error类型2"></a>error类型2</h5><p><img src="../../../../pictures/UNIX/20170514211448.png" alt=""><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">chmod 755 ./advio/fixup.awk</div><div class="line">make</div></pre></td></tr></table></figure></p>
<p>继续更改权限，只要是执行权限问题，都可以更改权限后再编译</p>
<h5 id="error类型3"><a href="#error类型3" class="headerlink" title="error类型3"></a>error类型3</h5><p>下面的这个错误我没有碰到，来自于网友的报错，这里给出关键报错信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">/usr/bin/ld: cannot find -lbsd</div><div class="line">...</div><div class="line">make: ***[all] Error 1</div></pre></td></tr></table></figure></p>
<p>根据这个error提示，应该是缺少一个库，解决方案如下。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">apt-get install libbsd-dev</div><div class="line">make</div></pre></td></tr></table></figure></p>
<p>要说明的是我是roor权限，不是roor权限的在上一条命令前加sudo，再编译。<br>希望对各位正在使用UNIX环境高级编程一书的同行们有帮助，有错误还请指出。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;初次学UNIX环境高级编程（第三版）都会遇到头文件”apue.h”怎么添加的问题，这里说下从下载源码到编译通过的整个过程。当然在编译中会遇到各种error，本人也踩了好几个坑，好在都解决了。&lt;br&gt;
    
    </summary>
    
      <category term="UNIX/LINUX" scheme="http://yoursite.com/categories/UNIX-LINUX/"/>
    
    
  </entry>
  
  <entry>
    <title>异常控制流</title>
    <link href="http://yoursite.com/2016/10/19/%E5%BC%82%E5%B8%B8%E6%8E%A7%E5%88%B6%E6%B5%81/"/>
    <id>http://yoursite.com/2016/10/19/异常控制流/</id>
    <published>2016-10-19T04:44:34.000Z</published>
    <updated>2017-10-02T19:02:46.771Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a>
<h3 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h3><p>&emsp;&emsp;现代系统通过使控制流发生突变来对某些情况做出反应（比如，一个硬件定时器定期产生信号，这个事件必须得到处理；包到达网络适配器后，必须存放在存储器中；程序向磁盘请求数据，然后休眠直到被通知数据已就绪。）一般而言，把这些突变称为异常控制流。<br>&emsp;&emsp;异常是异常控制流的一种形式，它一部分是由硬件实现的，一部分是由操作系统实现的。异常就是控制流中的突变，用来响应处理器状态的某些变化。图1给出了处理异常的基本思想：<br><img src="../../../../pictures/Computer System/20171003014141.png" alt=""></p>
<h4 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h4><p>&emsp;&emsp;处理异常需要硬件和软件的紧密合作，系统中可能的每种类型的异常都分配了一个唯一的非负整数的异常号。其中一些号码是由处理器的设计者分配的，其他号码是由操作系统内核的设计者分配的。<br>&emsp;&emsp;在系统启动时，操作系统分配和初始化一张称为异常表的跳转表，使得条目k包含异常k的处理程序的地址。图2给出了处理器如何使用异常表来形成适当的异常处理程序的地址。异常号是到异常表中的索引，异常表的起始地址存放在一个叫做异常表基址寄存器的特殊CPU寄存器里。<br><img src="../../../../pictures/Computer System/20171003020314.png" alt=""></p>
<h4 id="异常的类别"><a href="#异常的类别" class="headerlink" title="异常的类别"></a>异常的类别</h4><p>&emsp;&emsp;异常可以分为四类：中断、陷阱、故障和终止。图3对这些类别的属性做了小结。<br><img src="../../../../pictures/Computer System/20171003021412.png" alt=""><br><strong>中断：</strong>硬件中断不是由任何一条专门的指令造成的，硬件中断的异常处理程序通常称为中断处理程序。<br><strong>陷阱和系统调用：</strong>陷阱是有意的异常，是执行一条指令的结果。陷阱最重要的用途是在用户程序和内核之间提供一个像过程一样的接口，叫做系统调用。<br><strong>故障：</strong>故障由错误情况引起，它可能能够被故障处理程序修正，如果处理程序能够修正这个错误情况，它就将控制返回到引起故障的指令，从而重新执行它。否则，处理程序返回到内核中的abort例程。<br><strong>终止：</strong>终止是不可恢复的致命错误造成的结果，通常是一些硬件错误，处理程序将控制返回给一个abort例程，该例程会终止这个应用程序。</p>
]]></content>
    
    <summary type="html">
    
      &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;异常&quot;&gt;&lt;a href=&quot;#异常&quot; class=&quot;headerlink&quot; title=&quot;异常&quot;&gt;&lt;/a&gt;异常&lt;/h3&gt;&lt;p&gt;&amp;emsp;&amp;emsp;现代系统通过使控制流发生突变来对某些情况做出反应（比如，一个硬件定时器定期产生信
    
    </summary>
    
      <category term="深入理解计算机系统" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"/>
    
    
  </entry>
  
</feed>
